<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">

  <!-- PACE Progress Bar START -->
  
    
<script src="https://raw.githubusercontent.com/HubSpot/pace/v1.0.2/pace.min.js"></script>

    
<link rel="stylesheet" href="https://github.com/HubSpot/pace/raw/master/themes/orange/pace-theme-flash.css">

  
  

  <!-- PACE Progress Bar START -->

  
  <title>Yujie&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  
  
  
  <meta name="description" content="æ¬¢è¿å’Œæˆ‘ä¸€èµ·è¿›æ­¥ï¼åˆ†äº«ç”Ÿæ´»ï¼åˆ†äº«çƒ­çˆ±">
<meta property="og:type" content="website">
<meta property="og:title" content="Yujie&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Yujie&#39;s Blog">
<meta property="og:description" content="æ¬¢è¿å’Œæˆ‘ä¸€èµ·è¿›æ­¥ï¼åˆ†äº«ç”Ÿæ´»ï¼åˆ†äº«çƒ­çˆ±">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chen Yujie">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Yujie&#39;s Blog" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="https://cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  
<link rel="stylesheet" href="/css/style.css">


  
<script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css" >
  <link rel="stylesheet" href="/css/hiero.css" >
  <link rel="stylesheet" href="/css/glyphs.css" >
  
    <link rel="stylesheet" href="/css/vdonate.css" >
  

  <!-- Custom CSS -->
  
<link rel="stylesheet" href="/css/my.css">

  <!-- Google Adsense -->
  
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
      (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-0123456789ABCDEF",
          enable_page_level_ads: true
      });
  </script>
  
<meta name="generator" content="Hexo 6.3.0"></head>

<script>
var themeMenus = {};

  themeMenus["/"] = "é¦–é¡µ"; 

  themeMenus["/archives"] = "å½’æ¡£"; 

  themeMenus["/categories"] = "åˆ†ç±»"; 

  themeMenus["/tags"] = "æ ‡ç­¾"; 

  themeMenus["/about"] = "å…³äº"; 

</script>


  <body>


  <header id="allheader" class="site-header" role="banner">
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" title="Yujie&#39;s Blog" rel="home"> Yujie&#39;s Blog </a>
            
          </h1>

          
            <div class="site-description">æ¬¢è¿å’Œæˆ‘ä¸€èµ·è¿›æ­¥ï¼åˆ†äº«ç”Ÿæ´»ï¼åˆ†äº«çƒ­çˆ±</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>
            <div class="clearfix sf-menu">

              <ul id="main-nav" class="nmenu sf-js-enabled">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">é¦–é¡µ</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">å½’æ¡£</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/categories">åˆ†ç±»</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/tags">æ ‡ç­¾</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/about">å…³äº</a> </li>
                    
              </ul>
            </div>
          </nav>


      </div>
  </div>
</header>


  <div id="originBgDiv" style="background: #fff; width: 100%;">

      <div style="max-height:600px; overflow: hidden;  display: flex; display: -webkit-flex; align-items: center;">
        <img id="originBg" width="100%" alt="" src="">
      </div>

  </div>

  <script>
  function setAboutIMG(){
      var imgUrls = "css/images/pose.jpg,https://source.unsplash.com/collection/954550/1920x1080".split(",");
      var random = Math.floor((Math.random() * imgUrls.length ));
      if (imgUrls[random].startsWith('http') || imgUrls[random].indexOf('://') >= 0) {
        document.getElementById("originBg").src=imgUrls[random];
      } else {
        document.getElementById("originBg").src='/' + imgUrls[random];
      }
  }
  bgDiv=document.getElementById("originBgDiv");
  if(location.pathname.match('about')){
    setAboutIMG();
    bgDiv.style.display='block';
  }else{
    bgDiv.style.display='none';
  }
  </script>



  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main">
  
    <article id="post-Untitled"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
    <div class="article-meta">
      
	Posted on <a href="/2023/08/09/Untitled/" class="article-date">
	  <time datetime="2023-08-09T01:19:40.626Z" itemprop="datePublished">å…«æœˆ 9, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="entry-meta entry-footer">
      
      
      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-LLMç›¸å…³æœ€æ–°è¿›å±•"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/08/08/LLM%E7%9B%B8%E5%85%B3%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/">LLMç›¸å…³è¿›å±•</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/08/08/LLM%E7%9B%B8%E5%85%B3%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/" class="article-date">
	  <time datetime="2023-08-08T08:23:51.858Z" itemprop="datePublished">å…«æœˆ 8, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>è·Ÿè¸ªå¤§è¯­è¨€æ¨¡å‹ç›¸å…³çš„æœ€æ–°è¿›å±•</p>
<h1 id="LLMç±»å‹"><a href="#LLMç±»å‹" class="headerlink" title="LLMç±»å‹"></a>LLMç±»å‹</h1><h2 id="ä¸­æ–‡å¤§æ¨¡å‹"><a href="#ä¸­æ–‡å¤§æ¨¡å‹" class="headerlink" title="ä¸­æ–‡å¤§æ¨¡å‹"></a>ä¸­æ–‡å¤§æ¨¡å‹</h2><h3 id="é€šä¹‰åƒé—®"><a href="#é€šä¹‰åƒé—®" class="headerlink" title="é€šä¹‰åƒé—®"></a>é€šä¹‰åƒé—®</h3><h4 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h4><p>é€šä¹‰åƒé—®-7Bï¼ˆQwen-7Bï¼‰ æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„é€šä¹‰åƒé—®å¤§æ¨¡å‹ç³»åˆ—çš„70äº¿å‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€‚Qwen-7Bæ˜¯åŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹, åœ¨è¶…å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒå¾—åˆ°ã€‚é¢„è®­ç»ƒæ•°æ®ç±»å‹å¤šæ ·ï¼Œè¦†ç›–å¹¿æ³›ï¼ŒåŒ…æ‹¬å¤§é‡ç½‘ç»œæ–‡æœ¬ã€ä¸“ä¸šä¹¦ç±ã€ä»£ç ç­‰ã€‚åŒæ—¶ï¼Œåœ¨Qwen-7Bçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨å¯¹é½æœºåˆ¶æ‰“é€ äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„AIåŠ©æ‰‹Qwen-7B-Chatã€‚Qwen-7Bç³»åˆ—æ¨¡å‹çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>å¤§è§„æ¨¡é«˜è´¨é‡é¢„è®­ç»ƒæ•°æ®</strong>ï¼šæˆ‘ä»¬ä½¿ç”¨äº†è¶…è¿‡2.2ä¸‡äº¿tokençš„è‡ªå»ºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†è¿›è¡Œè¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒã€‚æ•°æ®é›†åŒ…æ‹¬æ–‡æœ¬å’Œä»£ç ç­‰å¤šç§æ•°æ®ç±»å‹ï¼Œè¦†ç›–é€šç”¨é¢†åŸŸå’Œä¸“ä¸šé¢†åŸŸã€‚</li>
<li><strong>ä¼˜ç§€çš„æ¨¡å‹æ€§èƒ½</strong>ï¼šç›¸æ¯”åŒè§„æ¨¡çš„å¼€æºæ¨¡å‹ï¼ŒQwen-7Båœ¨å¤šä¸ªè¯„æµ‹æ•°æ®é›†ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œç”šè‡³è¶…å‡º12-13Bç­‰æ›´å¤§è§„æ¨¡çš„æ¨¡å‹ã€‚è¯„æµ‹è¯„ä¼°çš„èƒ½åŠ›èŒƒå›´åŒ…æ‹¬è‡ªç„¶è¯­è¨€ç†è§£ä¸ç”Ÿæˆã€æ•°å­¦è¿ç®—è§£é¢˜ã€ä»£ç ç”Ÿæˆç­‰ã€‚</li>
<li><strong>æ›´å¥½åœ°æ”¯æŒå¤šè¯­è¨€</strong>ï¼šåŸºäºæ›´å¤§è¯è¡¨çš„åˆ†è¯å™¨åœ¨åˆ†è¯ä¸Šæ›´é«˜æ•ˆï¼ŒåŒæ—¶å®ƒå¯¹å…¶ä»–è¯­è¨€è¡¨ç°æ›´åŠ å‹å¥½ã€‚ç”¨æˆ·å¯ä»¥åœ¨Qwen-7Bçš„åŸºç¡€ä¸Šæ›´æ–¹ä¾¿åœ°è®­ç»ƒç‰¹å®šè¯­è¨€çš„7Bè¯­è¨€æ¨¡å‹ã€‚</li>
<li><strong>8Kçš„ä¸Šä¸‹æ–‡é•¿åº¦</strong>ï¼šQwen-7BåŠQwen-7B-Chatå‡èƒ½æ”¯æŒ8Kçš„ä¸Šä¸‹æ–‡é•¿åº¦, å…è®¸ç”¨æˆ·è¾“å…¥æ›´é•¿çš„promptã€‚</li>
<li><strong>æ”¯æŒæ’ä»¶è°ƒç”¨</strong>ï¼šQwen-7B-Chaté’ˆå¯¹æ’ä»¶è°ƒç”¨ç›¸å…³çš„å¯¹é½æ•°æ®åšäº†ç‰¹å®šä¼˜åŒ–ï¼Œå½“å‰æ¨¡å‹èƒ½æœ‰æ•ˆè°ƒç”¨æ’ä»¶ä»¥åŠå‡çº§ä¸ºAgentã€‚</li>
</ol>
<h5 id="æ¨¡å‹åŸºåº§"><a href="#æ¨¡å‹åŸºåº§" class="headerlink" title="æ¨¡å‹åŸºåº§"></a><strong>æ¨¡å‹åŸºåº§</strong></h5><p>åŸºäºtransformerçš„çº¯è§£ç å™¨è¯­è¨€æ¨¡å‹ï¼Œå…¶æ¶æ„ç±»ä¼¼äºLLaMAç³»åˆ—æ¨¡å‹ã€‚å’Œæ ‡å‡†transformerä¸åŒä¹‹å¤„åœ¨äºï¼š</p>
<blockquote>
<ol>
<li>using <strong><u>untied embedding</u></strong></li>
<li>using <strong><u>rotary positional embedding</u></strong></li>
<li><strong><u>no biases</u></strong> except for QKV in attention</li>
<li><strong><u>RMSNorm</u></strong> instead of LayerNorm</li>
<li><strong><u>SwiGLU</u></strong> instead of ReLU</li>
<li>adopting <strong><u>flash attention</u></strong> to accelerate training.</li>
</ol>
<p>The model has 32 layers, the embedding dimension is 4096, and the number of attention heads is 32.</p>
</blockquote>
<h5 id="é¢„è®­ç»ƒQwen-7B"><a href="#é¢„è®­ç»ƒQwen-7B" class="headerlink" title="é¢„è®­ç»ƒQwen-7B"></a><strong>é¢„è®­ç»ƒQwen-7B</strong></h5><blockquote>
<p><strong>é¢„è®­ç»ƒ</strong>ï¼šè¶…è¿‡2.2ä¸‡äº¿ä¸ªtokenä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œä»å…¬å¼€å¯ç”¨çš„æ•°æ®ä¸­è·å¾—2048ä¸ªä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæ¶µç›–ä¸€èˆ¬å’Œä¸“ä¸šé¢†åŸŸï¼Œé‡ç‚¹æ˜¯è‹±è¯­å’Œæ±‰è¯­</p>
<p><strong>é¢„è®­ç»ƒæ•°æ®</strong>å¤„ç†ï¼šæˆ‘ä»¬çš„æ•°æ®åŒ…æ‹¬æ¥è‡ªå…¬å¼€æ¥æºçš„æ··åˆæ•°æ®ï¼Œä¸»è¦åŒ…æ‹¬ç½‘ç»œæ–‡æ¡£å’Œä»£ç æ–‡ä»¶ã€‚æ­¤å¤–ï¼Œæ•°æ®æ˜¯å¤šè¯­ç§çš„ï¼Œå¤§éƒ¨åˆ†æ˜¯è‹±è¯­å’Œæ±‰è¯­ã€‚æˆ‘ä»¬åŠªåŠ›ä½¿ç”¨ä¸€ç³»åˆ—æ¨¡å‹æ¥æ’é™¤ä½è´¨é‡æˆ–è¢«è®¤ä¸ºä¸é€‚åˆé¢„è®­ç»ƒçš„æ•°æ®ï¼Œä¾‹å¦‚ NSFW å†…å®¹ã€‚å¯¹äºæ•°å­¦æ¨ç†ï¼Œæˆ‘ä»¬åŒ…æ‹¬æ¥è‡ª<a target="_blank" rel="noopener" href="https://github.com/ofa-sys/gsm8k-ScRel"> gsm8k-scRel </a>çš„ RFT æ•°æ®ã€‚æœ€ç»ˆæ•°æ®è¿›è¡Œäº†å…¨å±€æ¨¡ç³Šé‡å¤ï¼ˆglobal fuzzy deduplicationï¼‰æ•°æ®åˆ é™¤ã€‚é€šè¿‡å¤§é‡çš„æ¶ˆèå®éªŒï¼Œä¼˜åŒ–äº†é¢„è®­ç»ƒè¯­æ–™åº“çš„ç»„åˆã€‚</p>
<p><strong>tokenization</strong>ï¼šè¯è¡¨ 151,851 tokensï¼Œå®ƒé¦–å…ˆè€ƒè™‘äº†æ±‰è¯­ã€è‹±è¯­å’Œä»£ç æ•°æ®çš„é«˜æ•ˆç¼–ç ï¼Œè€Œä¸”å¯¹å¤šè¯­è¨€æ›´åŠ å‹å¥½ï¼Œä½¿ç”¨æˆ·å¯ä»¥ç›´æ¥æé«˜æŸäº›è¯­è¨€çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€æ‰©å……è¯æ±‡é‡ã€‚å®ƒæŒ‰å¯¹æ•°å­—è¿›è¡Œåˆ†å‰²ï¼ˆå•ä¸ªï¼‰ï¼Œå¹¶è°ƒç”¨ <a target="_blank" rel="noopener" href="https://github.com/openai/tiktoken">tiktoken</a>  tokenizeråº“ä»¥è¿›è¡Œæœ‰æ•ˆçš„tokenizationã€‚tokenizationåçš„æ•°æ®æ€»é‡è¶…è¿‡2.2ä¸‡äº¿ä¸ªtokenã€‚</p>
<p>æˆ‘ä»¬éšæœºé€‰æ‹©æ¯ç§è¯­è¨€çš„100ä¸‡ä¸ªæ–‡æ¡£è¯­æ–™åº“æ¥æµ‹è¯•å’Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„ç¼–ç å‹ç¼©ç‡(ä½¿ç”¨æ”¯æŒ100ç§è¯­è¨€çš„ XLM-R ä½œä¸ºåŸºå€¼1ï¼Œå›¾ä¸­æœªæ˜¾ç¤º)ã€‚å¯ä»¥çœ‹å‡ºï¼ŒQwen-7B åœ¨ä¿è¯æ±‰è¯­ã€è‹±è¯­å’Œä»£ç çš„é«˜æ•ˆè§£ç çš„åŒæ—¶ï¼Œè¿˜èƒ½åœ¨å…¶ä»–å¤šç§è¯­è¨€(å¦‚ æ³°è¯­thã€å¸Œä¼¯æ¥è¯­heã€é˜¿æ‹‰ä¼¯è¯­arã€éŸ©è¯­koã€è¶Šå—è¯­viã€æ—¥è¯­jaã€åœŸè€³å…¶è¯­trã€å°å°¼è¯­idã€æ³¢å…°è¯­plã€ä¿„è¯­ruã€è·å…°è¯­nlã€è‘¡è„ç‰™è¯­ptã€æ„å¤§åˆ©è¯­itã€å¾·è¯­deã€è¥¿ç­ç‰™è¯­esã€æ³•è¯­frç­‰)ä¸­è·å¾—è¾ƒé«˜çš„å‹ç¼©ç‡ï¼Œä½¿æ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„å¯æ‰©å±•æ€§ï¼Œä»¥åŠè¿™äº›è¯­è¨€çš„é«˜è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚</p>
<p><strong>è®­ç»ƒç»†èŠ‚</strong>: </p>
<blockquote>
<p>The model is trained using the AdamW optimizer, with<br>$$<br>\beta_1&#x3D;0.9, \beta_2&#x3D;0.95, \epsilon&#x3D;10^{-6}<br>$$<br>. The sequence length is 2048, and the batch size is 2048, which means each optimization step accumulates over 4 million tokens. We use a cosine learning rate schedule, with a warm-up of 2000 steps, a peak learning rate of 3Ã—10^âˆ’4, and a minimum learning rate of 10% of the peak learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. The training adopts mixed precision training with <code>bfloat16</code>.</p>
</blockquote>
<p>è¯„ä¼°ï¼š</p>
<p>ã€1ã€‘World knowledgeï¼ˆä¸–ç•ŒçŸ¥è¯†ï¼‰</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.08322"> <strong>C-Eval</strong> </a>æ˜¯ä¸€ä¸ªé€šç”¨çš„è¯„ä¼°åŸºå‡†ï¼Œç”¨äºæµ‹è¯•é¢„è®­ç»ƒçš„ä¸­æ–‡æ¨¡å‹çš„å¸¸è¯†èƒ½åŠ›ã€‚å®ƒæ¶µç›–äº†å››ä¸ªä¸»è¦æ–¹å‘çš„52ä¸ªå­¦ç§‘: äººæ–‡ã€ç¤¾ä¼šç§‘å­¦ã€ç§‘å­¦ã€æŠ€æœ¯ã€å·¥ç¨‹å’Œå…¶ä»–ä¸“ä¸šï¼ˆhumanities, social sciences, STEM, and other specialtiesï¼‰ã€‚æ ¹æ®æ ‡å‡†å®è·µï¼Œä»¥validationæ ·æœ¬ä½œä¸ºå°‘æ ·æœ¬promptçš„æ¥æºï¼Œå¯¹ Qwen-7B é¢„è®­ç»ƒæ¨¡å‹çš„5-shotéªŒè¯é›†å’Œæµ‹è¯•é›†ç²¾åº¦è¿›è¡Œäº†è¯„ä¼°ã€‚</p>
<p><strong>MMLU</strong> æ˜¯ç›®å‰è¯„ä»·è‹±è¯­ç†è§£èƒ½åŠ›æœ€å…¬è®¤çš„åŸºå‡†ä¹‹ä¸€ï¼Œæ¶µç›–äº†ä¸åŒå­¦æœ¯é¢†åŸŸå’Œéš¾åº¦æ°´å¹³çš„57ä¸ªå­ä»»åŠ¡ã€‚</p>
<p>ã€2ã€‘Codingï¼ˆç¼–ç¨‹ï¼‰</p>
<p>**<a target="_blank" rel="noopener" href="https://github.com/openai/human-eval">HumanEval</a>**ï¼šPass@1</p>
<p>ã€3ã€‘Mathï¼ˆæ•°å­¦ï¼‰</p>
<p><a target="_blank" rel="noopener" href="https://github.com/openai/grade-school-math">GSM8K</a> (8-shot)ï¼šAccuracy</p>
<p>ã€4ã€‘Natural language processing è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆç¿»è¯‘ï¼‰</p>
<p>WMT22 zh-en and en-zh (5-shot BLEU)</p>
<p>ã€5ã€‘Long-context inference é•¿æ–‡æœ¬å¤–æ¨</p>
</blockquote>
<h5 id="å¾®è°ƒQwen-7B-Chat"><a href="#å¾®è°ƒQwen-7B-Chat" class="headerlink" title="å¾®è°ƒQwen-7B-Chat"></a><strong>å¾®è°ƒQwen-7B-Chat</strong></h5><blockquote>
<p>**å¯¹é½æ•°æ® ** :<br>è¿™äº›æ•°æ®åŒ…æ‹¬å¸¸è§çš„æŒ‡ä»¤é£æ ¼çš„å¯¹è¯ï¼Œä»¥åŠæ¶‰åŠå¤§é‡æ ‡æ³¨å·¥ä½œçš„é¢å‘å®‰å…¨å’ŒæœåŠ¡çš„æ•°æ®ã€‚<br>â€“ æŒ‡ä»¤æ•°æ®åŒ…æ‹¬å¹¿æ³›çš„èƒ½åŠ›ï¼Œå¦‚å†™ä½œï¼Œé—®é¢˜å›ç­”ï¼Œå¤´è„‘é£æš´å’Œè®¡åˆ’ï¼Œå†…å®¹ç†è§£ï¼Œæ€»ç»“ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†å’Œç¼–ç ã€‚<br>â€“ å®‰å…¨æ•°æ®è¯•å›¾é˜²æ­¢æ¨¡å‹ç”Ÿæˆæœ‰å®³å’Œä¸é€‚å½“çš„å†…å®¹ã€‚<br>â€“ æœåŠ¡æ•°æ®å°è¯•ä½¿ç”¨ç‰¹å®šçš„ä¼šè¯æ¨¡å¼æ¥å¢å¼ºæ¨¡å‹ï¼Œè¿™äº›æ¨¡å¼å¯ä»¥è¢«è§£æä»¥è°ƒç”¨å’Œåˆå¹¶å¤–éƒ¨ç³»ç»Ÿã€‚</p>
<p><strong>æ•°æ®æ ¼å¼</strong> :<br>ç”±äºæ•°æ®ç”±ä¼šè¯è½®æ•°ç»„æˆï¼Œæˆ‘ä»¬ä½¿ç”¨<a target="_blank" rel="noopener" href="https://github.com/openai/openai-python/blob/main/ChatML.md"> chatML </a>æ ¼å¼å°†å®ƒä»¬æ’åˆ—æˆæ–‡æœ¬ï¼Œè¿™æ˜¯ä¸€ç§å…ƒè¯­è¨€ï¼Œæ—¢å¯ä»¥æè¿°å…ƒæ•°æ®(ä¾‹å¦‚ï¼Œroles) ï¼Œä¹Ÿå¯ä»¥æè¿°æ¯è½®çš„å†…å®¹ã€‚<br>ç›®å‰ï¼Œç°æœ‰çš„è§’è‰²åŒ…æ‹¬ç³»ç»Ÿã€ç”¨æˆ·å’ŒåŠ©æ‰‹(system, user, and assistant)ã€‚</p>
<p><strong>æ¨¡å‹è®­ç»ƒç»†èŠ‚ï¼š</strong></p>
<p>ä½¿ç”¨å› æœè¯­è¨€å»ºæ¨¡ç›®æ ‡ï¼ˆcausal language modelingï¼‰å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé™¤äº†userè½®æ¬¡å†…å®¹ä¸­çš„tokenã€‚</p>
<p>è¯¥æ¨¡å‹ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­ $beta _ 1 &#x3D; 0.9ï¼Œbeta _ 2 &#x3D; 0.95ï¼Œepsilon &#x3D; 10 ^ {-6} $ã€‚</p>
<p>åºåˆ—é•¿åº¦é™åˆ¶ä¸º2048ï¼Œæ‰¹é‡å¤§å°ä¸º128ã€‚</p>
<p>è¯¥æ¨¡å‹ç»è¿‡4000ä¸ªæ­¥éª¤çš„è®­ç»ƒï¼Œåœ¨å‰1430ä¸ªæ­¥éª¤ä¸­ï¼Œå­¦ä¹ é€Ÿç‡è¢«åŠ çƒ­åˆ° $1ä¹˜ä»¥10 ^ { -5} $ã€‚</p>
<p>æˆ‘ä»¬ä½¿ç”¨0.1çš„æƒé‡è¡°å‡ï¼Œ0.1çš„è¾å­¦ï¼Œå’Œ1.0çš„æ¢¯åº¦è£å‰ªã€‚</p>
<p><strong>è¯„ä¼°ï¼š</strong></p>
<p>ã€1ã€‘World knowledge</p>
<p>ç”±äºå¾®è°ƒä½¿ç”¨çš„æ•°æ®é›†æ¯”é¢„è®­ç»ƒå°å¾—å¤šï¼Œäººç±»å¯¹ä¸–ç•ŒçŸ¥è¯†çš„ç†è§£å¯èƒ½æœ‰é™ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ C-Eval å’Œ MMLU ä»¥zero-shotå’Œç”Ÿæˆçš„æ–¹å¼è¯„ä¼° Qwen-7B-Chat çš„ä¸–ç•ŒçŸ¥è¯†ã€‚</p>
<p>C-Eval validation setï¼šzero-shot accuracy</p>
<p>MMLUï¼šzero-shot accuracy</p>
<p>ã€2ã€‘Coding</p>
<p><a target="_blank" rel="noopener" href="https://github.com/openai/human-eval">HumanEval</a>ï¼šzero-shot Pass@1</p>
<p>ã€3ã€‘Math</p>
<p>GSM8Kï¼šaccuracy</p>
<p>ã€4ã€‘Service</p>
<p>Tool Selection (Acc.â†‘)ã€Tool Input (Rouge-Lâ†‘) ã€ False Positive Errorâ†“  </p>
</blockquote>
<h4 id="è¯„æµ‹è¡¨ç°"><a href="#è¯„æµ‹è¡¨ç°" class="headerlink" title="è¯„æµ‹è¡¨ç°"></a>è¯„æµ‹è¡¨ç°</h4><p>Qwen-7Båœ¨å¤šä¸ªå…¨é¢è¯„ä¼°è‡ªç„¶è¯­è¨€ç†è§£ä¸ç”Ÿæˆã€æ•°å­¦è¿ç®—è§£é¢˜ã€ä»£ç ç”Ÿæˆç­‰èƒ½åŠ›çš„è¯„æµ‹æ•°æ®é›†ä¸Šï¼ŒåŒ…æ‹¬MMLUã€C-Evalã€GSM8Kã€HumanEvalã€WMT22ç­‰ï¼Œå‡è¶…å‡ºäº†åŒè§„æ¨¡å¤§è¯­è¨€æ¨¡å‹çš„è¡¨ç°ï¼Œç”šè‡³è¶…å‡ºäº†å¦‚12-13Bå‚æ•°ç­‰æ›´å¤§è§„æ¨¡çš„è¯­è¨€æ¨¡å‹ã€‚</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>MMLU</th>
<th>C-Eval</th>
<th>GSM8K</th>
<th>HumanEval</th>
<th>WMT22 (en-zh)</th>
</tr>
</thead>
<tbody><tr>
<td>LLaMA-7B</td>
<td>35.1</td>
<td>-</td>
<td>11.0</td>
<td>10.5</td>
<td>8.7</td>
</tr>
<tr>
<td>LLaMA 2-7B</td>
<td>45.3</td>
<td>-</td>
<td>14.6</td>
<td>12.8</td>
<td>17.9</td>
</tr>
<tr>
<td>Baichuan-7B</td>
<td>42.3</td>
<td>42.8</td>
<td>9.7</td>
<td>9.2</td>
<td>26.6</td>
</tr>
<tr>
<td>ChatGLM2-6B</td>
<td>47.9</td>
<td>51.7</td>
<td>32.4</td>
<td>9.2</td>
<td>-</td>
</tr>
<tr>
<td>InternLM-7B</td>
<td>51.0</td>
<td>52.8</td>
<td>31.2</td>
<td>10.4</td>
<td>14.8</td>
</tr>
<tr>
<td>Baichuan-13B</td>
<td>51.6</td>
<td>53.6</td>
<td>26.6</td>
<td>12.8</td>
<td>30.0</td>
</tr>
<tr>
<td>LLaMA-13B</td>
<td>46.9</td>
<td>35.5</td>
<td>17.8</td>
<td>15.8</td>
<td>12.0</td>
</tr>
<tr>
<td>LLaMA 2-13B</td>
<td>54.8</td>
<td>-</td>
<td>28.7</td>
<td>18.3</td>
<td>24.2</td>
</tr>
<tr>
<td>ChatGLM2-12B</td>
<td>56.2</td>
<td><strong>61.6</strong></td>
<td>40.9</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td><strong>Qwen-7B</strong></td>
<td><strong>56.7</strong></td>
<td>59.6</td>
<td><strong>51.6</strong></td>
<td><strong>24.4</strong></td>
<td><strong>30.6</strong></td>
</tr>
</tbody></table>
<h4 id="ä½¿ç”¨"><a href="#ä½¿ç”¨" class="headerlink" title="ä½¿ç”¨"></a>ä½¿ç”¨</h4><p>åœ¨å¼€å§‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»é…ç½®å¥½ç¯å¢ƒå¹¶å®‰è£…å¥½ç›¸å…³çš„ä»£ç åŒ…ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œç¡®ä¿ä½ æ»¡è¶³ä¸Šè¿°è¦æ±‚ï¼Œç„¶åå®‰è£…ç›¸å…³çš„ä¾èµ–åº“ã€‚</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>å¦‚æœä½ çš„æ˜¾å¡æ”¯æŒfp16æˆ–bf16ç²¾åº¦ï¼Œæˆ‘ä»¬è¿˜æ¨èå®‰è£…<a target="_blank" rel="noopener" href="https://github.com/Dao-AILab/flash-attention">flash-attention</a>æ¥æé«˜ä½ çš„è¿è¡Œæ•ˆç‡ä»¥åŠé™ä½æ˜¾å­˜å ç”¨ã€‚(<strong>flash-attentionåªæ˜¯å¯é€‰é¡¹ï¼Œä¸å®‰è£…ä¹Ÿå¯æ­£å¸¸è¿è¡Œè¯¥é¡¹ç›®</strong>)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone -b v1.0.8 https://github.com/Dao-AILab/flash-attention</span><br><span class="line">cd flash-attention &amp;&amp; pip install .</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ä¸‹æ–¹å®‰è£…å¯é€‰ï¼Œå®‰è£…å¯èƒ½æ¯”è¾ƒç¼“æ…¢ã€‚</span></span><br><span class="line">pip install csrc/layer_norm</span><br><span class="line">pip install csrc/rotary</span><br></pre></td></tr></table></figure>

<p>æ¥ä¸‹æ¥å¯ä»¥å¼€å§‹ä½¿ç”¨Transformersæˆ–è€…ModelScopeæ¥ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚</p>
<h5 id="ğŸ¤—-Transformers"><a href="#ğŸ¤—-Transformers" class="headerlink" title="ğŸ¤— Transformers"></a>ğŸ¤— Transformers</h5><p>å¦‚å¸Œæœ›ä½¿ç”¨Qwen-7B-chatè¿›è¡Œæ¨ç†ï¼Œæ‰€éœ€è¦å†™çš„åªæ˜¯å¦‚ä¸‹æ‰€ç¤ºçš„æ•°è¡Œä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers.generation <span class="keyword">import</span> GenerationConfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯·æ³¨æ„ï¼šåˆ†è¯å™¨é»˜è®¤è¡Œä¸ºå·²æ›´æ”¹ä¸ºé»˜è®¤å…³é—­ç‰¹æ®Štokenæ”»å‡»é˜²æŠ¤ã€‚</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;Qwen/Qwen-7B-Chat&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‰“å¼€bf16ç²¾åº¦ï¼ŒA100ã€H100ã€RTX3060ã€RTX3070ç­‰æ˜¾å¡å»ºè®®å¯ç”¨ä»¥èŠ‚çœæ˜¾å­˜</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, bf16=True).eval()</span></span><br><span class="line"><span class="comment"># æ‰“å¼€fp16ç²¾åº¦ï¼ŒV100ã€P100ã€T4ç­‰æ˜¾å¡å»ºè®®å¯ç”¨ä»¥èŠ‚çœæ˜¾å­˜</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, fp16=True).eval()</span></span><br><span class="line"><span class="comment"># ä½¿ç”¨CPUè¿›è¡Œæ¨ç†ï¼Œéœ€è¦çº¦32GBå†…å­˜</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;cpu&quot;, trust_remote_code=True).eval()</span></span><br><span class="line"><span class="comment"># é»˜è®¤ä½¿ç”¨è‡ªåŠ¨æ¨¡å¼ï¼Œæ ¹æ®è®¾å¤‡è‡ªåŠ¨é€‰æ‹©ç²¾åº¦</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;Qwen/Qwen-7B-Chat&quot;</span>, device_map=<span class="string">&quot;auto&quot;</span>, trust_remote_code=<span class="literal">True</span>).<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯æŒ‡å®šä¸åŒçš„ç”Ÿæˆé•¿åº¦ã€top_pç­‰ç›¸å…³è¶…å‚</span></span><br><span class="line">model.generation_config = GenerationConfig.from_pretrained(<span class="string">&quot;Qwen/Qwen-7B-Chat&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€è½®å¯¹è¯ 1st dialogue turn</span></span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">&quot;ä½ å¥½&quot;</span>, history=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="comment"># ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬äºŒè½®å¯¹è¯ 2nd dialogue turn</span></span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">&quot;ç»™æˆ‘è®²ä¸€ä¸ªå¹´è½»äººå¥‹æ–—åˆ›ä¸šæœ€ç»ˆå–å¾—æˆåŠŸçš„æ•…äº‹ã€‚&quot;</span>, history=history) </span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="comment"># è¿™æ˜¯ä¸€ä¸ªå…³äºä¸€ä¸ªå¹´è½»äººå¥‹æ–—åˆ›ä¸šæœ€ç»ˆå–å¾—æˆåŠŸçš„æ•…äº‹ã€‚</span></span><br><span class="line"><span class="comment"># æ•…äº‹çš„ä¸»äººå…¬å«ææ˜ï¼Œä»–æ¥è‡ªä¸€ä¸ªæ™®é€šçš„å®¶åº­ï¼Œçˆ¶æ¯éƒ½æ˜¯æ™®é€šçš„å·¥äººã€‚ä»å°ï¼Œææ˜å°±ç«‹ä¸‹äº†ä¸€ä¸ªç›®æ ‡ï¼šè¦æˆä¸ºä¸€åæˆåŠŸçš„ä¼ä¸šå®¶ã€‚</span></span><br><span class="line"><span class="comment"># ä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œææ˜å‹¤å¥‹å­¦ä¹ ï¼Œè€ƒä¸Šäº†å¤§å­¦ã€‚åœ¨å¤§å­¦æœŸé—´ï¼Œä»–ç§¯æå‚åŠ å„ç§åˆ›ä¸šæ¯”èµ›ï¼Œè·å¾—äº†ä¸å°‘å¥–é¡¹ã€‚ä»–è¿˜åˆ©ç”¨è¯¾ä½™æ—¶é—´å»å®ä¹ ï¼Œç§¯ç´¯äº†å®è´µçš„ç»éªŒã€‚</span></span><br><span class="line"><span class="comment"># æ¯•ä¸šåï¼Œææ˜å†³å®šå¼€å§‹è‡ªå·±çš„åˆ›ä¸šä¹‹è·¯ã€‚ä»–å¼€å§‹å¯»æ‰¾æŠ•èµ„æœºä¼šï¼Œä½†å¤šæ¬¡éƒ½è¢«æ‹’ç»äº†ã€‚ç„¶è€Œï¼Œä»–å¹¶æ²¡æœ‰æ”¾å¼ƒã€‚ä»–ç»§ç»­åŠªåŠ›ï¼Œä¸æ–­æ”¹è¿›è‡ªå·±çš„åˆ›ä¸šè®¡åˆ’ï¼Œå¹¶å¯»æ‰¾æ–°çš„æŠ•èµ„æœºä¼šã€‚</span></span><br><span class="line"><span class="comment"># æœ€ç»ˆï¼Œææ˜æˆåŠŸåœ°è·å¾—äº†ä¸€ç¬”æŠ•èµ„ï¼Œå¼€å§‹äº†è‡ªå·±çš„åˆ›ä¸šä¹‹è·¯ã€‚ä»–æˆç«‹äº†ä¸€å®¶ç§‘æŠ€å…¬å¸ï¼Œä¸“æ³¨äºå¼€å‘æ–°å‹è½¯ä»¶ã€‚åœ¨ä»–çš„é¢†å¯¼ä¸‹ï¼Œå…¬å¸è¿…é€Ÿå‘å±•èµ·æ¥ï¼Œæˆä¸ºäº†ä¸€å®¶æˆåŠŸçš„ç§‘æŠ€ä¼ä¸šã€‚</span></span><br><span class="line"><span class="comment"># ææ˜çš„æˆåŠŸå¹¶ä¸æ˜¯å¶ç„¶çš„ã€‚ä»–å‹¤å¥‹ã€åšéŸ§ã€å‹‡äºå†’é™©ï¼Œä¸æ–­å­¦ä¹ å’Œæ”¹è¿›è‡ªå·±ã€‚ä»–çš„æˆåŠŸä¹Ÿè¯æ˜äº†ï¼Œåªè¦åŠªåŠ›å¥‹æ–—ï¼Œä»»ä½•äººéƒ½æœ‰å¯èƒ½å–å¾—æˆåŠŸã€‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸‰è½®å¯¹è¯ 3rd dialogue turn</span></span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">&quot;ç»™è¿™ä¸ªæ•…äº‹èµ·ä¸€ä¸ªæ ‡é¢˜&quot;</span>, history=history)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="comment"># ã€Šå¥‹æ–—åˆ›ä¸šï¼šä¸€ä¸ªå¹´è½»äººçš„æˆåŠŸä¹‹è·¯ã€‹</span></span><br></pre></td></tr></table></figure>

<p>è¿è¡ŒQwen-7BåŒæ ·éå¸¸ç®€å•ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers.generation <span class="keyword">import</span> GenerationConfig</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;Qwen/Qwen-7B&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‰“å¼€bf16ç²¾åº¦ï¼ŒA100ã€H100ã€RTX3060ã€RTX3070ç­‰æ˜¾å¡å»ºè®®å¯ç”¨ä»¥èŠ‚çœæ˜¾å­˜</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, bf16=True).eval()</span></span><br><span class="line"><span class="comment"># æ‰“å¼€fp16ç²¾åº¦ï¼ŒV100ã€P100ã€T4ç­‰æ˜¾å¡å»ºè®®å¯ç”¨ä»¥èŠ‚çœæ˜¾å­˜</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, fp16=True).eval()</span></span><br><span class="line"><span class="comment"># ä½¿ç”¨CPUè¿›è¡Œæ¨ç†ï¼Œéœ€è¦çº¦32GBå†…å­˜</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;cpu&quot;, trust_remote_code=True).eval()</span></span><br><span class="line"><span class="comment"># é»˜è®¤ä½¿ç”¨è‡ªåŠ¨æ¨¡å¼ï¼Œæ ¹æ®è®¾å¤‡è‡ªåŠ¨é€‰æ‹©ç²¾åº¦</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;Qwen/Qwen-7B&quot;</span>, device_map=<span class="string">&quot;auto&quot;</span>, trust_remote_code=<span class="literal">True</span>).<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯æŒ‡å®šä¸åŒçš„ç”Ÿæˆé•¿åº¦ã€top_pç­‰ç›¸å…³è¶…å‚</span></span><br><span class="line">model.generation_config = GenerationConfig.from_pretrained(<span class="string">&quot;Qwen/Qwen-7B&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer(<span class="string">&#x27;è’™å¤å›½çš„é¦–éƒ½æ˜¯ä¹Œå…°å·´æ‰˜ï¼ˆUlaanbaatarï¼‰\nå†°å²›çš„é¦–éƒ½æ˜¯é›·å…‹é›…æœªå…‹ï¼ˆReykjavikï¼‰\nåŸƒå¡ä¿„æ¯”äºšçš„é¦–éƒ½æ˜¯&#x27;</span>, return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br><span class="line">inputs = inputs.to(model.device)</span><br><span class="line">pred = model.generate(**inputs)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(pred.cpu()[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># è’™å¤å›½çš„é¦–éƒ½æ˜¯ä¹Œå…°å·´æ‰˜ï¼ˆUlaanbaatarï¼‰\nå†°å²›çš„é¦–éƒ½æ˜¯é›·å…‹é›…æœªå…‹ï¼ˆReykjavikï¼‰\nåŸƒå¡ä¿„æ¯”äºšçš„é¦–éƒ½æ˜¯äºšçš„æ–¯äºšè´å·´ï¼ˆAddis Ababaï¼‰...</span></span><br></pre></td></tr></table></figure>

<h5 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h5><blockquote>
<p>æ³¨ï¼šä½œä¸ºæœ¯è¯­çš„â€œtokenizationâ€åœ¨ä¸­æ–‡ä¸­å°šæ— å…±è¯†çš„æ¦‚å¿µå¯¹åº”ï¼Œæœ¬æ–‡æ¡£é‡‡ç”¨è‹±æ–‡è¡¨è¾¾ä»¥åˆ©è¯´æ˜ã€‚</p>
</blockquote>
<p>åŸºäºtiktokençš„tokenizeræœ‰åˆ«äºå…¶ä»–åˆ†è¯å™¨ï¼Œæ¯”å¦‚sentencepiece tokenizerã€‚å°¤å…¶åœ¨å¾®è°ƒé˜¶æ®µï¼Œéœ€è¦ç‰¹åˆ«æ³¨æ„ç‰¹æ®Štokençš„ä½¿ç”¨ã€‚å…³äºtokenizerçš„æ›´å¤šä¿¡æ¯ï¼Œä»¥åŠå¾®è°ƒæ—¶æ¶‰åŠçš„ç›¸å…³ä½¿ç”¨ï¼Œè¯·å‚é˜…<a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-7B/blob/main/tokenization_note_zh.md">æ–‡æ¡£</a>ã€‚</p>
<p>Qwen-7Bé‡‡ç”¨**<u>UTF-8å­—èŠ‚çº§åˆ«çš„BPE tokenizationæ–¹å¼</u>**ï¼Œå¹¶ä¾èµ–<code>tiktoken</code>è¿™ä¸€é«˜æ•ˆçš„è½¯ä»¶åŒ…æ‰§è¡Œåˆ†è¯ã€‚ Qwen-7Bä¸­æœ‰ä¸¤ç±»tokenï¼Œå³æºäºBPEã€<code>bytes</code>ç±»å‹çš„æ™®é€štokenå’Œç‰¹æ®ŠæŒ‡å®šã€<code>str</code>ç±»å‹çš„ç‰¹æ®Štokenã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&#x27;Qwen/Qwen-7B&#x27;</span>, trust_remote_code=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h6 id="æ™®é€štoken"><a href="#æ™®é€štoken" class="headerlink" title="æ™®é€štoken"></a>æ™®é€štoken</h6><p>æ™®é€štokenæºäºBPEï¼Œæ˜¯åœ¨UTF-8ç¼–ç çš„æ–‡æœ¬å­—èŠ‚åºåˆ—ä¸Šå­¦ä¹ å¾—åˆ°çš„ã€‚ å°½ç®¡åŸºäºå­—èŠ‚åºåˆ—çš„æ–¹å¼ä¿è¯äº†æ‰€æœ‰æ–‡æœ¬å‡å¯è¢«tokenizeä¸”æ²¡æœ‰æœªç™»å½•tokené—®é¢˜ï¼Œä½†å¤„ç†ç½•è§æ–‡æœ¬æ—¶æœ‰å¯èƒ½å›é€€åˆ°å­—èŠ‚çº§åˆ«çš„ç¼–ç ã€‚ ç”±äºä»å­—èŠ‚åºåˆ—è§£ç ä¸ºæ–‡æœ¬æ—¶ï¼Œ<code>errors</code>å‚æ•°è®¾ä¸º<code>replace</code>ï¼Œå¤„ç†ä¸å®Œæ•´çš„tokenåºåˆ—å¯èƒ½ä¼šé‡åˆ°UTF-8è§£ç é”™è¯¯ï¼Œè¡¨è±¡æ˜¯ç”Ÿæˆä¸­åŒ…å«â€œæ›¿æ¢å­—ç¬¦â€(ï¿½)ã€‚ **<u>è¿™ä¸€è¡Œä¸ºå¯ä»¥é€šè¿‡å°†<code>errors</code>å‚æ•°è®¾ä¸º<code>ignore</code>æ¥è§„é¿</u>**ã€‚ ä¸€æ¬¡æ€§ä¿®æ”¹å¯ä»¥ä¼ å…¥tokenizerçš„<code>decode</code>å‡½æ•°ï¼ŒæŒä¹…æ€§ä¿®æ”¹å¯ä»¥ä¼ å…¥tokenizerçš„åˆå§‹åŒ–å‡½æ•°ï¼Œè¯·æ³¨æ„<code>decode</code>çš„é…ç½®ä¼˜å…ˆçº§æ›´é«˜ã€‚ <code>errors</code>çš„å¯é€‰å€¼ï¼Œè¯·å‚é˜…<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#bytes.decode">Pythonæ–‡æ¡£</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer.decode([<span class="number">51461</span>])</span><br><span class="line"><span class="string">&#x27; ï¿½&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer.convert_ids_to_tokens([<span class="number">51461</span>])</span><br><span class="line">[<span class="string">b&#x27; \xe6\xa0&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">b&#x27; \xe6\xa0&#x27;</span>.decode(<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&#x27;replace&#x27;</span>)</span><br><span class="line"><span class="string">&#x27; ï¿½&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer.decode([<span class="number">51461</span>, <span class="number">117</span>])</span><br><span class="line"><span class="string">&#x27; æ ¹&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer.convert_ids_to_tokens([<span class="number">51461</span>, <span class="number">117</span>])</span><br><span class="line">[<span class="string">b&#x27; \xe6\xa0&#x27;</span>, <span class="string">b&#x27;\xb9&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">b&#x27; \xe6\xa0\xb9&#x27;</span>.decode(<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&#x27;replace&#x27;</span>)</span><br><span class="line"><span class="string">&#x27; æ ¹&#x27;</span></span><br></pre></td></tr></table></figure>

<p><code>bytes</code>ç±»å‹çš„æ™®é€štokenåˆ°idçš„æ˜ å°„å¯ä»¥é€šè¿‡<code>tokenizer.get_vocab()</code>è·å–ã€‚ å°šä¸æ”¯æŒä¹Ÿä¸æ¨èå‘tokenizerå¢åŠ æ™®é€štokenã€‚</p>
<h6 id="ç‰¹æ®Štoken"><a href="#ç‰¹æ®Štoken" class="headerlink" title="ç‰¹æ®Štoken"></a>ç‰¹æ®Štoken</h6><p>ç‰¹æ®Štokenç”¨ä»¥ç»™æ¨¡å‹ä¼ é€’ç‰¹æ®Šä¿¡å·ï¼Œå¦‚åˆ°è¾¾æ–‡æœ¬æœ«å°¾ã€‚ ç†è®ºä¸Šï¼Œè¾“å…¥æ–‡æœ¬ä¸­ä¸åŒ…å«ç‰¹æ®Štokenï¼Œå®ƒä»¬ä»…åœ¨tokenizationåç”±å¼€å‘è€…æ‰‹åŠ¨åŠ å…¥ã€‚ ç‰¹æ®Štokençš„å­—é¢è¡¨è¾¾ï¼Œå¦‚è¡¨ç¤ºæ–‡æœ¬ç»“æŸçš„<code>&lt;|endoftext|&gt;</code>ï¼Œä»…ä¾¿äºæŒ‡ä»£ç‰¹æ®Štokenï¼Œä¸æ„å‘³ç€å®ƒä»¬åœ¨è¾“å…¥æ–‡æœ¬ç©ºé—´ä¸­ã€‚ ç›®å‰ï¼Œè®­ç»ƒä¸­ä½¿ç”¨çš„ã€å·²ç»æœ‰å›ºå®šå«ä¹‰çš„ã€ä¸åº”åšå®ƒç”¨çš„ç‰¹æ®Štokenï¼ŒQwen-7Bä¸­æœ‰<code>&lt;|endoftext|&gt;</code>ï¼ŒQwen-7B-Chatä¸­æœ‰<code>&lt;|endoftext|&gt;</code>ã€<code>&lt;|im_start|&gt;</code>ä»¥åŠ<code>&lt;|im_end|&gt;</code>ã€‚ ä½†è¯è¡¨ä¸­ä¹Ÿç•™æœ‰ä¾›æ‰©å±•çš„ç‰¹æ®Štokenä½ï¼Œå¯ç”¨<code>&lt;|extra_0|&gt;</code>åˆ°<code>&lt;|extra_204|&gt;</code>æ¥æŒ‡ä»£ã€‚ <code>str</code>ç±»å‹çš„ç‰¹æ®Štokenå­—é¢è¡¨è¾¾åˆ°idçš„æ˜ å°„ï¼Œå¯ä»¥é€šè¿‡<code>tokenizer.special_tokens</code>è·å–ã€‚</p>
<p>å¯¹äºæä¾›çš„æ¨¡å‹å‚æ•°(Qwen-7Bå’ŒQwen-7B-Chat)è€Œè¨€ï¼Œè¯¸å¦‚<code>bos</code>ã€<code>eos</code>ã€<code>unk</code>ã€<code>pad</code>ã€<code>mask</code>ã€<code>sep</code>ç­‰çš„ç‰¹æ®Štokençš„æ¦‚å¿µå¹¶ä¸é€‚ç”¨ã€‚ ç‰¹ä¾‹æ˜¯<code>pad</code>ï¼Œç”±äºè¿™ä¸ªtokenç†è®ºä¸Šå¹¶ä¸å‚ä¸æ¨¡å‹è®¡ç®—ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨ä»»æ„tokenè¡¨è¾¾è¿™ä¸€æ¦‚å¿µã€‚ ä½†ä¿é™©èµ·è§ï¼Œç›®å‰å¯åœ¨tokenizeråˆå§‹åŒ–æ—¶è®¾å®šçš„ç‰¹æ®Štokenï¼Œä»…å¯ä½¿ç”¨å·²çŸ¥çš„ç‰¹æ®Štokenå­—é¢è¡¨è¾¾ï¼Œå³<code>&lt;|endoftext|&gt;</code>ã€<code>&lt;|im_start|&gt;</code>ã€<code>&lt;|im_end|&gt;</code>å’Œ<code>&lt;|extra_0|&gt;</code>åˆ°<code>&lt;|extra_204|&gt;</code>ã€‚ å¯¹äºå¾®è°ƒæˆ–è€…å…¶å®ƒéœ€è¦è¿™äº›tokenæ‰èƒ½è¿è¡Œçš„æ¡†æ¶ï¼Œå¯ä»¥å¦‚ä¸‹é…ç½®</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&#x27;Qwen/Qwen-7B&#x27;</span>, trust_remote_code=<span class="literal">True</span>, pad_token=<span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>æ³¨æ„: å¯¹äºæä¾›çš„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè®¾ç½®è¯¸å¦‚<code>bos</code>ã€<code>eos</code>ã€<code>unk</code>ä¹‹ç±»çš„æ²¡æœ‰æ„ä¹‰ï¼Œå³æ¨¡å‹ä¸éœ€è¦è¿™äº›æ¦‚å¿µã€‚ å¦‚æœè®¾ç½®äº†è¿™äº›tokenï¼Œä½†æ²¡æœ‰ç›¸åº”çš„å¾®è°ƒè¿™äº›tokenä»¥è®©æ¨¡å‹ç†è§£å…¶å«ä¹‰ï¼ŒæœªçŸ¥è¡Œä¸ºå¯èƒ½è¢«è§¦å‘ã€‚ ç‰¹åˆ«æ—¶ï¼Œä¸åº”æ··æ·†<code>&lt;|endoftext|&gt;</code>å’Œ<code>eos</code>çš„æ¦‚å¿µï¼Œé™¤éåº”ç”¨åœºæ™¯ä¸­å®ƒä»¬çš„å®é™…å«ä¹‰æ˜¯ä¸€è‡´çš„ï¼Œå³å¥å­æœ«å°¾ç­‰ä»·äºæ–‡æœ¬æœ«å°¾ã€‚</p>
</blockquote>
<p><strong>æ³¨å…¥æ”»å‡»é˜²å¾¡</strong></p>
<p>ç”±äºç‰¹æ®Štokenå’Œæ™®é€štokenæ¦‚å¿µä¸Šçš„å·®å¼‚ï¼Œå¦‚æœè¾“å…¥æ–‡æœ¬ä¸­å«æœ‰ç‰¹æ®Štokençš„å­—é¢è¡¨è¾¾è¯¥å¦‚ä½•å¤„ç†ï¼Ÿ ä»¥ä¸‹é¢æ–‡æœ¬ä¸ºä¾‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>å…¶æ­£ç¡®çš„tokenizationä¸º</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ids:[<span class="number">1350</span>, <span class="number">9639</span>, <span class="number">91</span>, <span class="number">8691</span>, <span class="number">723</span>, <span class="number">427</span>, <span class="number">91</span>, <span class="number">82598</span>]</span><br><span class="line">tokens: [<span class="string">b&#x27;print&#x27;</span>, <span class="string">b&#x27;(&quot;&lt;&#x27;</span>, <span class="string">b&#x27;|&#x27;</span>, <span class="string">b&#x27;endo&#x27;</span>, <span class="string">b&#x27;ft&#x27;</span>, <span class="string">b&#x27;ext&#x27;</span>, <span class="string">b&#x27;|&#x27;</span>, <span class="string">b&#x27;&gt;&quot;)&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>ä¸æ˜¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ids: [<span class="number">1350</span>, <span class="number">445</span>, <span class="number">151643</span>, <span class="number">899</span>]</span><br><span class="line">tokens: [<span class="string">b&#x27;print&#x27;</span>, <span class="string">b&#x27;(&quot;&#x27;</span>, <span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>, <span class="string">b&#x27;&quot;)&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>é»˜è®¤è¡Œä¸ºæ›¾æ˜¯æ­£ç¡®çš„ï¼Œå³è¾“å…¥æ–‡æœ¬ä¸­ä»»ä½•å­—ç¬¦ä¸€å¾‹æŒ‰æ™®é€štokenå¤„ç†ï¼Œç‰¹æ®Štokenåº”ç”±å¼€å‘è€…åœ¨tokenizationäººå·¥å¤„ç†ã€‚ ç„¶åï¼Œè¿™ä¸ç¤¾åŒºä¸­çš„å®è·µä¼¼æœ‰å·®å¼‚ï¼Œä¸ºå¼€å‘è€…å¤ç”¨ä»£ç å¢åŠ äº†é¢å¤–é€‚é…æ­¥éª¤ã€‚</p>
<p>é»˜è®¤è¡Œä¸ºå·²è¢«è°ƒæ•´ä¸ºä»è¾“å…¥æ–‡æœ¬ä¸­è§£æç‰¹æ®Štokençš„å­—é¢è¡¨è¾¾ã€‚ å¦‚éœ€å¯ç”¨æ³¨å…¥æ”»å‡»é˜²å¾¡ï¼Œè¯·ä¼ å…¥å‚æ•°<code>allowed_special=set()</code>ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer(<span class="string">&#x27;print(&quot;&lt;|endoftext|&gt;&quot;)&#x27;</span>, allowed_special=<span class="built_in">set</span>())</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [<span class="number">1350</span>, <span class="number">9639</span>, <span class="number">91</span>, <span class="number">8691</span>, <span class="number">723</span>, <span class="number">427</span>, <span class="number">91</span>, <span class="number">82598</span>], <span class="string">&#x27;token_type_ids&#x27;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="string">&#x27;attention_mask&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>è¿™ä¸€è¡Œä¸ºå¯ä»¥æ›´ç²¾ç»†çš„è°ƒæ§ï¼Œå°†<code>allowed_special</code>è®¾è®¡ä¸º<code>str</code>çš„é›†åˆå³å¯ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer(<span class="string">&#x27;print(&quot;&lt;|extra_0|&gt;&quot;)&lt;|endoftext|&gt;&#x27;</span>, allowed_special=&#123;<span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>&#125;)</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [<span class="number">1350</span>, <span class="number">9639</span>, <span class="number">91</span>, <span class="number">15460</span>, <span class="number">62</span>, <span class="number">15</span>, <span class="number">91</span>, <span class="number">82598</span>, <span class="number">151643</span>], <span class="string">&#x27;token_type_ids&#x27;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="string">&#x27;attention_mask&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>å¦‚æœå¸Œæœ›è¾“å…¥ä¸­é‡åˆ°ç‰¹æ®Štokençš„å­—é¢è¡¨è¾¾æ—¶ï¼Œè·å¾—æ›´ç›´æ¥çš„æé†’ï¼Œé€šè¿‡é…ç½®<code>disallowed_special</code>å¯ä»¥è®©tokenizerç›´æ¥è§¦å‘å¼‚å¸¸ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer(<span class="string">&#x27;print(&quot;&lt;|extra_0|&gt;&quot;)&lt;|endoftext|&gt;&#x27;</span>, allowed_special=&#123;<span class="string">&#x27;&lt;|endoftext|&gt;&#x27;</span>&#125;, disallowed_special=(<span class="string">&#x27;&lt;|extra_0|&gt;&#x27;</span>, ))</span><br><span class="line">...</span><br><span class="line">ValueError: Encountered text corresponding to disallowed special token <span class="string">&#x27;&lt;|extra_0|&gt;&#x27;</span>.</span><br><span class="line">If you want this text to be encoded <span class="keyword">as</span> a special token, <span class="keyword">pass</span> it to `allowed_special`, e.g. `allowed_special=&#123;<span class="string">&#x27;&lt;|extra_0|&gt;&#x27;</span>, ...&#125;`.</span><br><span class="line">If you want this text to be encoded <span class="keyword">as</span> normal text, disable the check <span class="keyword">for</span> this token by passing `disallowed_special=(enc.special_tokens_set - &#123;<span class="string">&#x27;&lt;|extra_0|&gt;&#x27;</span>&#125;)`.</span><br><span class="line">To disable this check <span class="keyword">for</span> <span class="built_in">all</span> special tokens, <span class="keyword">pass</span> `disallowed_special=()`.</span><br></pre></td></tr></table></figure>

<p>æ›´å¤šå…³äº<code>allowed_special</code>å’Œ<code>disallowed_special</code>çš„ä¿¡æ¯, è¯·å‚é˜…<a target="_blank" rel="noopener" href="https://github.com/openai/tiktoken/blob/095924e02c85617df6889698d94515f91666c7ea/tiktoken/core.py#L75"><code>tiktoken</code>ä»£ç </a>.</p>
<p>æ–°çš„é»˜è®¤è¡Œä¸ºä¸ä»¥ä¸‹è®¾å®šç­‰ä»·</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokenizer(<span class="string">&#x27;print(&quot;&lt;|endoftext|&gt;&quot;)&#x27;</span>, allowed_special=<span class="string">&quot;all&quot;</span>, disallowed_special=())</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [<span class="number">1350</span>, <span class="number">445</span>, <span class="number">151643</span>, <span class="number">899</span>], <span class="string">&#x27;token_type_ids&#x27;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="string">&#x27;attention_mask&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]&#125;</span><br></pre></td></tr></table></figure>

<h5 id="é‡åŒ–"><a href="#é‡åŒ–" class="headerlink" title="é‡åŒ–"></a>é‡åŒ–</h5><p>å¦‚å¸Œæœ›ä½¿ç”¨æ›´ä½ç²¾åº¦çš„é‡åŒ–æ¨¡å‹ï¼Œå¦‚4æ¯”ç‰¹å’Œ8æ¯”ç‰¹çš„æ¨¡å‹ï¼Œæˆ‘ä»¬æä¾›äº†ç®€å•çš„ç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•å¿«é€Ÿä½¿ç”¨é‡åŒ–æ¨¡å‹ã€‚åœ¨å¼€å§‹å‰ï¼Œç¡®ä¿ä½ å·²ç»å®‰è£…äº†<code>bitsandbytes</code>ã€‚è¯·æ³¨æ„ï¼Œ<code>bitsandbytes</code>çš„å®‰è£…è¦æ±‚æ˜¯ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">**Requirements** Python &gt;=3.8. Linux distribution (Ubuntu, MacOS, etc.) + CUDA &gt; 10.0.</span><br></pre></td></tr></table></figure>

<p>Windowsç”¨æˆ·éœ€å®‰è£…ç‰¹å®šç‰ˆæœ¬çš„<code>bitsandbytes</code>ï¼Œå¯é€‰é¡¹åŒ…æ‹¬<a target="_blank" rel="noopener" href="https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels">bitsandbytes-windows-webui</a>ã€‚</p>
<p>ä½ åªéœ€è¦åœ¨<code>AutoModelForCausalLM.from_pretrained</code>ä¸­æ·»åŠ ä½ çš„é‡åŒ–é…ç½®ï¼Œå³å¯ä½¿ç”¨é‡åŒ–æ¨¡å‹ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, BitsAndBytesConfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># quantization configuration for NF4 (4 bits)</span></span><br><span class="line">quantization_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&#x27;nf4&#x27;</span>,</span><br><span class="line">    bnb_4bit_compute_dtype=torch.bfloat16</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># quantization configuration for Int8 (8 bits)</span></span><br><span class="line">quantization_config = BitsAndBytesConfig(load_in_8bit=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    args.checkpoint_path,</span><br><span class="line">    device_map=<span class="string">&quot;cuda:0&quot;</span>,</span><br><span class="line">    quantization_config=quantization_config,</span><br><span class="line">    max_memory=max_memory,</span><br><span class="line">    trust_remote_code=<span class="literal">True</span>,</span><br><span class="line">).<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>

<p>ä¸Šè¿°æ–¹æ³•å¯ä»¥è®©æˆ‘ä»¬å°†æ¨¡å‹é‡åŒ–æˆ<code>NF4</code>å’Œ<code>Int8</code>ç²¾åº¦çš„æ¨¡å‹è¿›è¡Œè¯»å–ï¼Œå¸®åŠ©æˆ‘ä»¬èŠ‚çœæ˜¾å­˜å¼€é”€ã€‚æˆ‘ä»¬ä¹Ÿæä¾›äº†ç›¸å…³æ€§èƒ½æ•°æ®ã€‚æˆ‘ä»¬å‘ç°å°½ç®¡æ¨¡å‹åœ¨æ•ˆæœä¸Šå­˜åœ¨æŸå¤±ï¼Œä½†æ¨¡å‹çš„æ˜¾å­˜å¼€é”€å¤§å¹…é™ä½ã€‚</p>
<table>
<thead>
<tr>
<th>Precision</th>
<th>MMLU</th>
<th>Memory</th>
</tr>
</thead>
<tbody><tr>
<td>BF16</td>
<td>56.7</td>
<td>16.2G</td>
</tr>
<tr>
<td>Int8</td>
<td>52.8</td>
<td>10.1G</td>
</tr>
<tr>
<td>NF4</td>
<td>48.9</td>
<td>7.4G</td>
</tr>
</tbody></table>
<h5 id="å·¥å…·è°ƒç”¨"><a href="#å·¥å…·è°ƒç”¨" class="headerlink" title="å·¥å…·è°ƒç”¨"></a>å·¥å…·è°ƒç”¨</h5><p>Qwen-7B-Chaté’ˆå¯¹åŒ…æ‹¬APIã€æ•°æ®åº“ã€æ¨¡å‹ç­‰å·¥å…·åœ¨å†…çš„è°ƒç”¨è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç”¨æˆ·å¯ä»¥å¼€å‘åŸºäºQwen-7Bçš„LangChainã€Agentç”šè‡³Code Interpreterã€‚æˆ‘ä»¬åœ¨å†…éƒ¨çš„å³å°†å¼€æºçš„è¯„æµ‹æ•°æ®é›†ä¸Šæµ‹è¯•æ¨¡å‹çš„å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå¹¶å‘ç°Qwen-7B-Chatèƒ½å¤Ÿå–å¾—ç¨³å®šçš„è¡¨ç°ã€‚</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Tool Selection (Acc.â†‘)</th>
<th>Tool Input (Rouge-Lâ†‘)</th>
<th>False Positive Errorâ†“</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4</td>
<td>95%</td>
<td><strong>0.90</strong></td>
<td>15%</td>
</tr>
<tr>
<td>GPT-3.5</td>
<td>85%</td>
<td>0.88</td>
<td>75%</td>
</tr>
<tr>
<td><strong>Qwen-7B</strong></td>
<td><strong>99%</strong></td>
<td>0.89</td>
<td><strong>8.5%</strong></td>
</tr>
</tbody></table>
<p>æˆ‘ä»¬æä¾›äº†æ–‡æ¡£è¯´æ˜å¦‚ä½•æ ¹æ®ReAct Promptingçš„åŸåˆ™å†™ä½œä½ çš„promptã€‚</p>
<p>For how to write and use prompts for ReAct Prompting, please refer to <a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-7B/blob/main/examples/react_prompt.md">the ReAct examples</a>ã€‚</p>
<p>æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†å®éªŒç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ¨¡å‹æ‰®æ¼”Agentçš„èƒ½åŠ›ã€‚è¯·é˜…è¯»ç›¸å…³æ–‡æ¡£<a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/transformers_agents">é“¾æ¥</a>äº†è§£æ›´å¤šä¿¡æ¯ã€‚æ¨¡å‹åœ¨Hugging Faceæä¾›çš„è¯„æµ‹æ•°æ®é›†ä¸Šè¡¨ç°å¦‚ä¸‹ï¼š</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Tool Selectionâ†‘</th>
<th>Tool Usedâ†‘</th>
<th>Codeâ†‘</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-4</td>
<td><strong>100</strong></td>
<td><strong>100</strong></td>
<td><strong>97.41</strong></td>
</tr>
<tr>
<td>GPT-3.5</td>
<td>95.37</td>
<td>96.30</td>
<td>87.04</td>
</tr>
<tr>
<td>StarCoder-15.5B</td>
<td>87.04</td>
<td>87.96</td>
<td>68.89</td>
</tr>
<tr>
<td><strong>Qwen-7B</strong></td>
<td>90.74</td>
<td>92.59</td>
<td>74.07</td>
</tr>
</tbody></table>
<h5 id="é•¿æ–‡æœ¬ç†è§£"><a href="#é•¿æ–‡æœ¬ç†è§£" class="headerlink" title="é•¿æ–‡æœ¬ç†è§£"></a>é•¿æ–‡æœ¬ç†è§£</h5><p>æˆ‘ä»¬å¼•å…¥äº†**<u><em>NTKæ’å€¼ã€çª—å£æ³¨æ„åŠ›ã€LogNæ³¨æ„åŠ›ç¼©æ”¾</em></u>**ç­‰æŠ€æœ¯æ¥æå‡æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦å¹¶çªç ´è®­ç»ƒåºåˆ—é•¿åº¦çš„é™åˆ¶ã€‚æˆ‘ä»¬çš„æ¨¡å‹å·²ç»çªç ´8Kçš„åºåˆ—é•¿åº¦ã€‚é€šè¿‡arXivæ•°æ®é›†ä¸Šçš„è¯­è¨€æ¨¡å‹å®éªŒï¼ˆPPLï¼‰ï¼Œæˆ‘ä»¬å‘ç°Qwen-7Bèƒ½å¤Ÿåœ¨é•¿åºåˆ—çš„è®¾ç½®ä¸‹å–å¾—ä¸é”™çš„è¡¨ç°ã€‚</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Sequence Length</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1024</td>
<td>2048</td>
<td>4096</td>
<td>8192</td>
<td>16384</td>
<td></td>
</tr>
<tr>
<td>Qwen-7B</td>
<td><strong>4.23</strong></td>
<td><strong>3.78</strong></td>
<td>39.35</td>
<td>469.81</td>
<td>2645.09</td>
</tr>
<tr>
<td>+ dynamic_ntk</td>
<td><strong>4.23</strong></td>
<td><strong>3.78</strong></td>
<td>3.59</td>
<td>3.66</td>
<td>5.71</td>
</tr>
<tr>
<td>+ dynamic_ntk + logn</td>
<td><strong>4.23</strong></td>
<td><strong>3.78</strong></td>
<td><strong>3.58</strong></td>
<td>3.56</td>
<td>4.62</td>
</tr>
<tr>
<td>+ dynamic_ntk + logn + local_attn</td>
<td><strong>4.23</strong></td>
<td><strong>3.78</strong></td>
<td><strong>3.58</strong></td>
<td><strong>3.49</strong></td>
<td><strong>4.32</strong></td>
</tr>
</tbody></table>
<h4 id="QWenå¾®è°ƒæ–¹æ¡ˆ"><a href="#QWenå¾®è°ƒæ–¹æ¡ˆ" class="headerlink" title="QWenå¾®è°ƒæ–¹æ¡ˆ"></a>QWenå¾®è°ƒæ–¹æ¡ˆ</h4><p>ã€1ã€‘ModelScope ç‰ˆæœ¬ <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/z5JNbKOjYV6vkqK6KyrSQg">https://mp.weixin.qq.com/s/z5JNbKOjYV6vkqK6KyrSQg</a></p>
<ol>
<li><strong>ç¯å¢ƒå‡†å¤‡</strong></li>
</ol>
<p><strong>ç¡¬ä»¶é…ç½®å»ºè®®</strong></p>
<ul>
<li>å¤„ç†å™¨ï¼šæ¨èä½¿ç”¨ç¬¬ 12 ä»£ Intel Core i7 æˆ–æ›´é«˜é…ç½®</li>
<li>å†…å­˜ï¼šå»ºè®® 48GB ä»¥ä¸Šï¼ˆå°½ç®¡ 16GB ä¹Ÿå¯ä»¥ï¼Œä½†åŠ è½½æ¨¡å‹é€Ÿåº¦è¾ƒæ…¢ï¼‰</li>
<li>æ˜¾å¡ï¼šæ¨èä½¿ç”¨ NVIDIA GeForce RTX 3080 æˆ–æ›´é«˜é…ç½®ï¼Œæ˜¾å­˜ 24GB ä»¥ä¸Šã€‚ï¼ˆç”±äºç›®å‰æ¡†æ¶ä¼¼ä¹è¿˜æ²¡æœ‰çœ‹åˆ°æ¨ç†åŠ é€Ÿï¼Œæ‰€ä»¥ï¼Œ24GBæˆ–è€…ä»¥ä¸Šæ˜¯éœ€è¦çš„ã€‚ï¼‰</li>
</ul>
<p><strong>éƒ¨ç½²ç¯å¢ƒ</strong></p>
<p>ä½¿ç”¨ nvidia-docker éƒ¨ç½²æœ€æ–°çš„ pytorchä»¥åŠmodelscopeï¼Œåˆ‡è®°ä¸è¦ä½¿ç”¨çœŸå®ç¯å¢ƒï¼Œä¸€æ—¦å‡ºç°åŒ…å­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´å›æ»šä¼šéå¸¸æµªè´¹æ—¶é—´ã€‚</p>
<p>ä¾æ¬¡æ£€éªŒï¼šnvidia-smi,pytorch,ä»¥åŠmodelscope </p>
<p>æŸ¥çœ‹ç¯å¢ƒæ˜¯å¦éƒ¨ç½²å¥½ï¼šnvidia-smi</p>
<p>æŸ¥çœ‹æ˜¾å¡æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸è¯†åˆ« : pytorch</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.get_device_name(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>æŸ¥çœ‹modelscopeçš„ç‰ˆæœ¬ æ˜¯å¦&gt;1.8.1 : pip list | grep modelscope </p>
<p><strong>2. æ¨¡å‹å‡†å¤‡</strong></p>
<ol>
<li><strong>ä¸‹è½½æ¨¡å‹ ï¼Œæ‰§è¡Œå¦‚ä¸‹ä»£ç ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½, åˆ‡è®°æ¨¡å‹çš„IDæ˜¯</strong> Qwen&#x2F;Qwen-7b ã€ä¸‹è½½å®Œåä¼šåœ¨ &#x2F;root&#x2F;.cache&#x2F;modelscope&#x2F;hub&#x2F;Qwen&#x2F;Qwen-7b çœ‹åˆ°æ¨¡å‹ã€‘</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from modelscope.hub.snapshot_download import snapshot_download</span><br><span class="line">model_dir = snapshot_download(&#x27;Qwen/Qwen-7b&#x27;, &#x27;v1.0.0&#x27;)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p><strong>ä¸‹è½½è®­ç»ƒè„šæœ¬</strong></p>
<p>ä¸‹è½½ <a target="_blank" rel="noopener" href="https://github.com/modelscope/swift">https://github.com/modelscope/swift</a></p>
<p>æ‰¾åˆ° examples&#x2F;pytorch&#x2F;llm&#x2F; , é‡Œé¢çš„run_sft.sh æ˜¯è®­ç»ƒæ–‡ä»¶ï¼Œrun_infer.sh æ˜¯æ¨ç†æ–‡ä»¶</p>
</li>
<li><p><strong>é¢„åŠ è½½è®­ç»ƒæ•°æ®</strong></p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 \</span><br><span class="line">python llm_sft.py \</span><br><span class="line">    --model_type qwen-7b \</span><br><span class="line">    --sft_type lora \</span><br><span class="line">    --output_dir runs \</span><br><span class="line">    --dataset alpaca-en,alpaca-zh \</span><br><span class="line">    --dataset_sample 20000 \</span><br><span class="line">    --max_length 1024 \</span><br><span class="line">    --quantization_bit 4 \</span><br><span class="line">    --lora_rank 8 \</span><br><span class="line">    --lora_alpha 32 \</span><br><span class="line">    --lora_dropout_p 0.1 \</span><br><span class="line">    --batch_size 1 \</span><br><span class="line">    --learning_rate 1e-4 \</span><br><span class="line">    --gradient_accumulation_steps 16 \</span><br><span class="line">    --eval_steps 100 \</span><br><span class="line">    --save_steps 100 \</span><br><span class="line">    --save_total_limit 2 \</span><br><span class="line">    --logging_steps 10 \</span><br></pre></td></tr></table></figure>

<p>çœ‹äº†ä¸€ä¸‹ä»£ç ï¼Œå¥½åƒä¿®æ”¹æ•°æ®çš„ç›®å½•æœ‰ç‚¹éº»çƒ¦ï¼Œä¹Ÿä¸çŸ¥é“æ•°æ®æ ¼å¼å’‹æ ·ï¼Œå…ˆç›´æ¥æ‰§è¡Œ PYTHONPATH&#x3D;..&#x2F;..&#x2F;.. bash run_sft.sh ï¼Œé¢„å…ˆåŠ è½½æ•°æ®çœ‹ä¸€ä¸‹ï¼Œçœ‹åˆ°æœ‰datasetsçš„æ–‡ä»¶ç›®å½•å‡ºæ¥åå¯ä»¥killæ‰</p>
<p>å¯ä»¥çœ‹åˆ° &#x2F;root&#x2F;.cache&#x2F;modelscope&#x2F;hub&#x2F;datasets&#x2F;AI-ModelScope&#x2F;  ä¿å­˜å¥½äº†è®­ç»ƒçš„æ•°æ®çœ‹ä¸€ä¸‹æ ¼å¼ï¼Œæ˜¯ç”± instruction,input ,outputä¸‰ä¸ªå­—æ®µçš„ç»„æˆçš„csvï¼Œé‚£æˆ‘ä»¬åªè¦æŒ‰ç…§è¿™ä¸ªæ ¼å¼å†™å…¥æ”¹æ•°æ®å³å¯æŠŠå¾®è°ƒæ›¿æ¢æˆæˆ‘ä»¬çš„æ•°æ®ã€‚</p>
<p>è‡³æ­¤ï¼Œæ¨¡å‹çš„å‡†å¤‡åŸºæœ¬å®Œæˆã€‚</p>
<ol start="3">
<li><strong>è®­ç»ƒæ•°æ®å‡†å¤‡</strong></li>
</ol>
<p>æœ¬æ¬¡çš„å¾®è°ƒä¾æ—§æ˜¯æ”¹å˜å¤§æ¨¡å‹çš„è‡ªæˆ‘è®¤çŸ¥ã€‚ç›´æ¥æ‹¿èµ·æ—§çš„æ•°æ®è·‘ï¼ŒæŠŠè¯¥æ•°æ®è½¬æ¢æˆCSVæ›¿æ¢æ‰&#x2F;root&#x2F;.cache&#x2F;modelscope&#x2F;hub&#x2F;datasets&#x2F;AI-ModelScope&#x2F;çš„alpaca-gpt4-data-zh</p>
<p>ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼ŒåªåŠ è½½å•ä¸ªæ•°æ®é›†ï¼Œå¢åŠ å¤šè½®çš„è®­ç»ƒæ¬¡æ•°ã€‚</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 \</span><br><span class="line">python llm_sft.py \</span><br><span class="line">    --model_type qwen-7b \</span><br><span class="line">    --sft_type lora \</span><br><span class="line">    --output_dir runs \</span><br><span class="line">    --dataset alpaca-zh \</span><br><span class="line">    --dataset_sample 20 \</span><br><span class="line">    --max_length 1024 \</span><br><span class="line">    --quantization_bit 4 \</span><br><span class="line">    --lora_rank 8 \</span><br><span class="line">    --lora_alpha 32 \</span><br><span class="line">    --lora_dropout_p 0.1 \</span><br><span class="line">    --batch_size 1 \</span><br><span class="line">    --learning_rate 1e-4 \</span><br><span class="line">    --gradient_accumulation_steps 16 \</span><br><span class="line">    --eval_steps 100 \</span><br><span class="line">    --save_steps 100 \</span><br><span class="line">    --save_total_limit 2 \</span><br><span class="line">    --logging_steps 10 \</span><br></pre></td></tr></table></figure>

<blockquote>
<p>æ³¨ï¼š</p>
<ol>
<li>ç¨‹åºä¼šæŒ‰ç…§åŠ è½½æ¨¡å‹ï¼ï¼ åŠ è½½è®­ç»ƒæ•°æ®ï¼ï¼ è®­ç»ƒï¼ï¼ ä¿å­˜åˆ° output_dir 4 ä¸ªæ­¥éª¤è¿›è¡Œã€‚å¯ä»¥æŸ¥çœ‹è‡ªå·±åœ¨å“ªä¸€ä¸ªæ­¥éª¤å‡ºé”™ï¼Œè¿›è¡Œä¿®æ”¹ã€‚</li>
<li>æ¯ä¸ªäººçš„ç¯å¢ƒä¸ä¸€æ ·ï¼Œè®­ç»ƒçš„æ—¶é—´ä¸ä¸€æ ·ï¼Œæˆ‘è¿™ä¸ªé…ç½®è®­ç»ƒçš„æ—¶é—´æ˜¯å¤§æ¦‚ 10 å‡ åˆ†é’Ÿå°±èµ°å®Œã€‚</li>
</ol>
</blockquote>
<ol start="4">
<li><strong>è®­ç»ƒç»“æœ</strong></li>
</ol>
<p>åå‡ åˆ†é’Ÿåï¼Œåœ¨ runæ–‡ä»¶å¤¹ä¸‹çœ‹åˆ°çœ‹åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œ ä¸€èˆ¬å–æœ€æ–°çš„ã€‚</p>
<p>ä¿®æ”¹run_infer.sh æŠŠckpt_diråªå‘æˆ‘ä»¬åˆšè®­ç»ƒå®Œçš„æ¨¡å‹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 \</span><br><span class="line">python llm_infer.py \</span><br><span class="line">    --model_type qwen-7b \</span><br><span class="line">    --ckpt_dir runs/qwen-7b\v1-20230807-002814\checkpoint-100 \</span><br><span class="line">    --eval_human true \</span><br><span class="line">    --dataset_sample 19 \</span><br><span class="line">    --max_new_tokens 1024 \</span><br><span class="line">    --temperature 0.9 \</span><br><span class="line">    --top_k 50 \</span><br><span class="line">    --top_p 0.9 \</span><br><span class="line">    --do_sample true \</span><br></pre></td></tr></table></figure>

<p>æ‰§è¡Œå¦‚ä¸‹ä»£ç  PYTHONPATH&#x3D;..&#x2F;..&#x2F;.. bash run_infer.sh ï¼Œæ·»åŠ å¾®è°ƒç»“æœï¼Œå¯åŠ¨æ¨¡å‹ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå¤§æ¨¡å‹çš„è®¤çŸ¥å·²ç»æ”¹å˜ã€‚</p>
<ol start="5">
<li><strong>ä¸€äº›é—®é¢˜å’Œæƒ³æ³•</strong></li>
</ol>
<blockquote>
<p><strong>1. å½“å‰swift è¿˜åœ¨è¿­ä»£ä¸­ï¼Œå¯èƒ½å­˜åœ¨ä¸ç¨³å®šçš„æƒ…å†µã€‚</strong></p>
<p>ä¾‹å¦‚5å·çš„ä»£ç èƒ½æ­£å¸¸åœ¨3090è·‘ï¼Œæœ€è¿‘æ›´æ–°çš„ä¸€ä¸ªç‰ˆæœ¬ä¼¼ä¹ä¸è¡Œäº†ï¼Œæˆ‘åˆä¼šé€€äº†ä¸€ä¸‹ã€‚</p>
<p>ä¾‹å¦‚åœ¨5å·çš„æ—¶å€™ï¼Œè¿˜ä¸æ”¯æŒé‡åŒ–ï¼Œ7å·çš„æ—¶å€™å·²ç»å¯ä»¥äº†ã€‚ å¤§å®¶å¦‚æœæ‰§è¡Œä¸ç¨³å®šçš„è¯ï¼Œå¯ä»¥å…ˆå›ºåŒ–ä¸€ä¸‹å¯ä»¥è·‘çš„ç‰ˆæœ¬æ…¢æ…¢ç­‰ä¼˜åŒ–ã€‚</p>
<p><strong>2.  å¾®è°ƒçš„æ•ˆæœå¾ˆå¥½ï¼Œæ²¡æœ‰å‡ºç°çŸ¥è¯†é—å¿˜çš„æƒ…å†µã€‚</strong></p>
<p><strong>3.  ç”±äºæ¡†æ¶å’Œllamaç±»ä¼¼ï¼ŒæœŸå¾…åç»­çš„åŠ é€Ÿæ–¹æ¡ˆä»¥åŠç”Ÿæ€å·¥å…·åŠ ä¸Šã€‚</strong></p>
</blockquote>
<p>ä»“åº“é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-7B/blob/main/tech_memo.md#introducing-qwen-7b-open-foundation-and-human-aligned-models-of-the-state-of-the-arts">https://github.com/QwenLM/Qwen-7B/blob/main/tech_memo.md#introducing-qwen-7b-open-foundation-and-human-aligned-models-of-the-state-of-the-arts</a></p>
<h3 id="InternLM"><a href="#InternLM" class="headerlink" title="InternLM"></a>InternLM</h3><h3 id="Baichuan"><a href="#Baichuan" class="headerlink" title="Baichuan"></a>Baichuan</h3><h4 id="latest-news"><a href="#latest-news" class="headerlink" title="latest news"></a><strong>latest news</strong></h4><p>ç™¾å·æ™ºèƒ½4æœˆ10æ—¥æˆç«‹åï¼Œ6æœˆ15æ—¥å‘å¸ƒäº†70äº¿å‚æ•°è§„æ¨¡å¼€æºæ¨¡å‹Baichuan-7Bï¼Œ7æœˆ11æ—¥å‘å¸ƒäº†130äº¿å‚æ•°è§„æ¨¡å¤§æ¨¡å‹Baichuan-13Bã€‚</p>
<p>2023å¹´8æœˆ8æ—¥ä¸‹åˆï¼Œç™¾å·æ™ºèƒ½å‘å¸ƒ530äº¿å‚æ•°è§„æ¨¡çš„é—­æºå¤§æ¨¡å‹Baichuan-53Bï¼Œè¿™æ˜¯ç™¾å·æ™ºèƒ½å‘å¸ƒçš„ç¬¬ä¸‰ä¸ªå¤§æ¨¡å‹ï¼Œä¸»è¦æœåŠ¡Bç«¯è¡Œä¸šï¼Œé¢„è®¡ä¸‹ä¸ªæœˆå°†ä¼šå¼€æ”¾APIç­‰ç›¸å…³ç»„ä»¶ã€‚ã€è¿™æ¬¡å¤§æ¨¡å‹çš„æ–‡ç§‘èƒ½åŠ›æ›´å¥½ï¼Œæ¯”å¦‚åœ¨ç†è§£å¤è¯—ã€ç”Ÿæˆæœ‰ä¸ªæ€§åŒ–é£æ ¼çš„æ–‡ç« ç­‰æ–¹é¢ã€‚ã€‘</p>
<p>èåˆäº†æ„å›¾ç†è§£ã€ä¿¡æ¯æ£€ç´¢ä»¥åŠå¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œåœ¨çŸ¥è¯†é—®ç­”ã€æ–‡æœ¬åˆ›ä½œé¢†åŸŸè¡¨ç°çªå‡º</p>
<blockquote>
<p>ç™¾å·æ™ºèƒ½æŠ€æœ¯è”åˆåˆ›å§‹äººé™ˆç‚œé¹ï¼š</p>
<p>é¦–å…ˆï¼Œåšå¤§æ¨¡å‹çš„ç¬¬ä¸€ä¸ªç¯èŠ‚æ˜¯æ•°æ®ä»å“ªæ¥ï¼Œä¸­æ–‡äº’è”ç½‘ç½‘é¡µä¸­çš„æ•°æ®é«˜è¾¾ä¸‡äº¿ã€ç™¾äº¿é‡çº§ï¼Œæœç‹—æ­¤å‰çš„æ•°æ®ç§¯ç´¯ï¼Œèƒ½è®©ä»–ä»¬çŸ¥é“å“ªé‡Œæœ‰å¥½çš„æ•°æ®ï¼Œå¹¶ä¸”å°†è¿™äº›æ•°æ®è¿›è¡Œæ”¶é›†ã€å¤„ç†ã€è¯†åˆ«ï¼Œåœ¨è¿™ä¸€é¢†åŸŸï¼Œç™¾å·æ™ºèƒ½ç›®å‰çš„å›¢é˜Ÿæœ‰å¾ˆå¼ºçš„æŠ€æœ¯ç§¯ç´¯å’Œæ–¹æ³•è®ºã€‚</p>
<p>åœ¨è‹±æ–‡æ•°æ®æ–¹é¢ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œä»–è¡¥å……é“ï¼Œæœç‹—åœ¨ç¿»è¯‘é¢†åŸŸçš„ç§¯ç´¯ä¹Ÿæœ‰å¾ˆå¤šã€‚</p>
<p>å…¶æ¬¡ï¼Œæ¨¡å‹æœ¬èº«çš„è®­ç»ƒï¼Œæ¨¡å‹çš„è®­ç»ƒæ˜¯ä¸€ä¸ªç›¸å¯¹å¤æ‚çš„ç³»ç»Ÿï¼Œé™ˆç‚œé¹è°ˆé“ï¼Œè¿™åŒ…æ‹¬**<u>æ•°æ®çš„è·å–ã€é€‰æ‹©ã€é…æ¯”ã€æ ‡æ³¨ï¼Œæ•°æ®å‡†å¤‡å¥½ä¹‹åæ¨¡å‹çš„è®­ç»ƒæ¡†æ¶</u><strong>ï¼Œ</strong><u>ç½‘ç»œçš„è¿è¥æ•ˆç‡å¦‚ä½•ç»„æˆæ¡†æ¶ï¼Œä¸åŒçš„ç®—æ³•å¦‚ä½•ç»„åˆï¼Œé€‰ç”¨ä»€ä¹ˆæ ·çš„ç½‘ç»œç»“æ„ç»Ÿé¢†è¿™äº›ï¼Œå¦‚ä½•è¯„ä»·è¿™ä¸ªäº‹æƒ…ï¼Œç®—æ³•çš„é€‰æ‹©ç­‰</u>**ã€‚ç™¾å·æ™ºèƒ½æ­¤å‰æ¨å‡ºçš„70äº¿å‚æ•°è§„æ¨¡å¤§æ¨¡å‹åœ¨å¹¶è¡Œç­–ç•¥æ–¹é¢åšçš„æ¯”è¾ƒå¥½ï¼Œæœ‰æŠ€æœ¯ç§¯ç´¯ã€‚</p>
<p>æœ€åï¼Œç™¾å·æ™ºèƒ½ç›®å‰çš„æŠ€æœ¯å›¢é˜Ÿæœ‰å¾ˆå¤šæ¥è‡ªå­—èŠ‚è·³åŠ¨ã€ç™¾åº¦ã€åä¸ºçš„æŠ€æœ¯äººæ‰ï¼Œä¹Ÿä½¿å¾—å…¶æŠ€æœ¯èƒ½åŠ›æ›´åŠ å¤šå…ƒã€‚</p>
<p>ç»¼ä¸Šï¼Œåœ¨æŠ€æœ¯å’Œäººæ‰çš„å…±åŒåŠ æŒä¸‹ï¼Œç™¾å·æ™ºèƒ½åœ¨å¤§æ¨¡å‹çš„ç ”å‘æ–¹é¢èµ°çš„æ¯”è¾ƒå¿«ã€‚</p>
</blockquote>
<h4 id="Baichuan-7B"><a href="#Baichuan-7B" class="headerlink" title="Baichuan-7B"></a>Baichuan-7B</h4><h4 id="Baichuan-53B"><a href="#Baichuan-53B" class="headerlink" title="Baichuan-53B"></a>Baichuan-53B</h4><p><strong>é¢„è®­ç»ƒæ•°æ®ï¼ˆç‰¹ç‚¹ï¼‰ï¼š</strong></p>
<p>â€“å…¨é¢çš„ä¸–ç•ŒçŸ¥è¯†ä½“ç³»</p>
<p>â€“ ç³»ç»Ÿçš„æ•°æ®è´¨é‡ä½“ç³»</p>
<p>â€“å¤šç²’åº¦çš„å¤§è§„æ¨¡èšç±»ç³»ç»Ÿ</p>
<p>â€“ç»†ç²’åº¦è‡ªåŠ¨åŒ–åŒ¹é…ç®—æ³•</p>
<p>**<u>æœç´¢å¢å¼ºæ˜¯è§£å†³æ¨¡å‹æ—¶æ•ˆæ€§å’Œå¹»è§‰çš„æœ‰æ•ˆæ‰‹æ®µ</u>**ï¼Œå› æ­¤ï¼Œç™¾å·æ™ºèƒ½å°†æœç´¢æŠ€æœ¯ä¸å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›ç›¸ç»“åˆï¼Œå®ç°åˆ›æ–°æ€§çš„æ¨¡å‹ä¼˜åŒ–ä¸æ”¹è¿›ã€‚</p>
<p>æœç´¢å¢å¼ºç³»ç»Ÿ**<u>èåˆäº†æŒ‡ä»¤æ„å›¾ç†è§£ã€æ™ºèƒ½æœç´¢å’Œç»“æœå¢å¼ºç­‰å…³é”®ç»„ä»¶</u>**ï¼Œè¿™ä¸€ç»¼åˆä½“ç³»é€šè¿‡æ·±å…¥ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œç²¾ç¡®é©±åŠ¨æŸ¥è¯¢è¯çš„æœç´¢ï¼Œå¹¶ç»“åˆå¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯æ¥ä¼˜åŒ–æ¨¡å‹ç»“æœç”Ÿæˆçš„å¯é æ€§ï¼ŒåŸºäºæ­¤ï¼Œç™¾å·æ™ºèƒ½å®ç°äº†æ›´ç²¾ç¡®ã€æ›´æ™ºèƒ½çš„æ¨¡å‹ç»“æœå›ç­”ï¼Œå‡å°‘äº†æ¨¡å‹çš„å¹»è§‰ã€‚</p>
<p>å…¶ä¸­ï¼Œ**<u>åŠ¨æ€å“åº”ç­–ç•¥æ–¹é¢ï¼Œç™¾å·æ™ºèƒ½å°†æŒ‡ä»¤ä»»åŠ¡ç»†åŒ–ä¸º16ä¸ªç‹¬ç«‹ç±»åˆ«ï¼Œæ¶µç›–äº†ç”¨æˆ·æŒ‡ä»¤çš„ç²¾å‡†é—®ç­”ã€é€»è¾‘æ¨ç†ã€å¤´è„‘é£æš´ç­‰å„ç§åœºæ™¯ï¼Œå¹¶é’ˆå¯¹æ¯ä¸€ä¸ªæŒ‡ä»¤ç±»åˆ«éƒ½è¿›è¡Œäº†è®¾è®¡å’Œä¼˜åŒ–</u>**ã€‚</p>
<p>**<u>æ™ºèƒ½åŒ–æœç´¢è¯ç”Ÿæˆ</u>**åˆ™æ˜¯é€šè¿‡å¯¹é—®ç­”æ ·æœ¬è¿›è¡Œç²¾ç»†åŒ–äººå·¥æ ‡æ³¨ï¼Œæ•æ‰å’Œç†è§£ç”¨æˆ·å¤šå…ƒåŒ–çš„æŒ‡ä»¤éœ€æ±‚ï¼Œå¤§æ¨¡å‹è´Ÿè´£æ‰§è¡Œä¸€ç³»åˆ—å…³é”®ä»»åŠ¡ï¼Œå¦‚æ—¶æ•ˆæ€§è¯†åˆ«å’Œæœç´¢æ„å›¾åˆ¤åˆ«ï¼Œä»è€Œå‡†ç¡®è§£é‡Šç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾å¹¶ç²¾å‡†å“åº”ã€‚</p>
<p>ä¸ºäº†è¾¾åˆ°é«˜è´¨é‡æœç´¢ç»“æœç­›é€‰ï¼Œç™¾å·æ™ºèƒ½æ„å»ºäº†ä¸€ä¸ª**<u>æœç´¢ç»“æœç›¸å…³æ€§æ¨¡å‹</u>**ï¼Œå¯¹ä»æœç´¢å†…å®¹å’ŒçŸ¥è¯†åº“ä¸­è·å–çš„ä¿¡æ¯è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ã€‚</p>
<p>åœ¨å›ç­”ç»“æœçš„æœç´¢å¢å¼ºä¸Šï¼Œç™¾å·æ™ºèƒ½**<u>é‡‡ç”¨RLHFï¼ˆäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼‰æŠ€æœ¯ï¼Œä½¿å¾—å¤§æ¨¡å‹èƒ½å¤Ÿå‚ç…§æœç´¢ç»“æœï¼Œé’ˆå¯¹ç”¨æˆ·è¯·æ±‚ç”Ÿæˆé«˜ä»·å€¼ä¸”å…·æœ‰å®æ—¶æ€§çš„å›ç­”</u>**ã€‚</p>
<p>é™¤æ­¤ä»¥å¤–ï¼Œå¤§æ¨¡å‹è¿˜ä¼šé€šè¿‡å¯¹é½è°ƒæ•´è®©æ¨¡å‹åŒäººç±»ä»·å€¼è§‚å¯¹é½ï¼Œç”Ÿæˆä»¤äººæ»¡æ„çš„å›å¤å†…å®¹ã€‚</p>
<h2 id="å¤šè¯­è¨€å¤§æ¨¡å‹"><a href="#å¤šè¯­è¨€å¤§æ¨¡å‹" class="headerlink" title="å¤šè¯­è¨€å¤§æ¨¡å‹"></a>å¤šè¯­è¨€å¤§æ¨¡å‹</h2><h3 id="LLaMa"><a href="#LLaMa" class="headerlink" title="LLaMa"></a>LLaMa</h3><h4 id="LLaMA-2"><a href="#LLaMA-2" class="headerlink" title="LLaMA-2"></a>LLaMA-2</h4><p>æ–‡ç« åœ°å€<a target="_blank" rel="noopener" href="https://together.ai/blog/llama-2-7b-32k%E4%B8%AD%E6%8A%A5%E9%81%93%E4%BA%86LLaMA-2-7B-32K%E8%BF%99%E4%B8%80%E5%B7%A5%E4%BD%9C%EF%BC%8C%E8%AF%A5%E6%A8%A1%E5%9E%8B%E5%B0%86LLaMA-2-7B%E6%89%A9%E5%B1%95%E5%88%B032K%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%EF%BC%8C%E4%BD%BF%E7%94%A8Meta%E7%9A%84[%E6%8F%92%E5%80%BC](https://arxiv.org/abs/2306.15595)%E3%80%81%E7%BB%A7%E7%BB%AD%E9%A2%84%E8%AE%AD%E7%BB%83%E3%80%81FlashAttention%EF%BC%8C%E8%83%BD%E5%A4%9F%E5%A4%84%E7%90%86%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BB%BB%E5%8A%A1%EF%BC%88%E5%A6%82%E5%A4%9A%E6%96%87%E6%A1%A3%E7%90%86%E8%A7%A3%E3%80%81%E6%91%98%E8%A6%81%E5%92%8C">https://together.ai/blog/llama-2-7b-32kä¸­æŠ¥é“äº†LLaMA-2-7B-32Kè¿™ä¸€å·¥ä½œï¼Œè¯¥æ¨¡å‹å°†LLaMA-2-7Bæ‰©å±•åˆ°32Ké•¿ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨Metaçš„[æ’å€¼](https://arxiv.org/abs/2306.15595)ã€ç»§ç»­é¢„è®­ç»ƒã€FlashAttentionï¼Œèƒ½å¤Ÿå¤„ç†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ï¼ˆå¦‚å¤šæ–‡æ¡£ç†è§£ã€æ‘˜è¦å’Œ</a> QA)ã€‚</p>
<h5 id="é•¿æ–‡æœ¬æ‰©å±•"><a href="#é•¿æ–‡æœ¬æ‰©å±•" class="headerlink" title="é•¿æ–‡æœ¬æ‰©å±•"></a>é•¿æ–‡æœ¬æ‰©å±•</h5><p>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹å¯¹äºæ–‡æ¡£ç†è§£ã€æ‘˜è¦å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆå·²ç»è‡³å…³é‡è¦ã€‚</p>
<p>å°† LLaMA-2 (4K) æ‰©å±•åˆ° 32K ä¸Šä¸‹æ–‡æ˜¯å¦‚ä½•åšåˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹çœ‹å…¶å®ç°é€»è¾‘ã€‚LLaMA-2çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸º4Ktokenã€‚è¦å°†å…¶æ‰©å±•åˆ°32Kä¸Šä¸‹æ–‡ï¼Œè¯¥å·¥ä½œåˆ†æˆäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼š<strong>å»ºæ¨¡ã€æ•°æ®å’Œç³»ç»Ÿä¼˜åŒ–(åŒ…æ‹¬<a target="_blank" rel="noopener" href="https://together.ai/blog/tri-dao-flash-attention">Flash-Attention-2</a>)ã€‚</strong></p>
<p>ã€1ã€‘å»ºæ¨¡</p>
<p>é¦–å…ˆï¼Œåœ¨å»ºæ¨¡æ–¹é¢ï¼Œæˆ‘**<u>ä½¿ç”¨çº¿æ€§æ’å€¼æ¥æ‰©å±•ä¸Šä¸‹æ–‡é•¿åº¦</u>**ï¼Œçº¿æ€§æ’å€¼æ³•æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥æ‰©å±•å…·æœ‰æ—‹è½¬ä½ç½®åµŒå…¥çš„æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚ä½¿ç”¨LLaMA-2æ£€æŸ¥ç‚¹ï¼Œå¹¶ç»§ç»­ä½¿ç”¨1.5B tokençš„çº¿æ€§æ’å€¼å¯¹å…¶è¿›è¡Œé¢„è®­ç»ƒ&#x2F;å¾®è°ƒã€‚</p>
<p>ã€2ã€‘æ•°æ®</p>
<p>å…¶æ¬¡ï¼Œ**<u>åœ¨æ•°æ®æ–¹é¢</u><strong>ï¼Œä¸æ˜¯ç®€å•åœ°ä½¿ç”¨Pileå’ŒRedPajamaç­‰é€šç”¨è¯­è¨€æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œä¸»è¦è€ƒè™‘åˆ°2ç‚¹ï¼Œä¸€ä¸ªæ˜¯</strong><u>éœ€è¦æ¨¡å‹çš„é€šç”¨é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ•°æ®æ¥å­¦ä¹ å¦‚ä½•å¤„ç†æ’å€¼ä½ç½®åµŒå…¥ï¼Œå¦ä¸€ä¸ªæ˜¯éœ€è¦æŒ‡ä»¤æ•°æ®æ¥é¼“åŠ±æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­å®é™…åˆ©ç”¨ä¿¡æ¯</u>**ã€‚</p>
<blockquote>
<p>æ‰€ä»¥ï¼Œé‡‡ç”¨äº†<strong>æ•°æ®æ··åˆ</strong>çš„æ–¹å¼:</p>
<p>[1] <strong>åœ¨ç»§ç»­é¢„è®­ç»ƒé˜¶æ®µ</strong>ï¼Œæ•°æ®æ„æˆä¸ŠåŒ…å«25%çš„RedPajama Bookã€25% çš„RedPajama ArXivï¼ˆåŒ…æ‹¬æ‘˜è¦ï¼‰ã€25%æ¥è‡ªRedPajamaçš„å…¶ä»–æ•°æ®ï¼Œä»¥åŠ 25% æ¥è‡ª UL2 Oscar Data(è¿™æ˜¯ OIG(<a target="_blank" rel="noopener" href="https://github.com/LAION-AI/Open-Instruction-Generalist">Open-Instruction-Generalist</a>) çš„ä¸€éƒ¨åˆ†)ï¼Œè¦æ±‚æ¨¡å‹å¡«å†™ç¼ºå¤±çš„å—æˆ–å®Œæˆæ–‡æœ¬ã€‚ä¸ºäº†å¢å¼ºé•¿ä¸Šä¸‹æ–‡åŠŸèƒ½ï¼Œå‰”é™¤äº†çŸ­äº2K tokençš„åºåˆ—ã€‚UL2 Oscaræ•°æ®é¼“åŠ±æ¨¡å‹å¯¹é•¿ç¨‹ä¾èµ–è¿›è¡Œå»ºæ¨¡ã€‚</p>
<p>[2] <strong>åœ¨å¾®è°ƒé˜¶æ®µ</strong>ï¼Œä¸“æ³¨äºå…¶å…·æœ‰é•¿ä¸Šä¸‹æ–‡çš„few shotèƒ½åŠ›ï¼ŒåŒ…æ‹¬20%è‡ªç„¶æŒ‡ä»¤ï¼ˆNIï¼‰ã€20%çš„Public Pool of Promptsï¼ˆP3ï¼‰ã€20%çš„Pileã€‚ä¸ºäº†å‡è½»é—å¿˜ï¼Œè¿›ä¸€æ­¥å°†20%çš„RedPajama Bookå’Œ20%çš„RedPajama ArXivä¸æ‘˜è¦ç›¸ç»“åˆã€‚</p>
</blockquote>
<p>æœ€åï¼Œ<strong>åœ¨è¯„ä¼°é˜¶æ®µ</strong>ï¼Œé’ˆå¯¹HELMæ ¸å¿ƒåœºæ™¯(HELM core scenarios) <a target="_blank" rel="noopener" href="https://together.ai/blog/redpajama-7b">here</a>è¿›è¡Œäº†æ•°æ®å»é‡ï¼Œå¹¶åšç»†è‡´è¯„ä¼°ï¼Œå…·ä½“åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰åœ¨PG-19ä¸Šä¸åŒåºåˆ—é•¿åº¦ä¸‹çš„å½’ä¸€åŒ–å›°æƒ‘åº¦ï¼Œï¼ˆ2ï¼‰ä»¥åŠåœ¨16ä¸ªæ ¸å¿ƒåœºæ™¯ä¸­çš„HELM v1.0å¾—åˆ†ï¼ˆåœ¨é€‚åˆLLaMA 2çš„ç›¸åŒä¸Šä¸‹æ–‡é•¿åº¦ä¸Šè¯„ä¼°ï¼‰ï¼Œå¯ä»¥çœ‹åˆ°ï¼ŒLLaMA-2-7B-32Käº§ç”Ÿåˆç†çš„å›°æƒ‘ï¼Œä¸åŸå§‹LLaMA 2æ¨¡å‹ç›¸å½“ã€‚æ­¤å¤–ï¼Œåœ¨HELM v1.0ä¸Šï¼ŒLLaMA-2-7B-32Kä¸åŸå§‹LLaMA-2-7B baseç›¸æ¯”ï¼Œå³ä½¿æ²¡æœ‰è¾¾åˆ°æ›´å¥½è´¨é‡ï¼Œä½†ä¹Ÿæ˜¯ç›¸å½“ã€‚Perplexity-per-byte for various context lengths:<br>$$<br>exp(1&#x2F;N_{byte} sum_{i&#x3D;1,â€¦,N_{tokens}} loss_i)<br>$$<br><strong>å¾®è°ƒæ„å»ºé•¿ä¸Šä¸‹æ–‡åº”ç”¨åœºæ™¯æ•°æ®å½¢å¼</strong></p>
<p>LLaMA-2-7B-32K çš„å¼ºå¤§ä¹‹å¤„åœ¨äºå®ƒå½¢æˆäº†ä¸€ä¸ªå¼ºå¤§çš„åŸºåº§æ¨¡å‹ï¼Œäººä»¬å¯ä»¥å¯¹å…¶è¿›è¡Œå¾®è°ƒä»¥æ„å»ºè‡ªå·±çš„åº”ç”¨ç¨‹åºã€‚æˆ‘ä»¬ç°åœ¨ä¸¾ä¾‹è¯´æ˜ä¸¤ä¸ªè¿™æ ·çš„ä¾‹å­ã€‚</p>
<p><strong>ï¼ˆ1ï¼‰Long-context QA.</strong></p>
<p>æˆ‘ä»¬ä»¥è®ºæ–‡â€œè¿·å¤±åœ¨ä¸­é—´ï¼šè¯­è¨€æ¨¡å‹å¦‚ä½•ä½¿ç”¨é•¿ä¸Šä¸‹æ–‡â€ä¸­çš„å¤šæ–‡æ¡£é—®ç­”ä»»åŠ¡ä¸ºä¾‹ã€‚æ¨¡å‹çš„è¾“å…¥åŒ…æ‹¬ 1ï¼‰ éœ€è¦ç­”æ¡ˆçš„é—®é¢˜å’Œ 2ï¼‰ k ä¸ªæ–‡æ¡£ï¼Œè¿™äº›æ–‡æ¡£æ˜¯ä»ç»´åŸºç™¾ç§‘ä¸­æå–çš„æ®µè½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›æ–‡æ¡£ä¸­åªæœ‰ä¸€ä¸ªæ–‡æ¡£åŒ…å«é—®é¢˜çš„ç­”æ¡ˆï¼Œè€Œå…¶ä½™çš„k âˆ’ 1æ–‡æ¡£ï¼ˆç§°ä¸ºâ€œå¹²æ‰°â€æ–‡æ¡£ï¼‰åˆ™ä¸åŒ…å«ã€‚è‹¥è¦æˆåŠŸæ‰§è¡Œæ­¤ä»»åŠ¡ï¼Œæ¨¡å‹å¿…é¡»ä»å…¶è¾“å…¥ä¸Šä¸‹æ–‡ä¸­è¯†åˆ«å¹¶åˆ©ç”¨åŒ…å«ç­”æ¡ˆçš„æ–‡æ¡£ã€‚ä¸€ä¸ªæ½œåœ¨çš„ç”¨ä¾‹æ˜¯å®ç°LLMä¸æ–‡æ¡£å’Œvector databaseä¹‹é—´çš„æ— ç¼é›†æˆï¼Œvector databaseç”¨äºè·å–ç›¸å…³ä¿¡æ¯ï¼ˆä¸Šä¸‹æ–‡ï¼‰ï¼ŒLLMç”¨äºå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚</p>
<blockquote>
<p>å¾®è°ƒåœ¨é•¿ä¸Šä¸‹æ–‡ QA ä¸­è¡¨ç°æ›´å¥½çš„æ¨¡å‹ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼å‡†å¤‡æ•°æ®ï¼š</p>
<p><em>&#96;&#96;&#96;<br>Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant).</em></p>
<p><em>Document [1] (Title: Email retargeting) on sending personalized e-mail to an anonymous website visitorâ€¦</em></p>
<p><em>Document [2] (Title: Opt-in email) of 2003 does not require an opt-in approach, only an easy opt-out systemâ€¦</em></p>
<p><em>Document [3] (Title: Email marketing) to send direct promotional messages to, or they rent a list of email addresses â€¦</em></p>
<p><em>â€¦</em></p>
<p><em>Question: which is the most common use of opt-in e-mail marketing</em></p>
<p><em>Answer: a newsletter sent to an advertising firmâ€™s customers</em></p>
<p><em>&#96;&#96;&#96;</em></p>
<p>æˆ‘ä»¬çš„é¢„å¤„ç†è¿‡ç¨‹åæ˜ äº†ä¸Šè¿°è®ºæ–‡ä¸­ä½¿ç”¨çš„è¿‡ç¨‹ï¼Œå¹¶ä¸”æˆ‘ä»¬ä»NaturalQuestionæ•°æ®é›†ä¸­å¾—å‡ºäº†æˆ‘ä»¬çš„è®­ç»ƒé›†ã€‚training&#x2F;finetune_LLaMA-2-7b-32k-mqa.sh è¯´æ˜äº†å¦‚ä½•å°†æ­¤æ•°æ®é›†ä¼ é€’ç»™ OCK ä»¥å¾®è°ƒ LLaMA-2-7B-32Kã€‚</p>
<p>æˆ‘ä»¬é€šè¿‡åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰“åŒ…çš„ä¸åŒæ•°é‡(ä» 20 åˆ° 100)çš„æ–‡æ¡£æ¥è¡¡é‡è´¨é‡ã€‚å¹³å‡è€Œè¨€ï¼Œè¿™ç›¸å½“äºæ¨¡å‹è¾“å…¥ä¸­çš„ 2.9K ä¸ªtokenåˆ° 14.8K ä¸ªtokenã€‚æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œä¸€æ—¦æˆ‘ä»¬åœ¨è¿™é¡¹ä»»åŠ¡ä¸Šå¾®è°ƒLLaMA-2-7B-32Kï¼Œæˆ‘ä»¬å°±å®ç°äº†è´¨é‡çš„æ˜¾ç€æé«˜ã€‚</p>
</blockquote>
<p><strong>ï¼ˆ2ï¼‰Long-context summarization.</strong> </p>
<p>æˆ‘ä»¬ä½¿ç”¨BookSumï¼Œè¿™æ˜¯ä¸€ä¸ªç‹¬ç‰¹çš„æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³é•¿ç¯‡å™äº‹æ‘˜è¦çš„æŒ‘æˆ˜ã€‚è¯¥æ•°æ®é›†åŒ…å«æ–‡å­¦é¢†åŸŸçš„æºæ–‡æ¡£ï¼ŒåŒ…æ‹¬å°è¯´ã€æˆå‰§å’Œæ•…äº‹ï¼Œå¹¶æä¾›äººç±»ç¼–å†™çš„é«˜åº¦æŠ½è±¡æ‘˜è¦ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå…³æ³¨ç« èŠ‚çº§åˆ«çš„æ•°æ®ã€‚ BookSum æå‡ºäº†ä¸€ç³»åˆ—ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œéœ€è¦æ¨¡å‹å…¨é¢é€šè¯»æ¯ä¸€ç« ã€‚</p>
<blockquote>
<p>æˆ‘ä»¬æŒ‰ä»¥ä¸‹æ ¼å¼å‡†å¤‡æ•°æ®ï¼š</p>
<p><em>&#96;&#96;&#96;</em></p>
<p><em>Chapter: â€œMother, Mother, I am so happy!â€ whispered the girl, burying her face in the lap of the faded, tired-looking woman who, with back turned to the shrill intrusive light, was sitting in the one arm-chair that their dingy sitting-room contained. â€œI am so happy!â€ she repeated, â€œand you must be happy, too!â€â€¦</em></p>
<p><em>Q: Can you write an appropriate summary of the above paragraphs?</em></p>
<p><em>A: The following day, Sibyl Vane and her mother discuss the girlâ€™s relationship with â€œPrince Charming.â€ Sibyl is elated and wants her mother to share her joy. She is in love. Mrs. Vaneâ€™s attitude is more realistic and down-to-earth. She wants her daughter to think of her careerâ€¦</em></p>
<p><em>&#96;&#96;&#96;</em></p>
<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡è®­ç»ƒ&#x2F;finetune_LLaMA-2-7b-32k-booksum.sh åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šå¾®è°ƒLLaMA-2-7B-32Kã€‚</p>
<p>æµ‹è¯•æ•°æ®å¹³å‡åŒ…å«å¤§çº¦ 4500 ä¸ªtokenã€‚ä¸ºäº†è¯„ä¼°å’Œæ¯”è¾ƒæ€§èƒ½ï¼Œæˆ‘ä»¬è®¡ç®—äº†ä¸‰ä¸ªç‰¹å®šæŒ‡æ ‡ï¼šRouge-1ã€Rouge-2 å’Œ Rouge-L åˆ†æ•°ã€‚å¯¹äº LLaMA-2ï¼Œå½“è¾“å…¥ä¸é€‚åˆ 4K ä¸Šä¸‹æ–‡æ—¶ï¼Œæˆ‘ä»¬ä¼šæˆªæ–­è¾“å…¥ã€‚æˆ‘ä»¬çœ‹åˆ°ï¼Œå¾®è°ƒåçš„æ¨¡å‹åœ¨æ‰€æœ‰è¿™äº›æŒ‡æ ‡ä¸Šéƒ½è·å¾—äº†æ›´é«˜çš„åˆ†æ•°ã€‚</p>
</blockquote>
<p>ã€3ã€‘ç³»ç»Ÿä¼˜åŒ–</p>
<p>æ„å»ºé•¿ä¸Šä¸‹æ–‡æ¨¡å‹çš„ä¸€ä¸ªç‹¬ç‰¹æŒ‘æˆ˜æ˜¯ï¼Œä¸æ–­å¢åŠ çš„ä¸Šä¸‹æ–‡é•¿åº¦éœ€è¦ç³»ç»Ÿä¼˜åŒ–ã€‚</p>
<p>æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªæ›´æ–°çš„è®­ç»ƒå’Œæ¨ç†å †æ ˆï¼Œé›†æˆäº†æˆ‘ä»¬çš„é¦–å¸­ç§‘å­¦å®¶Tri Daoæœ€è¿‘å‘å¸ƒçš„FlashAttention-2ï¼Œä»¥åŠä¸€ç³»åˆ—å…¶ä»–ä¼˜åŒ–ï¼š</p>
<blockquote>
<ul>
<li>å½“å‰çš„<a target="_blank" rel="noopener" href="https://github.com/togethercomputer/OpenChatKit">OCK repo</a>ç°åœ¨æ”¯æŒä½¿ç”¨ 32K ä¸Šä¸‹æ–‡è¿›è¡Œå¾®è°ƒã€‚é€šè¿‡æœ€æ–°çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨FlashAttention-1å®ç°äº†æ¯”ä¼˜åŒ–è‰¯å¥½çš„OCKé«˜å‡º1.6å€ã€‚</li>
<li>æˆ‘ä»¬è¿˜å°† FlashAttention-2 é›†æˆåˆ° <a target="_blank" rel="noopener" href="https://huggingface.co/togethercomputer/Llama-2-7B-32K-beta/">inference stack</a> ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ HuggingFace Transformer è¿è¡Œ;åœ¨ 32K ä¸Šä¸‹æ–‡ä¸­ï¼Œä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒçš„æ¨ç†ååé‡æé«˜äº† 3 å€ã€‚</li>
</ul>
</blockquote>
<h3 id="BLOOM"><a href="#BLOOM" class="headerlink" title="BLOOM"></a>BLOOM</h3><h3 id="Falcon"><a href="#Falcon" class="headerlink" title="Falcon"></a>Falcon</h3><h1 id="é¢†åŸŸLLMæ¨¡å‹"><a href="#é¢†åŸŸLLMæ¨¡å‹" class="headerlink" title="é¢†åŸŸLLMæ¨¡å‹"></a>é¢†åŸŸLLMæ¨¡å‹</h1><h2 id="å„¿ç«¥é™ªä¼´"><a href="#å„¿ç«¥é™ªä¼´" class="headerlink" title="å„¿ç«¥é™ªä¼´"></a>å„¿ç«¥é™ªä¼´</h2><p><strong>ã€1ã€‘é¢å‘å„¿ç«¥å¿ƒç†å¥åº·é¢†åŸŸçš„å¾®è°ƒæ¨¡å‹QiaoBan</strong></p>
<p>è¯¥é¡¹ç›®æ—¨åœ¨æ„å»ºä¸€ä¸ªé¢å‘å„¿ç«¥æƒ…æ„Ÿé™ªä¼´çš„å¤§æ¨¡å‹ï¼Œ<strong>ä¸»è¦é¢å‘K12ä¸­å°å­¦ç”ŸåŠå®¶é•¿ç¾¤ä½“ï¼Œæ˜¯ä¸€ä¸ª7Bè§„æ¨¡çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå…¶é€šè¿‡ç»™å®šè¯é¢˜ä¸‹è¿›è¡Œæ•°æ®çš„ç”Ÿæˆï¼Œå¯ä»¥ä½œä¸ºå¤šè½®å¯¹è¯çš„ä¸€ä¸ªæµ‹è¯•é›†ä½¿ç”¨ï¼Œå…¶åœºæ™¯ä¹Ÿå¾ˆæœ‰è¶£ã€‚</strong></p>
<p><em><strong>åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR-SC/QiaoBan">https://github.com/HIT-SCIR-SC/QiaoBan</a></strong></em></p>
<p>åœ¨è®­ç»ƒæ•°æ®ä¸Šï¼Œä»çœŸå®åœºæ™¯çš„å„¿ç«¥å¯¹è¯è¯é¢˜åˆ—è¡¨ä¸­è¿›è¡Œé‡‡æ ·ï¼Œé€‰å®šå½“å‰å¯¹è¯è¯é¢˜ï¼Œåœ¨å„¿ç«¥æƒ…ç»ªè¾…å¯¼ç†è®ºçš„æŒ‡å¯¼ä¸‹ï¼Œ<strong>æ„å»ºäº†1kä½™æ®µé«˜è´¨é‡ä¸­æ–‡å„¿ç«¥æƒ…æ„Ÿé™ªä¼´å¯¹è¯æ•°æ®</strong>ã€‚</p>
<p>æ•°æ®æ„å»ºè¿‡ç¨‹ç”±ç»è¿‡å„¿ç«¥æƒ…ç»ªè¾…å¯¼ç†è®ºåŸ¹è®­çš„å¿—æ„¿è€…å®Œæˆï¼ŒåŒæ—¶é‚€è¯·äº†å„¿ç«¥å¿ƒç†å­¦é¢†åŸŸçš„ä¸“å®¶å­¦è€…å¯¹æ•°æ®çš„æ”¶é›†è¿‡ç¨‹æå‡ºå»ºè®®ä¸æŒ‡å¯¼ï¼Œä»¥ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚</p>
<p>ä»é¡¹ç›®ä¸­çš„<strong>è¯é¢˜åˆ—è¡¨</strong>å…±538ä¸ªï¼ˆæ–‡ä»¶ï¼š<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR-SC/QiaoBan/blob/main/topic.txt%EF%BC%89%E9%83%A8%E5%88%86%E5%A6%82%E4%B8%8B%EF%BC%9A">https://github.com/HIT-SCIR-SC/QiaoBan/blob/main/topic.txtï¼‰éƒ¨åˆ†å¦‚ä¸‹ï¼š</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ç­ä¼šæ¸¸æˆã€æ–°å¹´ç­ä¼šã€è¯„å¥–ç­ä¼šã€ç­çº§èšé¤ã€ç­çº§èšä¼š</span><br><span class="line">å…ƒæ—¦æ™šä¼šã€æ‰è‰ºæ™šä¼šã€å„¿ç«¥èŠ‚æ–‡è‰ºè¡¨æ¼”ã€â€œå¿«ä¹ç«¥å¹´â€æ‰è‰ºå°èˆå°ã€å„¿ç«¥èŠ‚æ¸¸å›­ã€æ˜¥èŠ‚è”æ¬¢æ™šä¼šã€è¿åŠ¨ä¼šã€æ­Œå”±æ¯”èµ›ã€è¯—æœ—è¯µæ¯”èµ›ã€å¹´çº§ç¯®çƒèµ›</span><br><span class="line">åŠ¨ç‰©å›­ã€åšç‰©é¦†ã€é£æ™¯åŒºã€æ˜¥ç§‹æ¸¸</span><br><span class="line">ç¯®çƒã€è¶³çƒã€è·‘æ­¥ã€ç¾½æ¯›çƒã€ä¹’ä¹“çƒã€å°çƒã€æ¸¸æ³³</span><br><span class="line">æ‹¾é‡‘ä¸æ˜§ã€çƒ­çˆ±åŠ³åŠ¨ã€è¯šå®ã€ä¹äºåŠ©äººã€è‡ªä¸»ä¸ºç­çº§æ¬ä¸œè¥¿</span><br></pre></td></tr></table></figure>

<p>å®Œæ•´çš„æ•°æ®å¯ä»¥æŸ¥çœ‹ï¼š<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR-SC/QiaoBan/blob/main/data/child_chat_data.json">https://github.com/HIT-SCIR-SC/QiaoBan/blob/main/data/child_chat_data.json</a></p>
<p>ä¾‹å¦‚ï¼Œç»™<strong>å®šè¯é¢˜ç”Ÿæˆ</strong>çš„æ•°æ®å¦‚ä¸‹ï¼š</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;dialog_id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;emotion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;angry&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ç­ä¼šæ¸¸æˆ&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;dialog&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å¦ˆå¦ˆï¼Œè€å¸ˆè¯´æˆ‘æ²¡èµ¢æ¸¸æˆï¼Œä½†æˆ‘çœŸçš„èµ¢äº†ï¼Œæˆ‘å¥½ç”Ÿæ°”ï¼Œè§‰å¾—å¤ªä¸å…¬å¹³äº†ï¼&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;äº²çˆ±çš„ï¼Œæˆ‘äº†è§£ä½ çš„æ„Ÿå—ï¼Œå¯ä»¥è·Ÿæˆ‘è¯´è¯´ç­ä¼šä¸Šçš„æƒ…å†µå—ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æˆ‘ä»¬ç­æœ‰ä¸ªæ¸¸æˆï¼Œæˆ‘å¾—åˆ†æœ€é«˜ï¼Œå›¢é˜Ÿä¹Ÿèµ¢äº†ï¼Œä½†è€å¸ˆå´è¯´æ˜¯åˆ«çš„åŒå­¦èµ¢äº†ï¼Œè¿™å¤ªä¸å…¬å¹³äº†ï¼&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æˆ‘æ˜ç™½äº†ï¼Œä½†æ˜¯ä½ æ˜¯æ€ä¹ˆèµ¢çš„æ¸¸æˆå‘¢ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æˆ‘å¾—åˆ†æœ€é«˜ï¼Œå›¢é˜Ÿä¹Ÿèµ¢äº†ï¼Œæ‰€æœ‰äººéƒ½çœ‹åˆ°æˆ‘æ˜¯èµ¢å®¶ï¼Œä¸ºä»€ä¹ˆè€å¸ˆè¿˜è¯´æˆ‘æ²¡èµ¢å‘¢ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;é‚£ä½ çŸ¥é“è€å¸ˆä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´å—ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä¸çŸ¥é“ï¼Œä½†æˆ‘è§‰å¾—å¤ªä¸å…¬å¹³äº†ï¼&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ˜¯å•Šï¼Œå¾ˆä¸å…¬å¹³ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿè¦å°Šé‡è€å¸ˆçš„å†³å®šï¼Œä¹Ÿè®¸ä»–æœ‰è‡ªå·±çš„åŸå› ã€‚ä½ å¯ä»¥å»è·Ÿè€å¸ˆèŠä¸€ä¸‹ï¼Œäº†è§£ä»–çš„æƒ³æ³•ï¼Œè¿™æ ·ä½ ä¼šæ›´æ¸…æ¥šäº‹æƒ…çš„çœŸç›¸ã€‚å¦‚æœä½ è¿˜æ˜¯è§‰å¾—å¾ˆä¸å…¬å¹³ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€èµ·æ‰¾ç­ä¸»ä»»æˆ–æ ¡é•¿è°ˆè°ˆï¼Œä½†æ˜¯åœ¨å¤„ç†é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬è¦ä¿æŒå†·é™ï¼Œä¸è¦å› ä¸ºæƒ…ç»ªè€Œåšå‡ºé”™è¯¯çš„å†³å®šã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å¥½çš„ï¼Œæˆ‘ä¼šå»è·Ÿè€å¸ˆèŠèŠã€‚è°¢è°¢ä½ ï¼Œå¦ˆå¦ˆã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ²¡äº‹ï¼Œæˆ‘æ°¸è¿œæ”¯æŒä½ ï¼Œå¦‚æœéœ€è¦å¸®åŠ©ï¼Œéšæ—¶æ¥æ‰¾æˆ‘å“¦ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å¦ˆå¦ˆï¼Œè¿˜æœ‰ä¸€ä»¶äº‹æˆ‘æƒ³è·Ÿä½ è¯´ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä»€ä¹ˆäº‹ï¼Ÿä½ å¯ä»¥è·Ÿæˆ‘è¯´è¯´çœ‹ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä»Šå¤©æˆ‘è·ŸåŒå­¦åƒåˆé¥­æ—¶ï¼Œæœ‰ä¸ªåŒå­¦è®²äº†å¾ˆå¤šå…³äºç¯ä¿çš„äº‹æƒ…ï¼Œè®©æˆ‘æ„Ÿåˆ°å¾ˆæƒŠè®¶ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å“¦ï¼Ÿé‚£ä½ è§‰å¾—ä»–è®²äº†äº›ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å—ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä»–è¯´æˆ‘ä»¬è¦å¤šä½¿ç”¨å¯é‡å¤åˆ©ç”¨çš„è¢‹å­ï¼Œå¯ä»¥å‡å°‘å¡‘æ–™è¢‹çš„æµªè´¹ï¼Œè¿˜è¯´æˆ‘ä»¬è¦å¤šç§æ¤æ ‘æœ¨ï¼Œå› ä¸ºæ ‘æœ¨å¯ä»¥å¸æ”¶äºŒæ°§åŒ–ç¢³ï¼Œå‡å°‘ç©ºæ°”æ±¡æŸ“ã€‚æˆ‘è§‰å¾—è¿™äº›ä¸»æ„å¾ˆå¥½ï¼Œå¦‚æœæ¯ä¸ªäººéƒ½èƒ½åšåˆ°ï¼Œåœ°çƒå°±ä¼šæ›´åŠ ç¾å¥½äº†ï¼&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å¤ªå¥½äº†ï¼ä½ çš„åŒå­¦æœ‰å¾ˆæ£’çš„æƒ³æ³•ï¼Œä½ ä¹Ÿå¯ä»¥å‘ä»–å­¦ä¹ å“¦ã€‚ä½ å¯ä»¥è·Ÿä»–å¤šèŠèŠç¯ä¿æ–¹é¢çš„çŸ¥è¯†ï¼Œä¹Ÿå¯ä»¥å°è¯•åœ¨å®¶é‡Œåšäº›ç¯ä¿çš„äº‹æƒ…ï¼Œæ¯”å¦‚åƒåœ¾åˆ†ç±»ã€èŠ‚çº¦ç”¨æ°´ç­‰ç­‰ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å¥½çš„ï¼Œæˆ‘ä¼šçš„ï¼æˆ‘è§‰å¾—ç¯ä¿çœŸçš„å¾ˆé‡è¦ï¼Œæˆ‘ä»¬è¦å°½åŠ›ä¿æŠ¤æˆ‘ä»¬çš„åœ°çƒã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å­©å­&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ˜¯çš„ï¼Œè¿™æ˜¯æˆ‘ä»¬æ¯ä¸ªäººéƒ½åº”è¯¥åšçš„äº‹æƒ…ã€‚æˆ‘å¾ˆé«˜å…´ä½ èƒ½æ„è¯†åˆ°è¿™ä¸€ç‚¹ï¼Œç»§ç»­åŠ æ²¹å“¦ï¼&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;speaker&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ™ºèƒ½åŠ©æ‰‹&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>æ­¤å¤–ï¼Œæ ¹æ®è¯¥é¡¹ç›®æè¿°ï¼Œå…¶é€šè¿‡è¯é¢˜é‡‡æ ·é€‰å®šå½“å‰å¯¹è¯è¯é¢˜ï¼Œç»“åˆå„¿ç«¥æƒ…ç»ªè¾…å¯¼ç†è®ºæŒ‡å¯¼ä¸‹çš„promptï¼Œå…±åŒç»„æˆchatgpt_promptï¼Œä»gpt-3.5-turboä¸­è·å–<strong>5åƒæ®µ</strong>å„¿ç«¥æƒ…æ„Ÿé™ªä¼´å¯¹è¯æ•°æ®ã€‚</p>
<p>åœ¨è®­ç»ƒè€—è´¹ä¸Šï¼Œ<strong>åœ¨å››å¼ A100-80GBçš„GPUå¡ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒ</strong>ï¼Œå¤§çº¦èŠ±è´¹50ä¸ªå°æ—¶å®Œæˆè®­ç»ƒè¿‡ç¨‹ã€‚</p>
<h1 id="Agentç›¸å…³"><a href="#Agentç›¸å…³" class="headerlink" title="Agentç›¸å…³"></a>Agentç›¸å…³</h1><h2 id="HuggingFace-Agent"><a href="#HuggingFace-Agent" class="headerlink" title="HuggingFace Agent"></a>HuggingFace Agent</h2><p>ä½¿ç”¨å¤§æ¨¡å‹ä½œä¸ºAgentï¼Œä»…éœ€è‡ªç„¶è¯­è¨€å°±å¯è°ƒç”¨HuggingFaceä¸­çš„æ¨¡å‹ï¼Œç›®å‰æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š</p>
<ul>
<li>runæ¨¡å¼ï¼šå•è½®å¯¹è¯ï¼Œæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œå•ä¸ªpromptå¤štoolç»„åˆè°ƒç”¨èƒ½åŠ›å¥½</li>
<li>chatæ¨¡å¼ï¼šå¤šè½®å¯¹è¯ï¼Œæœ‰ä¸Šä¸‹æ–‡ï¼Œå•æ¬¡è°ƒç”¨èƒ½åŠ›å¥½ï¼Œå¯èƒ½éœ€è¦å¤šæ¬¡promptå®ç°å¤štoolç»„åˆè°ƒç”¨</li>
</ul>
<blockquote>
<p>è¯¦è§å®˜æ–¹æ–‡æ¡£ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/transformers_agents">Transformers Agents</a></p>
</blockquote>
<h3 id="ä½¿ç”¨é€šä¹‰åƒé—®ä½œä¸ºAgent"><a href="#ä½¿ç”¨é€šä¹‰åƒé—®ä½œä¸ºAgent" class="headerlink" title="ä½¿ç”¨é€šä¹‰åƒé—®ä½œä¸ºAgent"></a>ä½¿ç”¨é€šä¹‰åƒé—®ä½œä¸ºAgent</h3><h4 id="å®‰è£…ä¾èµ–"><a href="#å®‰è£…ä¾èµ–" class="headerlink" title="å®‰è£…ä¾èµ–"></a>å®‰è£…ä¾èµ–</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure>

<h4 id="æ„å»ºQWenAgent"><a href="#æ„å»ºQWenAgent" class="headerlink" title="æ„å»ºQWenAgent"></a>æ„å»ºQWenAgent</h4><p>ä»¥ä¸‹ä»£ç ä¾¿å¯å®ç°QWenAgentï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer, Agent</span><br><span class="line"><span class="keyword">from</span> transformers.generation <span class="keyword">import</span> GenerationConfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QWenAgent</span>(<span class="title class_ inherited__">Agent</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Agent that uses QWen model and tokenizer to generate code.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        chat_prompt_template (`str`, *optional*):</span></span><br><span class="line"><span class="string">            Pass along your own prompt if you want to override the default template for the `chat` method. Can be the</span></span><br><span class="line"><span class="string">            actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named</span></span><br><span class="line"><span class="string">            `chat_prompt_template.txt` in this repo in this case.</span></span><br><span class="line"><span class="string">        run_prompt_template (`str`, *optional*):</span></span><br><span class="line"><span class="string">            Pass along your own prompt if you want to override the default template for the `run` method. Can be the</span></span><br><span class="line"><span class="string">            actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named</span></span><br><span class="line"><span class="string">            `run_prompt_template.txt` in this repo in this case.</span></span><br><span class="line"><span class="string">        additional_tools ([`Tool`], list of tools or dictionary with tool values, *optional*):</span></span><br><span class="line"><span class="string">            Any additional tools to include on top of the default ones. If you pass along a tool with the same name as</span></span><br><span class="line"><span class="string">            one of the default tools, that default tool will be overridden.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    ```py</span></span><br><span class="line"><span class="string">    agent = QWenAgent()</span></span><br><span class="line"><span class="string">    agent.run(&quot;Draw me a picture of rivers and lakes.&quot;)</span></span><br><span class="line"><span class="string">    ```</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, chat_prompt_template=<span class="literal">None</span>, run_prompt_template=<span class="literal">None</span>, additional_tools=<span class="literal">None</span></span>):</span><br><span class="line">        checkpoint = <span class="string">&quot;Qwen/Qwen-7B-Chat&quot;</span></span><br><span class="line">        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">        self.model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=<span class="string">&quot;auto&quot;</span>, trust_remote_code=<span class="literal">True</span>).cuda().<span class="built_in">eval</span>()</span><br><span class="line">        self.model.generation_config = GenerationConfig.from_pretrained(checkpoint, trust_remote_code=<span class="literal">True</span>) <span class="comment"># å¯æŒ‡å®šä¸åŒçš„ç”Ÿæˆé•¿åº¦ã€top_pç­‰ç›¸å…³è¶…å‚</span></span><br><span class="line">        self.model.generation_config.do_sample = <span class="literal">False</span>  <span class="comment"># greedy</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            chat_prompt_template=chat_prompt_template,</span><br><span class="line">            run_prompt_template=run_prompt_template,</span><br><span class="line">            additional_tools=additional_tools,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_one</span>(<span class="params">self, prompt, stop</span>):</span><br><span class="line">        <span class="comment"># &quot;Human:&quot; å’Œ &quot;Assistant:&quot; æ›¾ä¸ºé€šä¹‰åƒé—®çš„ç‰¹æ®Šä¿ç•™å­—ï¼Œéœ€è¦æ›¿æ¢ä¸º &quot;_HUMAN_:&quot; å’Œ &quot;_ASSISTANT_:&quot;ã€‚è¿™ä¸€é—®é¢˜å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¿®å¤ã€‚</span></span><br><span class="line">        prompt = prompt.replace(<span class="string">&quot;Human:&quot;</span>, <span class="string">&quot;_HUMAN_:&quot;</span>).replace(<span class="string">&quot;Assistant:&quot;</span>, <span class="string">&quot;_ASSISTANT_:&quot;</span>)</span><br><span class="line">        stop = [item.replace(<span class="string">&quot;Human:&quot;</span>, <span class="string">&quot;_HUMAN_:&quot;</span>).replace(<span class="string">&quot;Assistant:&quot;</span>, <span class="string">&quot;_ASSISTANT_:&quot;</span>) <span class="keyword">for</span> item <span class="keyword">in</span> stop]</span><br><span class="line"></span><br><span class="line">        result, _ = self.model.chat(self.tokenizer, prompt, history=<span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">for</span> stop_seq <span class="keyword">in</span> stop:</span><br><span class="line">            <span class="keyword">if</span> result.endswith(stop_seq):</span><br><span class="line">                result = result[: -<span class="built_in">len</span>(stop_seq)]</span><br><span class="line"></span><br><span class="line">        result = result.replace(<span class="string">&quot;_HUMAN_:&quot;</span>, <span class="string">&quot;Human:&quot;</span>).replace(<span class="string">&quot;_ASSISTANT_:&quot;</span>, <span class="string">&quot;Assistant:&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">agent = QWenAgent()</span><br><span class="line">agent.run(<span class="string">&quot;Draw me a picture of rivers and lakes.&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h3><h4 id="Toolsæ”¯æŒ"><a href="#Toolsæ”¯æŒ" class="headerlink" title="Toolsæ”¯æŒ"></a>Toolsæ”¯æŒ</h4><p>HuggingFace Agentå®˜æ–¹14ä¸ªtoolï¼š</p>
<ul>
<li><strong>Document question answering</strong>: given a document (such as a PDF) in image format, answer a question on this document (Donut)</li>
<li><strong>Text question answering</strong>: given a long text and a question, answer the question in the text (Flan-T5)</li>
<li><strong>Unconditional image captioning</strong>: Caption the image! (BLIP)</li>
<li><strong>Image question answering</strong>: given an image, answer a question on this image (VILT)</li>
<li><strong>Image segmentation</strong>: given an image and a prompt, output the segmentation mask of that prompt (CLIPSeg)</li>
<li><strong>Speech to text</strong>: given an audio recording of a person talking, transcribe the speech into text (Whisper)</li>
<li><strong>Text to speech</strong>: convert text to speech (SpeechT5)</li>
<li><strong>Zero-shot text classification</strong>: given a text and a list of labels, identify to which label the text corresponds the most (BART)</li>
<li><strong>Text summarization</strong>: summarize a long text in one or a few sentences (BART)</li>
<li><strong>Translation</strong>: translate the text into a given language (NLLB)</li>
<li><strong>Text downloader</strong>: to download a text from a web URL</li>
<li><strong>Text to image</strong>: generate an image according to a prompt, leveraging stable diffusion</li>
<li><strong>Image transformation</strong>: transforms an image</li>
<li><strong>Text to video</strong>: generate a small video according to a prompt, leveraging damo-vilab</li>
</ul>
<p>æ›´å¤šç©æ³•å‚è€ƒHuggingFaceå®˜æ–¹æ–‡æ¡£<a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/transformers_agents">Transformers Agents</a></p>
<h3 id="Toolsæ¨¡å‹éƒ¨ç½²"><a href="#Toolsæ¨¡å‹éƒ¨ç½²" class="headerlink" title="Toolsæ¨¡å‹éƒ¨ç½²"></a>Toolsæ¨¡å‹éƒ¨ç½²</h3><p>éƒ¨åˆ†å·¥å…·æ¶‰åŠçš„æ¨¡å‹HuggingFaceå·²è¿›è¡Œåœ¨çº¿éƒ¨ç½²ï¼Œä»…éœ€è®¾ç½®remote&#x3D;Trueä¾¿å¯å®ç°åœ¨çº¿è°ƒç”¨ï¼š</p>
<blockquote>
<p>agent.run(xxx, remote&#x3D;True)</p>
</blockquote>
<p>HuggingFaceæ²¡æœ‰åœ¨çº¿éƒ¨ç½²çš„æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½checkpointè¿›è¡Œæœ¬åœ°inference ç½‘ç»œåŸå› å¶å°”è¿ä¸ä¸ŠHuggingFaceï¼Œè¯·å¤šæ¬¡å°è¯•</p>
<h2 id="ReAct"><a href="#ReAct" class="headerlink" title="ReAct"></a>ReAct</h2><h3 id="ReAct-Prompting-ç¤ºä¾‹"><a href="#ReAct-Prompting-ç¤ºä¾‹" class="headerlink" title="ReAct Prompting ç¤ºä¾‹"></a>ReAct Prompting ç¤ºä¾‹</h3><p>æ¥æºï¼š<a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-7B/blob/main/examples/react_prompt.md">QWen</a> </p>
<p><strong>å‡†å¤‡å·¥ä½œä¸€ï¼šæ ·ä¾‹é—®é¢˜ã€æ ·ä¾‹å·¥å…·</strong></p>
<p>å‡è®¾æˆ‘ä»¬æœ‰å¦‚ä¸‹çš„ä¸€ä¸ªé€‚åˆç”¨å·¥å…·å¤„ç†çš„ queryï¼Œä»¥åŠæœ‰å¤¸å…‹æœç´¢ã€é€šä¹‰ä¸‡ç›¸æ–‡ç”Ÿå›¾è¿™ä¸¤ä¸ªå·¥å…·ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&#x27;æˆ‘æ˜¯è€æ¿ï¼Œæˆ‘è¯´å•¥ä½ åšå•¥ã€‚ç°åœ¨ç»™æˆ‘ç”»ä¸ªäº”å½©æ–‘æ–“çš„é»‘ã€‚&#x27;</span></span><br><span class="line"></span><br><span class="line">TOOLS = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;name_for_human&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;å¤¸å…‹æœç´¢&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;name_for_model&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;quark_search&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;description_for_model&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;å¤¸å…‹æœç´¢æ˜¯ä¸€ä¸ªé€šç”¨æœç´¢å¼•æ“ï¼Œå¯ç”¨äºè®¿é—®äº’è”ç½‘ã€æŸ¥è¯¢ç™¾ç§‘çŸ¥è¯†ã€äº†è§£æ—¶äº‹æ–°é—»ç­‰ã€‚&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;parameters&#x27;</span>: [&#123;</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;search_query&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;description&#x27;</span>: <span class="string">&#x27;æœç´¢å…³é”®è¯æˆ–çŸ­è¯­&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;required&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">            <span class="string">&#x27;schema&#x27;</span>: &#123;</span><br><span class="line">                <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;string&#x27;</span></span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;],</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&#x27;name_for_human&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;é€šä¹‰ä¸‡ç›¸&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;name_for_model&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;image_gen&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;description_for_model&#x27;</span>:</span><br><span class="line">        <span class="string">&#x27;é€šä¹‰ä¸‡ç›¸æ˜¯ä¸€ä¸ªAIç»˜ç”»ï¼ˆå›¾åƒç”Ÿæˆï¼‰æœåŠ¡ï¼Œè¾“å…¥æ–‡æœ¬æè¿°ï¼Œè¿”å›æ ¹æ®æ–‡æœ¬ä½œç”»å¾—åˆ°çš„å›¾ç‰‡çš„URL&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;parameters&#x27;</span>: [&#123;</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;query&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;description&#x27;</span>: <span class="string">&#x27;ä¸­æ–‡å…³é”®è¯ï¼Œæè¿°äº†å¸Œæœ›å›¾åƒå…·æœ‰ä»€ä¹ˆå†…å®¹&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;required&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">            <span class="string">&#x27;schema&#x27;</span>: &#123;</span><br><span class="line">                <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;string&#x27;</span></span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;],</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>å‡†å¤‡å·¥ä½œäºŒï¼šReAct æ¨¡ç‰ˆ</strong></p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨å¦‚ä¸‹çš„ ReAct prompt æ¨¡ç‰ˆæ¥æ¿€å‘åƒé—®ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TOOL_DESC = <span class="string">&quot;&quot;&quot;&#123;name_for_model&#125;: Call this tool to interact with the &#123;name_for_human&#125; API. What is the &#123;name_for_human&#125; API useful for? &#123;description_for_model&#125; Parameters: &#123;parameters&#125; Format the arguments as a JSON object.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">REACT_PROMPT = <span class="string">&quot;&quot;&quot;Answer the following questions as best you can. You have access to the following tools:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;tool_descs&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Use the following format:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: the input question you must answer</span></span><br><span class="line"><span class="string">Thought: you should always think about what to do</span></span><br><span class="line"><span class="string">Action: the action to take, should be one of [&#123;tool_names&#125;]</span></span><br><span class="line"><span class="string">Action Input: the input to the action</span></span><br><span class="line"><span class="string">Observation: the result of the action</span></span><br><span class="line"><span class="string"><span class="meta">... </span>(this Thought/Action/Action Input/Observation can be repeated zero or more times)</span></span><br><span class="line"><span class="string">Thought: I now know the final answer</span></span><br><span class="line"><span class="string">Final Answer: the final answer to the original input question</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Begin!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;query&#125;&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>æ­¥éª¤ä¸€ï¼šè®©åƒé—®åˆ¤æ–­è¦è°ƒç”¨ä»€ä¹ˆå·¥å…·ã€ç”Ÿæˆå·¥å…·å…¥å‚</strong></p>
<p>é¦–å…ˆæˆ‘ä»¬éœ€è¦æ ¹æ® ReAct prompt æ¨¡ç‰ˆã€queryã€å·¥å…·çš„ä¿¡æ¯æ„å»º promptï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tool_descs = []</span><br><span class="line">tool_names = []</span><br><span class="line">for info in TOOLS:</span><br><span class="line">    tool_descs.append(</span><br><span class="line">        TOOL_DESC.format(</span><br><span class="line">            name_for_model=info[&#x27;name_for_model&#x27;],</span><br><span class="line">            name_for_human=info[&#x27;name_for_human&#x27;],</span><br><span class="line">            description_for_model=info[&#x27;description_for_model&#x27;],</span><br><span class="line">            parameters=json.dumps(</span><br><span class="line">                info[&#x27;parameters&#x27;], ensure_ascii=False),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    tool_names.append(info[&#x27;name_for_model&#x27;])</span><br><span class="line">tool_descs = &#x27;\n\n&#x27;.join(tool_descs)</span><br><span class="line">tool_names = &#x27;,&#x27;.join(tool_names)</span><br><span class="line"></span><br><span class="line">prompt = REACT_PROMPT.format(tool_descs=tool_descs, tool_names=tool_names, query=query)</span><br><span class="line">print(prompt)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°å‡ºæ¥çš„ã€æ„å»ºå¥½çš„ prompt å¦‚ä¸‹ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Answer the following questions as best you can. You have access to the following tools:</span><br><span class="line"></span><br><span class="line">quark_search: Call this tool to interact with the å¤¸å…‹æœç´¢ API. What is the å¤¸å…‹æœç´¢ API useful for? å¤¸å…‹æœç´¢æ˜¯ä¸€ä¸ªé€šç”¨æœç´¢å¼•æ“ï¼Œå¯ç”¨äºè®¿é—®äº’è”ç½‘ã€æŸ¥è¯¢ç™¾ç§‘çŸ¥è¯†ã€äº†è§£æ—¶äº‹æ–°é—»ç­‰ã€‚ Parameters: [&#123;&quot;name&quot;: &quot;search_query&quot;, &quot;description&quot;: &quot;æœç´¢å…³é”®è¯æˆ–çŸ­è¯­&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.</span><br><span class="line"></span><br><span class="line">image_gen: Call this tool to interact with the é€šä¹‰ä¸‡ç›¸ API. What is the é€šä¹‰ä¸‡ç›¸ API useful for? é€šä¹‰ä¸‡ç›¸æ˜¯ä¸€ä¸ªAIç»˜ç”»ï¼ˆå›¾åƒç”Ÿæˆï¼‰æœåŠ¡ï¼Œè¾“å…¥æ–‡æœ¬æè¿°ï¼Œè¿”å›æ ¹æ®æ–‡æœ¬ä½œç”»å¾—åˆ°çš„å›¾ç‰‡çš„URL Parameters: [&#123;&quot;name&quot;: &quot;query&quot;, &quot;description&quot;: &quot;ä¸­æ–‡å…³é”®è¯ï¼Œæè¿°äº†å¸Œæœ›å›¾åƒå…·æœ‰ä»€ä¹ˆå†…å®¹&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.</span><br><span class="line"></span><br><span class="line">Use the following format:</span><br><span class="line"></span><br><span class="line">Question: the input question you must answer</span><br><span class="line">Thought: you should always think about what to do</span><br><span class="line">Action: the action to take, should be one of [quark_search,image_gen]</span><br><span class="line">Action Input: the input to the action</span><br><span class="line">Observation: the result of the action</span><br><span class="line">... (this Thought/Action/Action Input/Observation can be repeated zero or more times)</span><br><span class="line">Thought: I now know the final answer</span><br><span class="line">Final Answer: the final answer to the original input question</span><br><span class="line"></span><br><span class="line">Begin!</span><br><span class="line"></span><br><span class="line">Question: æˆ‘æ˜¯è€æ¿ï¼Œæˆ‘è¯´å•¥ä½ åšå•¥ã€‚ç°åœ¨ç»™æˆ‘ç”»ä¸ªäº”å½©æ–‘æ–“çš„é»‘ã€‚</span><br></pre></td></tr></table></figure>

<p>å°†è¿™ä¸ª prompt é€å…¥åƒé—®ï¼Œå¹¶è®°å¾—è®¾ç½® â€œObservationâ€ ä¸º stop word ï¼ˆè§æœ¬æ–‡æœ«å°¾çš„ FAQï¼‰â€”â€” å³è®©åƒé—®åœ¨é¢„æµ‹åˆ°è¦ç”Ÿæˆçš„ä¸‹ä¸€ä¸ªè¯æ˜¯ â€œObservationâ€ æ—¶é©¬ä¸Šåœæ­¢ç”Ÿæˆ â€”â€” åˆ™åƒé—®åœ¨å¾—åˆ°è¿™ä¸ª prompt åä¼šç”Ÿæˆå¦‚ä¸‹çš„ç»“æœï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Thought: æˆ‘åº”è¯¥ä½¿ç”¨é€šä¹‰ä¸‡ç›¸APIæ¥ç”Ÿæˆä¸€å¼ äº”å½©æ–‘æ–“çš„é»‘çš„å›¾ç‰‡ã€‚</span><br><span class="line">Action: image_gen</span><br><span class="line">Action Input: &#123;&quot;query&quot;: &quot;äº”å½©æ–‘æ–“çš„é»‘&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>åœ¨å¾—åˆ°è¿™ä¸ªç»“æœåï¼Œè°ƒç”¨åƒé—®çš„å¼€å‘è€…å¯ä»¥é€šè¿‡ç®€å•çš„è§£ææå–å‡º <code>&#123;&quot;query&quot;: &quot;äº”å½©æ–‘æ–“çš„é»‘&quot;&#125;</code> å¹¶åŸºäºè¿™ä¸ªè§£æç»“æœè°ƒç”¨æ–‡ç”Ÿå›¾æœåŠ¡ â€”â€” è¿™éƒ¨åˆ†é€»è¾‘éœ€è¦å¼€å‘è€…è‡ªè¡Œå®ç°ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ä½¿ç”¨åƒé—®å•†ä¸šç‰ˆï¼Œå•†ä¸šç‰ˆæœ¬å°†å†…éƒ¨é›†æˆç›¸å…³é€»è¾‘ã€‚</p>
<p><strong>è®©åƒé—®æ ¹æ®æ’ä»¶è¿”å›ç»“æœç»§ç»­ä½œç­”</strong></p>
<p>è®©æˆ‘ä»¬å‡è®¾æ–‡ç”Ÿå›¾æ’ä»¶è¿”å›äº†å¦‚ä¸‹ç»“æœï¼š</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;status_code&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span> <span class="attr">&quot;request_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;3d894da2-0e26-9b7c-bd90-102e5250ae03&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;code&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span> <span class="attr">&quot;message&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;task_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2befaa09-a8b3-4740-ada9-4d00c2758b05&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;task_status&quot;</span><span class="punctuation">:</span> <span class="string">&quot;SUCCEEDED&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;results&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230801/1509/6b26bb83-469e-4c70-bff4-a9edd1e584f3-1.png&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;task_metrics&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;TOTAL&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> <span class="attr">&quot;SUCCEEDED&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> <span class="attr">&quot;FAILED&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="attr">&quot;usage&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;image_count&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¹‹å‰é¦–æ¬¡è¯·æ±‚åƒé—®æ—¶ç”¨çš„ prompt å’Œ è°ƒç”¨æ–‡ç”Ÿå›¾æ’ä»¶çš„ç»“æœæ‹¼æ¥æˆå¦‚ä¸‹çš„æ–° promptï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Answer the following questions as best you can. You have access to the following tools:</span><br><span class="line"></span><br><span class="line">quark_search: Call this tool to interact with the å¤¸å…‹æœç´¢ API. What is the å¤¸å…‹æœç´¢ API useful for? å¤¸å…‹æœç´¢æ˜¯ä¸€ä¸ªé€šç”¨æœç´¢å¼•æ“ï¼Œå¯ç”¨äºè®¿é—®äº’è”ç½‘ã€æŸ¥è¯¢ç™¾ç§‘çŸ¥è¯†ã€äº†è§£æ—¶äº‹æ–°é—»ç­‰ã€‚ Parameters: [&#123;&quot;name&quot;: &quot;search_query&quot;, &quot;description&quot;: &quot;æœç´¢å…³é”®è¯æˆ–çŸ­è¯­&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.</span><br><span class="line"></span><br><span class="line">image_gen: Call this tool to interact with the é€šä¹‰ä¸‡ç›¸ API. What is the é€šä¹‰ä¸‡ç›¸ API useful for? é€šä¹‰ä¸‡ç›¸æ˜¯ä¸€ä¸ªAIç»˜ç”»ï¼ˆå›¾åƒç”Ÿæˆï¼‰æœåŠ¡ï¼Œè¾“å…¥æ–‡æœ¬æè¿°ï¼Œè¿”å›æ ¹æ®æ–‡æœ¬ä½œç”»å¾—åˆ°çš„å›¾ç‰‡çš„URL Parameters: [&#123;&quot;name&quot;: &quot;query&quot;, &quot;description&quot;: &quot;ä¸­æ–‡å…³é”®è¯ï¼Œæè¿°äº†å¸Œæœ›å›¾åƒå…·æœ‰ä»€ä¹ˆå†…å®¹&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.</span><br><span class="line"></span><br><span class="line">Use the following format:</span><br><span class="line"></span><br><span class="line">Question: the input question you must answer</span><br><span class="line">Thought: you should always think about what to do</span><br><span class="line">Action: the action to take, should be one of [quark_search,image_gen]</span><br><span class="line">Action Input: the input to the action</span><br><span class="line">Observation: the result of the action</span><br><span class="line">... (this Thought/Action/Action Input/Observation can be repeated zero or more times)</span><br><span class="line">Thought: I now know the final answer</span><br><span class="line">Final Answer: the final answer to the original input question</span><br><span class="line"></span><br><span class="line">Begin!</span><br><span class="line"></span><br><span class="line">Question: æˆ‘æ˜¯è€æ¿ï¼Œæˆ‘è¯´å•¥ä½ åšå•¥ã€‚ç°åœ¨ç»™æˆ‘ç”»ä¸ªäº”å½©æ–‘æ–“çš„é»‘ã€‚</span><br><span class="line">Thought: æˆ‘åº”è¯¥ä½¿ç”¨é€šä¹‰ä¸‡ç›¸APIæ¥ç”Ÿæˆä¸€å¼ äº”å½©æ–‘æ–“çš„é»‘çš„å›¾ç‰‡ã€‚</span><br><span class="line">Action: image_gen</span><br><span class="line">Action Input: &#123;&quot;query&quot;: &quot;äº”å½©æ–‘æ–“çš„é»‘&quot;&#125;</span><br><span class="line">Observation: &#123;&quot;status_code&quot;: 200, &quot;request_id&quot;: &quot;3d894da2-0e26-9b7c-bd90-102e5250ae03&quot;, &quot;code&quot;: null, &quot;message&quot;: &quot;&quot;, &quot;output&quot;: &#123;&quot;task_id&quot;: &quot;2befaa09-a8b3-4740-ada9-4d00c2758b05&quot;, &quot;task_status&quot;: &quot;SUCCEEDED&quot;, &quot;results&quot;: [&#123;&quot;url&quot;: &quot;https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230801/1509/6b26bb83-469e-4c70-bff4-a9edd1e584f3-1.png&quot;&#125;], &quot;task_metrics&quot;: &#123;&quot;TOTAL&quot;: 1, &quot;SUCCEEDED&quot;: 1, &quot;FAILED&quot;: 0&#125;&#125;, &quot;usage&quot;: &#123;&quot;image_count&quot;: 1&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>ç”¨è¿™ä¸ªæ–°çš„æ‹¼æ¥äº†æ–‡ç”Ÿå›¾æ’ä»¶ç»“æœçš„æ–° prompt å»è°ƒç”¨åƒé—®ï¼Œå°†å¾—åˆ°å¦‚ä¸‹çš„æœ€ç»ˆå›å¤ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Thought: æˆ‘å·²ç»æˆåŠŸä½¿ç”¨é€šä¹‰ä¸‡ç›¸APIç”Ÿæˆäº†ä¸€å¼ äº”å½©æ–‘æ–“çš„é»‘çš„å›¾ç‰‡ã€‚</span><br><span class="line">Final Answer: æˆ‘å·²ç»æˆåŠŸä½¿ç”¨é€šä¹‰ä¸‡ç›¸APIç”Ÿæˆäº†ä¸€å¼ äº”å½©æ–‘æ–“çš„é»‘çš„å›¾ç‰‡https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230801/1509/6b26bb83-469e-4c70-bff4-a9edd1e584f3-1.pngã€‚</span><br></pre></td></tr></table></figure>

<p>è™½ç„¶å¯¹äºæ–‡ç”Ÿå›¾æ¥è¯´ï¼Œè¿™ä¸ªç¬¬äºŒæ¬¡è°ƒç”¨åƒé—®çš„æ­¥éª¤æ˜¾å¾—å¤šä½™ã€‚ä½†æ˜¯å¯¹äºæœç´¢æ’ä»¶ã€ä»£ç æ‰§è¡Œæ’ä»¶ã€è®¡ç®—å™¨æ’ä»¶ç­‰åˆ«çš„æ’ä»¶æ¥è¯´ï¼Œè¿™ä¸ªç¬¬äºŒæ¬¡è°ƒç”¨åƒé—®çš„æ­¥éª¤ç»™äº†åƒé—®æç‚¼ã€æ€»ç»“æ’ä»¶è¿”å›ç»“æœçš„æœºä¼šã€‚</p>
<p><strong>FAQ</strong></p>
<p><strong>æ€ä¹ˆé…ç½® â€œObservationâ€ è¿™ä¸ª stop wordï¼Ÿ</strong></p>
<p>é€šè¿‡ chat æ¥å£çš„ stop_words_ids æŒ‡å®šï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">react_stop_words = [</span><br><span class="line">    <span class="comment"># tokenizer.encode(&#x27;Observation&#x27;),  # [37763, 367]</span></span><br><span class="line">    tokenizer.encode(<span class="string">&#x27;Observation:&#x27;</span>),  <span class="comment"># [37763, 367, 25]</span></span><br><span class="line">    tokenizer.encode(<span class="string">&#x27;Observation:\n&#x27;</span>),  <span class="comment"># [37763, 367, 510]</span></span><br><span class="line">]</span><br><span class="line">response, history = model.chat(</span><br><span class="line">    tokenizer, query, history,</span><br><span class="line">    stop_words_ids=react_stop_words  <span class="comment"># æ­¤æ¥å£ç”¨äºå¢åŠ  stop words</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>å¦‚æœæŠ¥é”™ç§°ä¸å­˜åœ¨ stop_words_ids æ­¤å‚æ•°ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ‚¨ç”¨äº†è€çš„ä»£ç ï¼Œè¯·é‡æ–°æ‰§è¡Œ from_pretrained æ‹‰å–æ–°çš„ä»£ç å’Œæ¨¡å‹ã€‚</p>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå½“å‰çš„ tokenizer å¯¹ <code>\n</code> æœ‰ä¸€ç³»åˆ—è¾ƒå¤æ‚çš„èšåˆæ“ä½œã€‚æ¯”å¦‚ä¾‹å­ä¸­çš„<code>:\n</code>è¿™ä¸¤ä¸ªå­—ç¬¦ä¾¿è¢«èšåˆæˆäº†ä¸€ä¸ª tokenã€‚å› æ­¤é…ç½® stop words éœ€è¦éå¸¸ç»†è‡´åœ°é¢„ä¼° tokenizer çš„è¡Œä¸ºã€‚</p>
<p><strong>å¯¹ top_p ç­‰æ¨ç†å‚æ•°æœ‰è°ƒå‚å»ºè®®å—ï¼Ÿ</strong></p>
<p>é€šå¸¸æ¥è®²ï¼Œè¾ƒä½çš„ top_p ä¼šæœ‰æ›´é«˜çš„å‡†ç¡®åº¦ï¼Œä½†ä¼šç‰ºç‰²å›ç­”çš„å¤šæ ·æ€§ã€ä¸”æ›´æ˜“å‡ºç°é‡å¤æŸä¸ªè¯å¥çš„ç°è±¡ã€‚</p>
<p>å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼è°ƒæ•´ top_p ä¸º 0.5ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.generation_config.top_p = 0.5</span><br></pre></td></tr></table></figure>

<p>ç‰¹åˆ«çš„ï¼Œå¯ä»¥ç”¨å¦‚ä¸‹æ–¹å¼å…³é—­ top-p samplingï¼Œæ”¹ç”¨ greedy samplingï¼Œæ•ˆæœä¸Šç›¸å½“äº top_p&#x3D;0 æˆ– temperature&#x3D;0ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.generation_config.do_sample = False  # greedy decoding</span><br></pre></td></tr></table></figure>

<p>æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ <code>model.chat()</code> æ¥å£ä¹Ÿæä¾›äº†è°ƒæ•´ top_p ç­‰å‚æ•°çš„æ¥å£ã€‚</p>
<p><strong>æœ‰è§£æActionã€Action Inputçš„å‚è€ƒä»£ç å—ï¼Ÿ</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_latest_plugin_call</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]:</span><br><span class="line">    i = text.rfind(<span class="string">&#x27;\nAction:&#x27;</span>)</span><br><span class="line">    j = text.rfind(<span class="string">&#x27;\nAction Input:&#x27;</span>)</span><br><span class="line">    k = text.rfind(<span class="string">&#x27;\nObservation:&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="number">0</span> &lt;= i &lt; j:  <span class="comment"># If the text has `Action` and `Action input`,</span></span><br><span class="line">        <span class="keyword">if</span> k &lt; j:  <span class="comment"># but does not contain `Observation`,</span></span><br><span class="line">            <span class="comment"># then it is likely that `Observation` is ommited by the LLM,</span></span><br><span class="line">            <span class="comment"># because the output text may have discarded the stop word.</span></span><br><span class="line">            text = text.rstrip() + <span class="string">&#x27;\nObservation:&#x27;</span>  <span class="comment"># Add it back.</span></span><br><span class="line">            k = text.rfind(<span class="string">&#x27;\nObservation:&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="number">0</span> &lt;= i &lt; j &lt; k:</span><br><span class="line">        plugin_name = text[i + <span class="built_in">len</span>(<span class="string">&#x27;\nAction:&#x27;</span>):j].strip()</span><br><span class="line">        plugin_args = text[j + <span class="built_in">len</span>(<span class="string">&#x27;\nAction Input:&#x27;</span>):k].strip()</span><br><span class="line">        <span class="keyword">return</span> plugin_name, plugin_args</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>æ­¤å¤–ï¼Œå¦‚æœè¾“å‡ºçš„ Action Input å†…å®¹æ˜¯ä¸€æ®µè¡¨ç¤º JSON å¯¹è±¡çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ <code>json5</code> åŒ…çš„ <code>json5.loads(...)</code> æ–¹æ³•åŠ è½½ã€‚</p>
<h1 id="æ–‡æœ¬Embedding"><a href="#æ–‡æœ¬Embedding" class="headerlink" title="æ–‡æœ¬Embedding"></a>æ–‡æœ¬Embedding</h1><p>å°†ä»»æ„æ–‡æœ¬æ˜ å°„ä¸ºä½ç»´ç¨ å¯†å‘é‡ï¼Œä»¥ç”¨äºæ£€ç´¢ã€åˆ†ç±»ã€èšç±»æˆ–è¯­ä¹‰åŒ¹é…ç­‰ä»»åŠ¡ï¼Œå¹¶å¯æ”¯æŒä¸ºå¤§æ¨¡å‹è°ƒç”¨å¤–éƒ¨çŸ¥è¯†ã€‚</p>
<h2 id="FlagEmbeddingï¼ˆæ™ºæºï¼‰"><a href="#FlagEmbeddingï¼ˆæ™ºæºï¼‰" class="headerlink" title="FlagEmbeddingï¼ˆæ™ºæºï¼‰"></a>FlagEmbeddingï¼ˆæ™ºæºï¼‰</h2><p><a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md">https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md</a></p>
<h4 id="Model-List"><a href="#Model-List" class="headerlink" title="Model List"></a>Model List</h4><table>
<thead>
<tr>
<th>Model</th>
<th>Language</th>
<th>Description</th>
<th>query instruction for retrieval*</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-en">BAAI&#x2F;bge-large-en</a></td>
<td>English</td>
<td>ğŸ† åœ¨ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/mteb/leaderboard">MTEB</a> æ¦œå•ä¸Šæ’å<strong>ç¬¬ä¸€</strong></td>
<td><code>Represent this sentence for searching relevant passages: </code></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-base-en">BAAI&#x2F;bge-base-en</a></td>
<td>English</td>
<td>åœ¨ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/mteb/leaderboard">MTEB</a> æ¦œå•ä¸Šæ’å<strong>ç¬¬äºŒ</strong></td>
<td><code>Represent this sentence for searching relevant passages: </code></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-small-en">BAAI&#x2F;bge-small-en</a></td>
<td>English</td>
<td>small-scaleæ¨¡å‹ï¼Œæ€§èƒ½é«˜äºå¾ˆå¤šå¼€æºlarge-scaleæ¨¡å‹ï¼Œæ¨ç†æ›´é«˜æ•ˆ</td>
<td><code>Represent this sentence for searching relevant passages: </code></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-zh">BAAI&#x2F;bge-large-zh</a></td>
<td>Chinese</td>
<td>ğŸ† åœ¨ <a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB">C-MTEB</a> æ¦œå•ä¸Šæ’å<strong>ç¬¬ä¸€</strong></td>
<td><code>ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š</code></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-zh-noinstruct">BAAI&#x2F;bge-large-zh-noinstruct</a></td>
<td>Chinese</td>
<td>åœ¨ <a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB">C-MTEB</a> æ¦œå•ä¸Šæ’å<strong>ç¬¬äºŒ</strong></td>
<td>â€“</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-base-zh">BAAI&#x2F;bge-base-zh</a></td>
<td>Chinese</td>
<td>base-scaleæ¨¡å‹ï¼Œä¸bge-largeæ€§èƒ½ç±»ä¼¼ï¼Œä½†æ¨ç†æ›´å¿«ï¼Œå‘é‡ç»´åº¦æ›´å°</td>
<td><code>ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š</code></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-small-zh">BAAI&#x2F;bge-small-zh</a></td>
<td>Chinese</td>
<td>small-scaleæ¨¡å‹ï¼Œæ¨ç†æ¯”baseæ¨¡å‹æ›´å¿«</td>
<td><code>ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š</code></td>
</tr>
</tbody></table>
<p>*: å¦‚æœæ‚¨éœ€è¦ä¸ºä¸€ä¸ªç®€çŸ­çš„æŸ¥è¯¢æœç´¢ç›¸å…³æ–‡æ¡£ï¼Œæ‚¨éœ€è¦åœ¨æŸ¥è¯¢ä¸­æ·»åŠ æŒ‡ä»¤ï¼›åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œä¸éœ€è¦æŒ‡ä»¤ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢å³å¯ã€‚<strong>åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæ‚¨éƒ½ä¸éœ€è¦ä¸ºå€™é€‰æ–‡æ¡£å¢åŠ æŒ‡ä»¤</strong>ã€‚</p>
<h4 id="ä½¿ç”¨-1"><a href="#ä½¿ç”¨-1" class="headerlink" title="ä½¿ç”¨"></a>ä½¿ç”¨</h4><ul>
<li><strong>Using FlagEmbedding</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U FlagEmbedding</span><br></pre></td></tr></table></figure>

<p>å¦‚æœæ‚¨ä½¿ç”¨äº†é•œåƒï¼Œå¯èƒ½æ— æ³•æ‰¾åˆ°æœ€æ–°ç‰ˆçš„FlagEmbeddingã€‚ å¯ä»¥å‚è€ƒ<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md">FlagEmbedding</a> ä¸‹è½½æ”¹é¡¹ç›®è¿›è¡Œå®‰è£…ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> FlagEmbedding <span class="keyword">import</span> FlagModel</span><br><span class="line">sentences = [<span class="string">&quot;æ ·ä¾‹æ•°æ®-1&quot;</span>, <span class="string">&quot;æ ·ä¾‹æ•°æ®-2&quot;</span>]</span><br><span class="line">model = FlagModel(<span class="string">&#x27;BAAI/bge-large-zh&#x27;</span>, query_instruction_for_retrieval=<span class="string">&quot;ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š&quot;</span>)</span><br><span class="line">embeddings_1 = model.encode(sentences)</span><br><span class="line">embeddings_2 = model.encode(sentences)</span><br><span class="line">smilarity = embeddings_1 @ embeddings_2.T</span><br><span class="line"><span class="built_in">print</span>(smilarity)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹äºæ£€ç´¢ä»»åŠ¡ä¸­çš„æŸ¥è¯¢é—®é¢˜ï¼Œè¯·ä½¿ç”¨ encode_queries() å‡½æ•°ï¼Œå…¶ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªæŸ¥è¯¢åŠ ä¸ŠæŒ‡ä»¤</span></span><br><span class="line"><span class="comment"># ç”±äºå€™é€‰æ–‡æœ¬ä¸éœ€è¦æ·»åŠ æŒ‡ä»¤ï¼Œæ£€ç´¢ä¸­çš„å€™é€‰é›†ä¾ç„¶ä½¿ç”¨ encode() æˆ– encode_corpus() å‡½æ•°</span></span><br><span class="line">queries = [<span class="string">&#x27;query_1&#x27;</span>, <span class="string">&#x27;query_2&#x27;</span>]</span><br><span class="line">passages = [<span class="string">&quot;æ ·ä¾‹æ®µè½-1&quot;</span>, <span class="string">&quot;æ ·ä¾‹æ®µè½-2&quot;</span>]</span><br><span class="line">q_embeddings = model.encode_queries(queries)</span><br><span class="line">p_embeddings = model.encode(passages)</span><br><span class="line">scores = q_embeddings @ p_embeddings.T</span><br></pre></td></tr></table></figure>

<p>Instructionå‚æ•° <code>query_instruction_for_retrieval</code> è¯·å‚ç…§ï¼š <a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list">Model List</a>.</p>
<p>ä¸ºæé«˜æ•ˆç‡ï¼ŒFlagModelé»˜è®¤ä¼šä½¿ç”¨æ‰€æœ‰çš„GPUè¿›è¡Œæ¨ç†ã€‚å¦‚æœæƒ³è¦ä½¿ç”¨å…·ä½“çš„GPUï¼Œè¯·è®¾ç½®<code>os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;]</code>ã€‚</p>
<ul>
<li><strong>Sentence-Transformers</strong></li>
</ul>
<p>å®‰è£… <a target="_blank" rel="noopener" href="https://www.sbert.net/">sentence-transformers</a>:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U sentence-transformers</span><br></pre></td></tr></table></figure>

<p>åŸºäºSentence-Transformersçš„ä½¿ç”¨æ–¹æ³•:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line">sentences = [<span class="string">&quot;æ ·ä¾‹æ•°æ®-1&quot;</span>, <span class="string">&quot;æ ·ä¾‹æ•°æ®-2&quot;</span>]</span><br><span class="line">model = SentenceTransformer(<span class="string">&#x27;BAAI/bge-large-zh&#x27;</span>)</span><br><span class="line">embeddings_1 = model.encode(sentences, normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">embeddings_2 = model.encode(sentences, normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">smilarity = embeddings_1 @ embeddings_2.T</span><br><span class="line"><span class="built_in">print</span>(smilarity)</span><br></pre></td></tr></table></figure>

<p>å¯¹äºæ£€ç´¢ä»»åŠ¡ï¼Œ æ¯ä¸ªæŸ¥è¯¢éƒ½åº”è¯¥ä»¥ä¸€æ¡æŒ‡ä»¤å¼€å§‹(æŒ‡ä»¤å‚è€ƒ <a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list">Model List</a>). ä½†å¯¹äºæ–‡æ¡£ï¼Œä¸éœ€è¦æ·»åŠ ä»»ä½•æŒ‡ä»¤ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">queries = [<span class="string">&quot;æ‰‹æœºå¼€ä¸äº†æœºæ€ä¹ˆåŠï¼Ÿ&quot;</span>] </span><br><span class="line">passages = [<span class="string">&quot;æ ·ä¾‹æ®µè½-1&quot;</span>, <span class="string">&quot;æ ·ä¾‹æ®µè½-2&quot;</span>] </span><br><span class="line">instruction = <span class="string">&quot;ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š&quot;</span> </span><br><span class="line">model = SentenceTransformer(<span class="string">&#x27;BAAI/bge-large-zh&#x27;</span>) </span><br><span class="line">q_embeddings = model.encode([instruction+q <span class="keyword">for</span> q <span class="keyword">in</span> queries], normalize_embeddings=<span class="literal">True</span>) </span><br><span class="line">p_embeddings = model.encode(passages, normalize_embeddings=<span class="literal">True</span>) </span><br><span class="line">scores = q_embeddings @ p_embeddings.T</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>With Langchain</strong></li>
</ul>
<p>åœ¨Langchianä¸­ä½¿ç”¨bgeæ¨¡å‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings <span class="keyword">import</span> HuggingFaceInstructEmbeddings</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">model = HuggingFaceInstructEmbeddings(model_name=<span class="string">&#x27;BAAI/bge-large-en&#x27;</span>,</span><br><span class="line">                                      embed_instruction=<span class="string">&quot;&quot;</span>,</span><br><span class="line">                                      query_instruction=<span class="string">&quot;Represent this sentence for searching relevant passages: &quot;</span>,</span><br><span class="line">                                      encode_kwargs=encode_kwargs)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>HuggingFace Transformers</strong></li>
</ul>
<p>ä½¿ç”¨transformersåº“æ—¶ï¼Œæ‚¨å¯ä»¥è¿™æ ·ä½¿ç”¨æ¨¡å‹:é¦–å…ˆï¼Œå°†è¾“å…¥ä¼ é€’ç»™transformeræ¨¡å‹ï¼Œç„¶åé€‰æ‹©ç¬¬ä¸€ä¸ªæ ‡è®°çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€(å³[CLS])ä½œä¸ºå¥å­åµŒå…¥ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># Sentences we want sentence embeddings for</span></span><br><span class="line">sentences = [<span class="string">&quot;æ ·ä¾‹æ•°æ®-1&quot;</span>, <span class="string">&quot;æ ·ä¾‹æ•°æ®-2&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load model from HuggingFace Hub</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&#x27;BAAI/bge-large-zh&#x27;</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&#x27;BAAI/bge-large-zh&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenize sentences</span></span><br><span class="line">encoded_input = tokenizer(sentences, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br><span class="line"><span class="comment"># for retrieval task, add an instruction to query (not add instruction for passages)</span></span><br><span class="line"><span class="comment"># encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors=&#x27;pt&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute embeddings</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    model_output = model(**encoded_input)</span><br><span class="line">    <span class="comment"># Perform pooling. In this case, cls pooling.</span></span><br><span class="line">    sentence_embeddings = model_output[<span class="number">0</span>][:, <span class="number">0</span>]</span><br><span class="line"><span class="comment"># normalize embeddings</span></span><br><span class="line">sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sentence embeddings:&quot;</span>, sentence_embeddings)</span><br></pre></td></tr></table></figure>

<h4 id="è¯„ä¼°"><a href="#è¯„ä¼°" class="headerlink" title="è¯„ä¼°"></a>è¯„ä¼°</h4><p><code>baai-general-embedding</code> æ¨¡å‹åœ¨MTEBå’ŒC-MTEBæ’è¡Œæ¦œä¸Šéƒ½å®ç°äº†<strong>æœ€å…ˆè¿›çš„æ€§èƒ½</strong>! æ›´å¤šç»†èŠ‚å’Œè¯„ä¼°è„šæœ¬è¯·å‚è§ <a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB">C_MTEB</a>.</p>
<ul>
<li><strong>MTEB</strong>:</li>
</ul>
<table>
<thead>
<tr>
<th>Model Name</th>
<th>Dimension</th>
<th>Sequence Length</th>
<th>Average (56)</th>
<th>Retrieval (15)</th>
<th>Clustering (11)</th>
<th>Pair Classification (3)</th>
<th>Reranking (4)</th>
<th>STS (10)</th>
<th>Summarization (1)</th>
<th>Classification (12)</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-en"><strong>bge-large-en</strong></a></td>
<td>1024</td>
<td>512</td>
<td><strong>63.98</strong></td>
<td><strong>53.9</strong></td>
<td><strong>46.98</strong></td>
<td>85.8</td>
<td><strong>59.48</strong></td>
<td>81.56</td>
<td>32.06</td>
<td><strong>76.21</strong></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-base-en"><strong>bge-base-en</strong></a></td>
<td>768</td>
<td>512</td>
<td>63.36</td>
<td>53.0</td>
<td>46.32</td>
<td>85.86</td>
<td>58.7</td>
<td>81.84</td>
<td>29.27</td>
<td>75.27</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/thenlper/gte-large">gte-large</a></td>
<td>1024</td>
<td>512</td>
<td>63.13</td>
<td>52.22</td>
<td>46.84</td>
<td>85.00</td>
<td>59.13</td>
<td>83.35</td>
<td>31.66</td>
<td>73.33</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/thenlper/gte-base">gte-base</a></td>
<td>768</td>
<td>512</td>
<td>62.39</td>
<td>51.14</td>
<td>46.2</td>
<td>84.57</td>
<td>58.61</td>
<td>82.3</td>
<td>31.17</td>
<td>73.01</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/intfloat/e5-large-v2">e5-large-v2</a></td>
<td>1024</td>
<td>512</td>
<td>62.25</td>
<td>50.56</td>
<td>44.49</td>
<td>86.03</td>
<td>56.61</td>
<td>82.05</td>
<td>30.19</td>
<td>75.24</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-small-en"><strong>bge-small-en</strong></a></td>
<td>384</td>
<td>512</td>
<td>62.11</td>
<td>51.82</td>
<td>44.31</td>
<td>83.78</td>
<td>57.97</td>
<td>80.72</td>
<td>30.53</td>
<td>74.37</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/hkunlp/instructor-xl">instructor-xl</a></td>
<td>768</td>
<td>512</td>
<td>61.79</td>
<td>49.26</td>
<td>44.74</td>
<td>86.62</td>
<td>57.29</td>
<td>83.06</td>
<td>32.32</td>
<td>61.79</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/intfloat/e5-base-v2">e5-base-v2</a></td>
<td>768</td>
<td>512</td>
<td>61.5</td>
<td>50.29</td>
<td>43.80</td>
<td>85.73</td>
<td>55.91</td>
<td>81.05</td>
<td>30.28</td>
<td>73.84</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/thenlper/gte-small">gte-small</a></td>
<td>384</td>
<td>512</td>
<td>61.36</td>
<td>49.46</td>
<td>44.89</td>
<td>83.54</td>
<td>57.7</td>
<td>82.07</td>
<td>30.42</td>
<td>72.31</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/embeddings">text-embedding-ada-002</a></td>
<td>1536</td>
<td>8192</td>
<td>60.99</td>
<td>49.25</td>
<td>45.9</td>
<td>84.89</td>
<td>56.32</td>
<td>80.97</td>
<td>30.8</td>
<td>70.93</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/intfloat/e5-base-v2">e5-small-v2</a></td>
<td>384</td>
<td>512</td>
<td>59.93</td>
<td>49.04</td>
<td>39.92</td>
<td>84.67</td>
<td>54.32</td>
<td>80.39</td>
<td>31.16</td>
<td>72.94</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers/sentence-t5-xxl">sentence-t5-xxl</a></td>
<td>768</td>
<td>512</td>
<td>59.51</td>
<td>42.24</td>
<td>43.72</td>
<td>85.06</td>
<td>56.42</td>
<td>82.63</td>
<td>30.08</td>
<td>73.42</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">all-mpnet-base-v2</a></td>
<td>768</td>
<td>514</td>
<td>57.78</td>
<td>43.81</td>
<td>43.69</td>
<td>83.04</td>
<td>59.36</td>
<td>80.28</td>
<td>27.49</td>
<td>65.07</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco">sgpt-bloom-7b1-msmarco</a></td>
<td>4096</td>
<td>2048</td>
<td>57.59</td>
<td>48.22</td>
<td>38.93</td>
<td>81.9</td>
<td>55.65</td>
<td>77.74</td>
<td>33.6</td>
<td>66.19</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2">all-MiniLM-L12-v2</a></td>
<td>384</td>
<td>512</td>
<td>56.53</td>
<td>42.69</td>
<td>41.81</td>
<td>82.41</td>
<td>58.44</td>
<td>79.8</td>
<td>27.9</td>
<td>63.21</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">all-MiniLM-L6-v2</a></td>
<td>384</td>
<td>512</td>
<td>56.26</td>
<td>41.95</td>
<td>42.35</td>
<td>82.37</td>
<td>58.04</td>
<td>78.9</td>
<td>30.81</td>
<td>63.05</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/nthakur/contriever-base-msmarco">contriever-base-msmarco</a></td>
<td>768</td>
<td>512</td>
<td>56.00</td>
<td>41.88</td>
<td>41.1</td>
<td>82.54</td>
<td>53.14</td>
<td>76.51</td>
<td>30.36</td>
<td>66.68</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/sentence-transformers/sentence-t5-base">sentence-t5-base</a></td>
<td>768</td>
<td>512</td>
<td>55.27</td>
<td>33.63</td>
<td>40.21</td>
<td>85.18</td>
<td>53.09</td>
<td>81.14</td>
<td>31.39</td>
<td>69.81</td>
</tr>
</tbody></table>
<ul>
<li><strong>C-MTEB</strong>:</li>
</ul>
<p>æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªä¸­æ–‡æ–‡æœ¬åµŒå…¥çš„åŸºå‡†æµ‹è¯•é›†åˆC-MTEBï¼Œå…¶åŒ…æ‹¬6ä¸ªä»»åŠ¡çš„31ä¸ªæ•°æ®é›†ã€‚ è¯·å‚é˜…<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md">C_MTEB</a>è·å–è¯¦ç»†ä»‹ç»ã€‚</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Embedding dimension</th>
<th>Avg</th>
<th>Retrieval</th>
<th>STS</th>
<th>PairClassification</th>
<th>Classification</th>
<th>Reranking</th>
<th>Clustering</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-zh"><strong>bge-large-zh</strong></a></td>
<td>1024</td>
<td><strong>64.20</strong></td>
<td><strong>71.53</strong></td>
<td><strong>53.23</strong></td>
<td><strong>78.94</strong></td>
<td>72.26</td>
<td><strong>65.11</strong></td>
<td>48.39</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-zh-noinstruct"><strong>bge-large-zh-noinstruct</strong></a></td>
<td>1024</td>
<td>63.53</td>
<td>70.55</td>
<td>50.98</td>
<td>76.77</td>
<td><strong>72.49</strong></td>
<td>64.91</td>
<td><strong>50.01</strong></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-base-zh"><strong>BAAI&#x2F;bge-base-zh</strong></a></td>
<td>768</td>
<td>62.96</td>
<td>69.53</td>
<td>52.05</td>
<td>77.5</td>
<td>70.98</td>
<td>64.91</td>
<td>47.63</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-small-zh"><strong>BAAI&#x2F;bge-small-zh</strong></a></td>
<td>512</td>
<td>58.27</td>
<td>63.07</td>
<td>46.87</td>
<td>70.35</td>
<td>67.78</td>
<td>61.48</td>
<td>45.09</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/moka-ai/m3e-base">m3e-base</a></td>
<td>768</td>
<td>57.10</td>
<td>56.91</td>
<td>48.15</td>
<td>63.99</td>
<td>70.28</td>
<td>59.34</td>
<td>47.68</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/moka-ai/m3e-large">m3e-large</a></td>
<td>1024</td>
<td>57.05</td>
<td>54.75</td>
<td>48.64</td>
<td>64.3</td>
<td>71.22</td>
<td>59.66</td>
<td>48.88</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings">text-embedding-ada-002(OpenAI)</a></td>
<td>1536</td>
<td>53.02</td>
<td>52.0</td>
<td>40.61</td>
<td>69.56</td>
<td>67.38</td>
<td>54.28</td>
<td>45.68</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/silk-road/luotuo-bert-medium">luotuo</a></td>
<td>1024</td>
<td>49.37</td>
<td>44.4</td>
<td>39.41</td>
<td>66.62</td>
<td>65.29</td>
<td>49.25</td>
<td>44.39</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/shibing624/text2vec-base-chinese">text2vec</a></td>
<td>768</td>
<td>47.63</td>
<td>38.79</td>
<td>41.71</td>
<td>67.41</td>
<td>65.18</td>
<td>49.45</td>
<td>37.66</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/GanymedeNil/text2vec-large-chinese">text2vec-large</a></td>
<td>1024</td>
<td>47.36</td>
<td>41.94</td>
<td>41.98</td>
<td>70.86</td>
<td>63.42</td>
<td>49.16</td>
<td>30.02</td>
</tr>
</tbody></table>
<h4 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>æœ¬èŠ‚å°†ä»‹ç»æˆ‘ä»¬ç”¨äºè®­ç»ƒé€šç”¨åµŒå…¥å‘é‡çš„æ–¹æ³•ã€‚ è®­ç»ƒè„šæœ¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding">FlagEmbedding</a>ä¸­ã€‚ åŒæ—¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€äº›ç¤ºä¾‹æ¥è¿›è¡Œ<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/examples/pretrain">é¢„è®­ç»ƒ</a>å’Œ<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/examples/finetune">å¾®è°ƒ</a>ã€‚</p>
<p><strong>1. RetroMAE Pre-train</strong></p>
<p>æˆ‘ä»¬æŒ‰ç…§ <a target="_blank" rel="noopener" href="https://github.com/staoxiao/RetroMAE">retromae</a> æ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œ å…¶åœ¨æ£€ç´¢ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†è‰¯å¥½çš„æ€§èƒ½( <a target="_blank" rel="noopener" href="https://aclanthology.org/2022.emnlp-main.35.pdf">å‚è€ƒè®ºæ–‡</a> )ã€‚ é¢„è®­ç»ƒæ˜¯åœ¨24å—A100(40G) gpuä¸Šè¿›è¡Œçš„ï¼Œbatchå¤§å°ä¸º720ã€‚åœ¨retromaeä¸­ï¼Œç¼–ç å™¨å’Œè§£ç å™¨çš„æ©ç ç‡åˆ†åˆ«ä¸º0.3å’Œ0.5ã€‚ ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸º2e-5ã€‚</p>
<p><strong>Pre-training data</strong>:</p>
<ul>
<li>English:<ul>
<li><a target="_blank" rel="noopener" href="https://pile.eleuther.ai/">Pile</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/wikipedia">wikipedia</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/Tevatron/msmarco-passage-corpus">msmarco</a></li>
</ul>
</li>
<li>Chinese:<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/BAAI-WuDao/Data">wudao</a></li>
</ul>
</li>
</ul>
<p><strong>2. Finetune</strong></p>
<p>æˆ‘ä»¬ä½¿ç”¨å¯¹æ¯”å­¦ä¹ è®­ç»ƒæ¨¡å‹ï¼Œè¾“å…¥æ•°æ®çš„æ ¼å¼æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„â€™ (query, positive, negative) â€˜ã€‚ é™¤äº†ä¸‰å…ƒç»„ä¸­çš„è´Ÿæ ·æœ¬ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨äº†in-batchçš„è´Ÿæ ·æœ¬ã€‚æˆ‘ä»¬é‡‡ç”¨ <a target="_blank" rel="noopener" href="https://github.com/microsoft/MoPQ">è·¨è®¾å¤‡è´Ÿæ ·æœ¬å…±äº«æ–¹æ³•</a> åœ¨ä¸åŒçš„gpuä¹‹é—´å…±äº«è´Ÿæ ·æœ¬ï¼Œè¿™ä¼šæ˜¾è‘—åœ°<strong>å¢åŠ è´Ÿæ ·æœ¬çš„æ•°é‡</strong>ã€‚ æˆ‘ä»¬åœ¨48å—A100(40G) gpuä¸Šè®­ç»ƒæ¨¡å‹ï¼Œbatchå¤§å°ä¸º32,768ã€‚ æˆ‘ä»¬ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸º1e-5ã€‚ å¯¹æ¯”æŸå¤±çš„æ¸©åº¦ç³»æ•°ä¸º0.01ã€‚</p>
<p>åŒæ—¶ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒä¸­ä¸ºæ£€ç´¢ä»»åŠ¡çš„æŸ¥è¯¢æ·»åŠ äº†instructionã€‚ å¯¹äºè‹±è¯­ï¼ŒæŒ‡ä»¤æ˜¯<code>Represent this sentence for searching relevant passages: </code>; å¯¹äºä¸­æ–‡ï¼ŒæŒ‡ä»¤æ˜¯<code>ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š</code>. åœ¨è¯„æµ‹ä¸­ï¼Œé’ˆå¯¹æ®µè½æ£€ç´¢ä»»åŠ¡çš„ä»»åŠ¡éœ€è¦åœ¨æŸ¥è¯¢ä¸­æ·»åŠ æŒ‡ä»¤ï¼Œä½†ä¸éœ€è¦ä¸ºæ®µè½æ–‡æ¡£æ·»åŠ æŒ‡ä»¤ã€‚</p>
<p>å¾®è°ƒè„šæœ¬å¯ä»¥åœ¨è¿™ä¸ªå­˜å‚¨åº“ä¸­è®¿é—®:<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding">FlagEmbedding</a>, ä½ å¯ä»¥ç”¨å®ƒè½»æ¾åœ°å¾®è°ƒä½ çš„æ¨¡å‹ã€‚</p>
<p><strong>Training data</strong>:</p>
<p>-å¯¹äºè‹±è¯­ï¼Œæˆ‘ä»¬ä» <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/wikipedia">wikipedia</a> ï¼Œ <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/cc_net">cc-net</a> ç­‰æ”¶é›†äº†2.3äº¿ä¸ªæ–‡æœ¬å¯¹ã€‚ </p>
<p>-å¯¹äºä¸­æ–‡ï¼Œæˆ‘ä»¬ä» <a target="_blank" rel="noopener" href="https://github.com/BAAI-WuDao/Data">æ‚Ÿé“</a> ã€<a target="_blank" rel="noopener" href="https://github.com/CLUEbenchmark/SimCLUE">simclue</a>ç­‰æ”¶é›†äº†1.2äº¿å¯¹æ–‡æœ¬ã€‚</p>
<p>æˆ‘ä»¬è®¡åˆ’åœ¨å°†æ¥å‘å¸ƒè®­ç»ƒæ•°æ®é›†ã€‚</p>
<h1 id="LLMè®­ç»ƒæŠ€æœ¯"><a href="#LLMè®­ç»ƒæŠ€æœ¯" class="headerlink" title="LLMè®­ç»ƒæŠ€æœ¯"></a>LLMè®­ç»ƒæŠ€æœ¯</h1><h2 id="FlashAttention"><a href="#FlashAttention" class="headerlink" title="FlashAttention"></a>FlashAttention</h2><p>ä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/Dao-AILab/flash-attention">https://github.com/Dao-AILab/flash-attention</a></p>
<p>åšå®¢ï¼š<a target="_blank" rel="noopener" href="https://together.ai/blog/tri-dao-flash-attention">https://together.ai/blog/tri-dao-flash-attention</a></p>
<h3 id="FlashAttention-1"><a href="#FlashAttention-1" class="headerlink" title="FlashAttention-1"></a>FlashAttention-1</h3><p>FlashAttention æ˜¯ä¸€ç§ç®—æ³•ï¼Œå®ƒå¯¹æ³¨æ„åŠ›è®¡ç®—è¿›è¡Œé‡æ–°æ’åºï¼Œå¹¶åˆ©ç”¨ç»å…¸æŠ€æœ¯ï¼ˆå¹³é“ºã€é‡æ–°è®¡ç®—ï¼‰æ¥æ˜¾ç€åŠ å¿«é€Ÿåº¦ï¼Œå¹¶å°†åºåˆ—é•¿åº¦çš„å†…å­˜ä½¿ç”¨é‡ä»äºŒæ¬¡å‡å°‘åˆ°çº¿æ€§ã€‚å¹³é“ºæ„å‘³ç€æˆ‘ä»¬å°†è¾“å…¥å—ä» HBMï¼ˆGPU å†…å­˜ï¼‰åŠ è½½åˆ° SRAMï¼ˆå¿«é€Ÿç¼“å­˜ï¼‰ï¼Œå¯¹è¯¥å—æ‰§è¡Œæ³¨æ„ï¼Œå¹¶åœ¨ HBM ä¸­æ›´æ–°è¾“å‡ºã€‚é€šè¿‡ä¸å°†å¤§å‹ä¸­é—´æ³¨æ„åŠ›çŸ©é˜µå†™å…¥ HBMï¼Œæˆ‘ä»¬å‡å°‘äº†å†…å­˜è¯»å–&#x2F;å†™å…¥é‡ï¼Œä»è€Œå¸¦æ¥äº† 2-4 å€çš„æŒ‚é’Ÿæ—¶é—´åŠ é€Ÿã€‚</p>
<blockquote>
<p>FlashAttention is an algorithm that reorders the attention computation and leverages classical techniques (tiling, recomputation) to significantly speed it up and reduce memory usage from quadratic to linear in sequence length. Tiling means that we load blocks of inputs from HBM (GPU memory) to SRAM (fast cache), perform attention with respect to that block, and update the output in HBM. By not writing the large intermediate attention matrices to HBM, we reduce the amount of memory reads&#x2F;writes, which brings 2-4x wallclock time speedup.</p>
</blockquote>
<p><img src="/images/image-20230809113601442.png" alt="Diagram of FlashAttention forward pass: with tiling and softmax rescaling, we operate by blocks and avoid having to read/write from HBM, while obtaining the correct output with no approximation."></p>
<p>ç”±äºGPUä¸Šä¸åŒçº¿ç¨‹å—å’Œwarpä¹‹é—´çš„æ¬¡ä¼˜å·¥ä½œåˆ†åŒºï¼ŒFlashAttentionä»ç„¶æ•ˆç‡ä½ä¸‹ï¼Œå¯¼è‡´å ç”¨ç‡ä½æˆ–ä¸å¿…è¦çš„å…±äº«å†…å­˜è¯»å–&#x2F;å†™å…¥</p>
<blockquote>
<p>However, FlashAttention still has some inefficiency <strong><u>due to suboptimal work partitioning between different thread blocks and warps on the GPU</u></strong>, causing either low-occupancy or unnecessary shared memory reads&#x2F;writes.</p>
</blockquote>
<h3 id="FlashAttention-2"><a href="#FlashAttention-2" class="headerlink" title="FlashAttention-2"></a>FlashAttention-2</h3><blockquote>
<p>FlashAttention-2: Better algorithm, parallelism, and work partitioning</p>
</blockquote>
<p>å°½ç®¡FlashAttentionåœ¨å‘å¸ƒæ—¶å·²ç»æ¯”ä¼˜åŒ–çš„åŸºçº¿å¿«2-4å€ï¼Œä½†å®ƒä»ç„¶æœ‰ç›¸å½“å¤§çš„ç©ºé—´ã€‚FlashAttention ä»ç„¶ä¸å¦‚ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³• ï¼ˆGEMMï¼‰ è¿ç®—å¿«ï¼Œä»…è¾¾åˆ°ç†è®ºæœ€å¤§ FLOPs&#x2F;s çš„ 25-40%ï¼ˆä¾‹å¦‚ï¼Œåœ¨ A100 GPU ä¸Šé«˜è¾¾ 124 TFLOPs&#x2F;sï¼‰</p>
<p>FlashAttention-2å®Œå…¨ä»å¤´å¼€å§‹é‡å†™ï¼Œä½¿ç”¨Nvidiaçš„<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cutlass">CUTLASS</a> 3.xåŠå…¶æ ¸å¿ƒåº“ <a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/00_quickstart.md">CuTe</a>çš„åŸè¯­ï¼Œæ¯”ä»¥å‰çš„ç‰ˆæœ¬å¿«çº¦2å€ï¼Œåœ¨A100 GPUï¼ˆFP16 &#x2F; BF16ï¼‰ä¸Šè¾¾åˆ°230 TFLOP &#x2F; sã€‚å½“ä½¿ç”¨ç«¯åˆ°ç«¯æ¥è®­ç»ƒ GPT é£æ ¼çš„è¯­è¨€æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬çš„è®­ç»ƒé€Ÿåº¦é«˜è¾¾ 225 TFLOP&#x2F;sï¼ˆæ¨¡å‹ FLOP åˆ©ç”¨ç‡ä¸º 72%ï¼‰ã€‚åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†FlashAttentionçš„ä¸€äº›ç“¶é¢ˆï¼Œä»¥åŠæˆ‘ä»¬å¦‚ä½•åˆ©ç”¨æ›´å¥½çš„å¹¶è¡Œæ€§å’Œå·¥ä½œåˆ†åŒºæ¥è·å¾—æ˜¾ç€çš„åŠ é€Ÿã€‚</p>
<p><strong>Fewer non-matmul FLOPs. æ›´å°‘çš„éçŸ©é˜µ FLOPã€‚</strong> </p>
<blockquote>
<p>æˆ‘ä»¬è°ƒæ•´äº†FlashAttentionçš„ç®—æ³•ï¼Œä»¥å‡å°‘éçŸ©é˜µFLOPçš„æ•°é‡ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºç°ä»£GPUå…·æœ‰ä¸“é—¨çš„è®¡ç®—å•å…ƒï¼ˆä¾‹å¦‚ï¼ŒNvidia GPUä¸Šçš„Tensor Coresï¼‰ï¼Œè¿™ä½¿å¾—matmulæ›´å¿«ã€‚ä¾‹å¦‚ï¼ŒFP16&#x2F;BF16 çŸ©é˜µè¿ç®—ï¼ŒA100 GPU çš„æœ€å¤§ç†è®ºååé‡ä¸º 312 TFLOP&#x2F;s ï¼Œä½†éçŸ©é˜µ FP32 çš„æœ€å¤§ç†è®ºååé‡ä»…ä¸º 19.5 TFLOP&#x2F;sã€‚å¦ä¸€ç§æ€è€ƒæ–¹å¼æ˜¯ï¼Œæ¯ä¸ªéçŸ©é˜µ FLOP æ¯”çŸ©é˜µ FLOP è´µ 16 å€ã€‚ä¸ºäº†ä¿æŒé«˜ååï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ matmul FLOP ä¸ŠèŠ±è´¹å°½å¯èƒ½å¤šçš„æ—¶é—´ã€‚</p>
<p>æˆ‘ä»¬åœ¨ä¸æ”¹è¾“å‡ºçš„æƒ…å†µä¸‹ï¼Œé‡å†™äº† FlashAttention ä¸­ä½¿ç”¨çš„åœ¨çº¿ softmax æŠ€å·§ï¼ˆonline softmax trickï¼‰ï¼Œä»¥å‡å°‘é‡æ–°ç¼©æ”¾æ“ä½œï¼ˆrescaling opsï¼‰çš„æ•°é‡ï¼Œä»¥åŠè¾¹ç•Œæ£€æŸ¥ï¼ˆbound-checking ï¼‰å’Œå› æœæ©è”½æ“ä½œï¼ˆcausal masking operationsï¼‰ã€‚</p>
</blockquote>
<p><strong>Better Parallelism. æ›´å¥½çš„å¹¶è¡Œæ€§ã€‚</strong> </p>
<blockquote>
<p>FlashAttention çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬åœ¨batch sizeå’Œheadæ•°é‡ä¸Šå¹¶è¡ŒåŒ–ã€‚æˆ‘ä»¬ä½¿ç”¨ 1 ä¸ªçº¿ç¨‹å—æ¥å¤„ç†ä¸€ä¸ªæ³¨æ„åŠ›å¤´ï¼Œå¹¶ä¸”æ€»ä½“ï¼ˆbatch_size * ä¸ªå¤´ï¼‰çº¿ç¨‹å—ã€‚æ¯ä¸ªçº¿ç¨‹å—éƒ½è®¡åˆ’åœ¨æµå¼å¤šå¤„ç†å™¨ ï¼ˆSM,streaming multiprocessorï¼‰ ä¸Šè¿è¡Œï¼Œä¾‹å¦‚ï¼ŒA100 GPU ä¸Šæœ‰ 108 ä¸ªè¿™æ ·çš„ SMã€‚å½“è¿™ä¸ªæ•°å­—å¾ˆå¤§ï¼ˆæ¯”å¦‚ &gt;&#x3D; 80ï¼‰æ—¶ï¼Œè¿™ç§è°ƒåº¦æ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°ä½¿ç”¨ GPU ä¸Šå‡ ä¹æ‰€æœ‰çš„è®¡ç®—èµ„æºã€‚</p>
<p>å¯¹äºé•¿åºåˆ—ï¼ˆé€šå¸¸æ„å‘³ç€å°batch sizeæˆ–å°‘é‡headï¼‰ï¼Œä¸ºäº†æ›´å¥½åœ°åˆ©ç”¨ GPU ä¸Šçš„å¤šå¤„ç†å™¨ï¼Œæˆ‘ä»¬ç°åœ¨å¦å¤–åœ¨åºåˆ—é•¿åº¦ç»´åº¦ä¸Šè¿›è¡Œå¹¶è¡ŒåŒ–ã€‚è¿™å¤§å¤§åŠ å¿«äº†è¿™ä¸€åˆ¶åº¦çš„å‘å±•é€Ÿåº¦ã€‚</p>
</blockquote>
<p><strong>Better Work Partitioning. æ›´å¥½çš„å·¥ä½œåˆ†åŒºã€‚</strong> </p>
<blockquote>
<p>å³ä½¿åœ¨æ¯ä¸ªçº¿ç¨‹å—ä¸­ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»å†³å®šå¦‚ä½•åœ¨ä¸åŒçš„ warpsï¼ˆä¸€ç»„ 32 ä¸ªçº¿ç¨‹ä¸€èµ·å·¥ä½œï¼‰ä¹‹é—´åˆ’åˆ†å·¥ä½œã€‚æˆ‘ä»¬é€šå¸¸æ¯ä¸ªçº¿ç¨‹å—ä½¿ç”¨ 4 æˆ– 8 ä¸ªwarpsï¼Œåˆ†åŒºæ–¹æ¡ˆå¦‚ä¸‹æ‰€è¿°ã€‚æˆ‘ä»¬åœ¨ FlashAttention-2 ä¸­æ”¹è¿›äº†è¿™ç§åˆ†åŒºï¼Œä»¥å‡å°‘ä¸åŒwarpsä¹‹é—´çš„åŒæ­¥å’Œé€šä¿¡é‡(synchronization and communication)ï¼Œä»è€Œå‡å°‘å…±äº«å†…å­˜è¯»å–&#x2F;å†™å…¥ã€‚</p>
</blockquote>
<p><img src="/images/image-20230809115137501.png" alt="image-20230809115137501"></p>
<blockquote>
<p>å¯¹äºæ¯ä¸ªå—ï¼ŒFlashAttention å°† K å’Œ V æ‹†åˆ†ä¸º 4 ä¸ªwarpsï¼ŒåŒæ—¶ä¿æŒæ‰€æœ‰warpséƒ½èƒ½è®¿é—® Qã€‚è¿™ç§°ä¸ºâ€œåˆ‡ç‰‡ Kâ€æ–¹æ¡ˆ(â€œsliced-Kâ€)ã€‚ä½†æ˜¯ï¼Œè¿™æ˜¯ä½æ•ˆçš„ï¼Œå› ä¸ºæ‰€æœ‰warpséƒ½éœ€è¦å°†å…¶ä¸­é—´ç»“æœå†™å…¥å…±äº«å†…å­˜ï¼ŒåŒæ­¥ï¼Œç„¶åå°†ä¸­é—´ç»“æœç›¸åŠ ã€‚è¿™äº›å…±äº«å†…å­˜è¯»å–&#x2F;å†™å…¥ä¼šå‡æ…¢ FlashAttention ä¸­çš„æ­£å‘ä¼ é€’é€Ÿåº¦ã€‚</p>
<p>åœ¨ FlashAttention-2 ä¸­ï¼Œæˆ‘ä»¬å°† Q æ‹†åˆ†ä¸º 4 ä¸ªwarpsï¼ŒåŒæ—¶ä¿æŒæ‰€æœ‰warpséƒ½èƒ½è®¿é—® K å’Œ Vã€‚åœ¨æ¯ä¸ªwarpæ‰§è¡ŒçŸ©é˜µä¹˜æ³•ä»¥è·å¾— Q K^T åˆ‡ç‰‡åï¼Œå®ƒä»¬åªéœ€è¦ä¸ V çš„å…±äº«åˆ‡ç‰‡ç›¸ä¹˜å³å¯è·å¾—ç›¸åº”çš„è¾“å‡ºåˆ‡ç‰‡ã€‚warpä¹‹é—´ä¸éœ€è¦é€šä¿¡ã€‚å…±äº«å†…å­˜è¯»&#x2F;å†™çš„å‡å°‘å¯åŠ å¿«é€Ÿåº¦ã€‚</p>
</blockquote>
<p><strong>New features: head dimensions up to 256, multi-query attention æ–°åŠŸèƒ½ï¼šå¤´ç»´åº¦å¯è¾¾256ï¼Œå¤šæŸ¥è¯¢æ³¨æ„</strong></p>
<blockquote>
<p>FlashAttentionä»…æ”¯æŒé«˜è¾¾128çš„head dimensionsï¼Œè¿™é€‚ç”¨äºå¤§å¤šæ•°å‹å·ï¼Œä½†å°‘æ•°è¢«æ’é™¤åœ¨å¤–ã€‚FlashAttention-2ç°åœ¨æ”¯æŒé«˜è¾¾256çš„head dimensionsï¼Œè¿™æ„å‘³ç€GPT-Jï¼ŒCodeGenå’ŒCodeGen2ä»¥åŠStableDiffusion 1.xç­‰å‹å·å¯ä»¥ä½¿ç”¨FlashAttention-2æ¥åŠ é€Ÿå’ŒèŠ‚çœå†…å­˜ã€‚</p>
<p>è¿™ä¸ªæ–°ç‰ˆæœ¬è¿˜æ”¯æŒå¤šæŸ¥è¯¢æ³¨æ„åŠ› ï¼ˆMQA,<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.02150">multi-query attention</a>ï¼‰ ä»¥åŠåˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› ï¼ˆGQA,<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.13245">grouped-query attention</a> ï¼‰ã€‚è¿™äº›æ˜¯attentionçš„å˜ä½“ï¼Œå…¶ä¸­å¤šä¸ªæŸ¥è¯¢å¤´å…³æ³¨åŒä¸€é”®å’Œå€¼å¤´ï¼Œ**<u>ä»¥ä¾¿åœ¨æ¨ç†æœŸé—´å‡å° KV ç¼“å­˜çš„å¤§å°ï¼Œå¹¶å¯ä»¥æ˜¾ç€æé«˜æ¨ç†ååé‡ã€‚</u>**</p>
</blockquote>
<p><strong>Attention benchmark</strong></p>
<p>æˆ‘ä»¬åœ¨ A100 80GB SXM4 GPU ä¸Šé’ˆå¯¹ä¸åŒçš„è®¾ç½®ï¼ˆä¸å¸¦&#x2F;å¸¦å› æœæ©ç ï¼Œhead dimensions 64 æˆ– 128ï¼‰æµ‹é‡ä¸åŒæ³¨æ„åŠ›æ–¹æ³•çš„è¿è¡Œæ—¶é—´ã€‚æˆ‘ä»¬çœ‹åˆ° FlashAttention-2 æ¯” FlashAttention å¿« 2 å€å·¦å³ï¼ˆä»¥åŠå®ƒåœ¨ xformers åº“å’Œ Triton ä¸­çš„å…¶ä»–å®ç°ï¼Œä½¿ç”¨æˆªè‡³ 2023 å¹´ 7 æœˆ 14 æ—¥çš„æœ€æ–°å¼€å‘ç‰ˆæœ¬ï¼‰ã€‚ä¸ PyTorch ä¸­çš„æ ‡å‡†æ³¨æ„åŠ›å®ç°ç›¸æ¯”ï¼ŒFlashAttention-2 çš„é€Ÿåº¦å¯ä»¥æé«˜ 9 å€ã€‚</p>
<p>åªéœ€åœ¨ H100 SXM5 GPU ä¸Šè¿è¡Œç›¸åŒçš„å®ç°ï¼ˆä¸ä½¿ç”¨ç‰¹æ®ŠæŒ‡ä»¤æ¥åˆ©ç”¨ TMA å’Œç¬¬å››ä»£Tensor Coresç­‰æ–°ç¡¬ä»¶åŠŸèƒ½ï¼‰ï¼Œæˆ‘ä»¬å°±èƒ½è·å¾—é«˜è¾¾ 335 TFLOP&#x2F;sã€‚</p>
<p>å½“ç”¨äºç«¯åˆ°ç«¯è®­ç»ƒ GPT é£æ ¼çš„æ¨¡å‹æ—¶ï¼ŒFlashAttention-2 æœ‰åŠ©äºåœ¨ A100 GPU ä¸Šå®ç°é«˜è¾¾ 225 TFLOP&#x2F;sï¼ˆæ¨¡å‹ FLOP åˆ©ç”¨ç‡ä¸º 72%ï¼‰ã€‚è¿™æ˜¯1.3å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œæ¯”å·²ç»éå¸¸ä¼˜åŒ–çš„FlashAttentionæ¨¡å‹é«˜ã€‚</p>

      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">è®¡ç®—æœº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/" rel="tag">AI</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1023-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/24/Day1023-The%20Economist/">Day1023-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/24/Day1023-The%20Economist/" class="article-date">
	  <time datetime="2023-07-24T13:19:31.841Z" itemprop="datePublished">ä¸ƒæœˆ 24, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/24/Day1023-The%20Economist/"><img width="250" height="175" src="/images/image-20230724100544248.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 22th 2023 æœŸ Business  æ ç›®
Workplace advice from our agony uncleæ¥è‡ªæˆ‘ä»¬çš„çŸ¥å¿ƒå¤§å”çš„èŒåœºå»ºè®®
Bartlebyå·´æ‰˜æ¯”

From hotdesking to nudity, your office questions answeredä»åŠå…¬æ¡Œè½®æ¢åˆ°è£¸ä½“ï¼Œä½ çš„åŠå…¬å®¤é—®é¢˜å¾—åˆ°äº†è§£ç­”
image: paul ...

        
          <p class="article-more-link">
            <a href="/2023/07/24/Day1023-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1022-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/23/Day1022-The%20Economist/">Day1022-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/23/Day1022-The%20Economist/" class="article-date">
	  <time datetime="2023-07-23T04:02:16.331Z" itemprop="datePublished">ä¸ƒæœˆ 23, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/23/Day1022-The%20Economist/"><img width="250" height="175" src="/images/image-20230723114920737.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 22th 2023 æœŸ Britain  æ ç›®
Voters give Britainâ€™s ruling Conservatives a historic maulingé€‰æ°‘ç»™è‹±å›½æ‰§æ”¿çš„ä¿å®ˆå…šä¸€æ¬¡å†å²æ€§çš„æ‰“å‡»
British politicsè‹±å›½æ”¿æ²»

But a backlash over clean-air policies leaves questions...

        
          <p class="article-more-link">
            <a href="/2023/07/23/Day1022-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1021-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/23/Day1021-The%20Economist/">Day1021-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/23/Day1021-The%20Economist/" class="article-date">
	  <time datetime="2023-07-23T04:00:40.214Z" itemprop="datePublished">ä¸ƒæœˆ 23, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/23/Day1021-The%20Economist/"><img width="250" height="175" src="/images/image-20230722095156129.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 22th 2023 æœŸ Leaders  æ ç›®
The world economy is still in dangerä¸–ç•Œç»æµä»å¤„äºå±é™©ä¹‹ä¸­
Economic optimismç»æµä¹è§‚ä¸»ä¹‰

Falling inflation is good news. But it is too early to hail a â€œsoft landingâ€
â€œsoft la...

        
          <p class="article-more-link">
            <a href="/2023/07/23/Day1021-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-æ­å»ºä¸ªäººæŠ€æœ¯åšå®¢"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/21/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/">Hexo+Githubæ­å»ºä¸ªäººæŠ€æœ¯åšå®¢ï¼ˆMACæ“ä½œç‰ˆï¼‰</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/21/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/" class="article-date">
	  <time datetime="2023-07-21T12:53:54.655Z" itemprop="datePublished">ä¸ƒæœˆ 21, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        

          
            <div class="entry-summary" style="margin-left:0;">
            ç¬¬ä¸€æ¬¡å°è¯•æ­å»ºä¸ªäººæŠ€æœ¯åšå®¢ï¼Œè®°å½•è¸©å‘å®è·µ
ä¸€ã€MACæœ¬æœº
ã€1ã€‘æ‰“å¼€ç»ˆç«¯terminalï¼Œå®‰è£…homebrew
PS: å¦‚æœæ²¡æœ‰æŠ¥é”™ï¼Œå¯ä»¥ç›´æ¥å®‰è£…ï¼›å¦åˆ™å»ºè®®å¸è½½é‡è£…
å¸è½½å‘½ä»¤ï¼š
1$ /bin/bash -c &quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/uninstall.sh)&quot;

å®‰è£…å‘½ä»¤ï¼š
1$ /bin/bash -c &quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/install.sh)&quot;

å¦‚æœé‡åˆ°â€œhomebrew-coreâ€ç›¸å…³çš„é”™è¯¯ï¼Œæˆ–è€…è¿è¡Œå¤ªæ…¢å¡ä½ï¼Œç›´æ¥è¿è¡Œ...
          

        
          <p class="article-more-link">
            <a href="/2023/07/21/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">è®¡ç®—æœº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BC%80%E5%8F%91/" rel="tag">å¼€å‘</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1020-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/15/Day1020-The%20Economist/">Day1020-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/15/Day1020-The%20Economist/" class="article-date">
	  <time datetime="2023-07-15T02:34:32.647Z" itemprop="datePublished">ä¸ƒæœˆ 15, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/15/Day1020-The%20Economist/"><img width="250" height="175" src="/images/image-20230721193603150.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 22th 2023 æœŸ Leaders  æ ç›®
Making babymaking betterFertility technology
IVF is failing most women. But new research holds out hope for the futureè¯•ç®¡å—ç²¾è®©å¤§å¤šæ•°å¥³æ€§å¤±æœ›ã€‚ä½†æ–°çš„ç ”ç©¶ä¸ºæœªæ¥å¸¦æ¥äº†å¸Œæœ›
Jul 20th 2023...

        
          <p class="article-more-link">
            <a href="/2023/07/15/Day1020-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1019-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/15/Day1019-The%20Economist/">Day1019-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/15/Day1019-The%20Economist/" class="article-date">
	  <time datetime="2023-07-15T02:34:28.298Z" itemprop="datePublished">ä¸ƒæœˆ 15, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/15/Day1019-The%20Economist/"><img width="250" height="175" src="/images/image-20230718085522402.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 15th 2023 æœŸ Leaders  æ ç›®
Big pharma is warming to the potential of AIå¤§å‹åˆ¶è¯å…¬å¸å¼€å§‹å…³æ³¨äººå·¥æ™ºèƒ½çš„æ½œåŠ›
Wonder drugsç‰¹æ•ˆè¯

But some worry the Terminator is comingä½†æ˜¯æœ‰äº›äººæ‹…å¿ƒç»ˆç»“è€…å°±è¦æ¥äº†
Jul 13th 202
image: Bryan...

        
          <p class="article-more-link">
            <a href="/2023/07/15/Day1019-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1018-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/15/Day1018-The%20Economist/">Day1018-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/15/Day1018-The%20Economist/" class="article-date">
	  <time datetime="2023-07-15T02:34:24.675Z" itemprop="datePublished">ä¸ƒæœˆ 15, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/15/Day1018-The%20Economist/"><img width="250" height="175" src="/images/image-20230716102725323.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 15th 2023 æœŸ Leaders  æ ç›®
How MAGA Republicans plan to make Donald Trumpâ€™s second term countMAGAå…±å’Œå…šäººè®¡åˆ’è®©å”çº³å¾·Â·ç‰¹æœ—æ™®çš„ç¬¬äºŒä¸ªä»»æœŸæœ‰æ‰€æˆå°±
Preparing for government
They think they know how to banish the...

        
          <p class="article-more-link">
            <a href="/2023/07/15/Day1018-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  
    <article id="post-Day1017-The Economist"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/07/03/Day1017-The%20Economist/">Day1017-The Economist</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2023/07/03/Day1017-The%20Economist/" class="article-date">
	  <time datetime="2023-07-03T01:45:06.394Z" itemprop="datePublished">ä¸ƒæœˆ 3, 2023</time>
	</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        
          <div class="entry-thumbnail">
            <a href="/2023/07/03/Day1017-The%20Economist/"><img width="250" height="175" src="/images/image-20230713210728159.png" class="attachment-thumb-featured size-thumb-featured wp-post-image" alt=""></a>
          </div>
          <div class="entry-summary">
          æ–‡ç« æ¥æºï¼šã€Šç»æµå­¦äººã€‹Jul 15th 2023 æœŸ Business  æ ç›®
Is big business really getting too big?å¤§ä¼ä¸šçœŸçš„ä¼šè¶Šå˜è¶Šå¤§å—ï¼Ÿ
Size warsè§„æ¨¡æˆ˜

In a few sectors, corporate concentration is a problem. In most, it neednâ€™t be
åœ¨ä¸€äº›è¡Œä¸šï¼Œä¼ä¸šâ€œé«˜é›†ä¸­...

        
          <p class="article-more-link">
            <a href="/2023/07/03/Day1017-The%20Economist/#more">é˜…è¯»å…¨æ–‡</a>
          </p>
        </div>
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a></li></ul>

      
            
      
    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

    

  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">ä¸‹ä¸€é¡µ</a>
  </nav>

</section>
          <aside id="sidebar">
  
    <div class="widget-wrap" style="margin: 20px 0;">
	<div id="search-form-wrap">

    <form class="search-form">
        <label style="width: 75%;">
            <span class="screen-reader-text">Search for:</span>
            <input type="search" class="search-field" style="height: 42px;" placeholder=" æœç´¢â€¦" value="" name="s" title="Search for:">
        </label>
        <input type="submit" class="search-form-submit" value="æœç´¢">
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="è¯·è¾“å…¥å…³é”®è¯..."/>
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'æ–‡ç« ',
            PAGES: 'é¡µé¢',
            CATEGORIES: 'åˆ†ç±»',
            TAGS: 'æ ‡ç­¾',
            UNTITLED: '(æ— æ ‡é¢˜)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
</div>
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">è”ç³»æˆ‘ä»¬</h3>
    <div class="widget widget_athemes_social_icons">

    	<ul class="clearfix widget-social-icons">   
    	
          
            <li><a href="mailto:yjchen@hnu.edu.cn?subject=è¯·è”ç³»æˆ‘&body=æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆ" title="email"><i class="fa fa-envelope" aria-hidden="true"></i></a></li> 
          
   		
   		</ul>


   		<!--
   		<ul class="clearfix widget-social-icons">   		
   		<li class="widget-si-twitter"><a target="_blank" rel="noopener" href="http://twitter.com" title="Twitter"><i class="ico-twitter"></i></a></li> 
		<li class="widget-si-facebook"><a target="_blank" rel="noopener" href="http://facebook.com" title="Facebook"><i class="ico-facebook"></i></a></li>
			<li class="widget-si-gplus"><a target="_blank" rel="noopener" href="http://plus.google.com" title="Google+"><i class="ico-gplus"></i></a></li>
			<li class="widget-si-pinterest"><a target="_blank" rel="noopener" href="http://pinterest.com" title="Pinterest"><i class="ico-pinterest"></i></a></li>
			<li class="widget-si-flickr"><a target="_blank" rel="noopener" href="http://flickr.com" title="Flickr"><i class="ico-flickr"></i></a></li>
			<li class="widget-si-instagram"><a target="_blank" rel="noopener" href="http://instagram.com" title="Instagram"><i class="ico-instagram"></i></a></li>
		</ul> -->

    </div>
  </div>


  
    
  <div class="widget_athemes_tabs">
    <ul id="widget-tab" class="clearfix widget-tab-nav">
      <li class="active"><a>æœ€æ–°æ–‡ç« </a></li>
    </ul>
    <div class="widget">
      <ul>
        
          <li class="clearfix">

            
              <div class="widget-entry-summary" style="margin: 0;">
            

              <h6 style="margin: 0;"><a href="/2023/08/09/Untitled/">(no title)</a></h6>
              <span>å…«æœˆ 9, 2023</span>
            </div>

          </li>
        
          <li class="clearfix">

            
              <div class="widget-entry-summary" style="margin: 0;">
            

              <h6 style="margin: 0;"><a href="/2023/08/08/LLM%E7%9B%B8%E5%85%B3%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/">LLMç›¸å…³è¿›å±•</a></h6>
              <span>å…«æœˆ 8, 2023</span>
            </div>

          </li>
        
          <li class="clearfix">

            
              <div class="widget-entry-thumbnail">
                <a href="/2023/07/24/Day1023-The%20Economist/" title=""><img width="50" height="50" src="/images/image-20230724100544248.png" class="attachment-thumb-small size-thumb-small wp-post-image" alt="preview-16" title=""></a>
              </div>
              <div class="widget-entry-summary">
            

              <h6 style="margin: 0;"><a href="/2023/07/24/Day1023-The%20Economist/">Day1023-The Economist</a></h6>
              <span>ä¸ƒæœˆ 24, 2023</span>
            </div>

          </li>
        
          <li class="clearfix">

            
              <div class="widget-entry-thumbnail">
                <a href="/2023/07/23/Day1022-The%20Economist/" title=""><img width="50" height="50" src="/images/image-20230723114920737.png" class="attachment-thumb-small size-thumb-small wp-post-image" alt="preview-16" title=""></a>
              </div>
              <div class="widget-entry-summary">
            

              <h6 style="margin: 0;"><a href="/2023/07/23/Day1022-The%20Economist/">Day1022-The Economist</a></h6>
              <span>ä¸ƒæœˆ 23, 2023</span>
            </div>

          </li>
        
          <li class="clearfix">

            
              <div class="widget-entry-thumbnail">
                <a href="/2023/07/23/Day1021-The%20Economist/" title=""><img width="50" height="50" src="/images/image-20230722095156129.png" class="attachment-thumb-small size-thumb-small wp-post-image" alt="preview-16" title=""></a>
              </div>
              <div class="widget-entry-summary">
            

              <h6 style="margin: 0;"><a href="/2023/07/23/Day1021-The%20Economist/">Day1021-The Economist</a></h6>
              <span>ä¸ƒæœˆ 23, 2023</span>
            </div>

          </li>
        
          <li class="clearfix">

            
              <div class="widget-entry-summary" style="margin: 0;">
            

              <h6 style="margin: 0;"><a href="/2023/07/21/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/">Hexo+Githubæ­å»ºä¸ªäººæŠ€æœ¯åšå®¢ï¼ˆMACæ“ä½œç‰ˆï¼‰</a></h6>
              <span>ä¸ƒæœˆ 21, 2023</span>
            </div>

          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">åˆ†ç±»</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/">ç»æµå­¦äºº</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">è®¡ç®—æœº</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">æ ‡ç­¾</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%80%E5%8F%91/" rel="tag">å¼€å‘</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/" rel="tag">ç»æµå­¦äºº</a><span class="tag-list-count">9</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">å½’æ¡£</h3>

    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">å…«æœˆ 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">ä¸ƒæœˆ 2023</a><span class="archive-list-count">10</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2023 Yujie&#39;s Blog All Rights Reserved.
          
            <span id="busuanzi_container_site_uv">
              æœ¬ç«™è®¿å®¢æ•°<span id="busuanzi_value_site_uv"></span>äººæ¬¡  
              æœ¬ç«™æ€»è®¿é—®é‡<span id="busuanzi_value_site_pv"></span>æ¬¡
            </span>
          
      </div>
      <div class="site-credit">
        Theme by <a href="https://github.com/iTimeTraveler/hexo-theme-hiero" target="_blank">hiero</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var contentdiv = document.getElementById("content");

    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
</script>

<!-- Custome JS -->

<script src="/js/my.js"></script>

    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



  
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.css">

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.js"></script>




<script src="/js/scripts.js"></script>


<script src="https://stackpath.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>


<script src="/js/main.js"></script>









	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
