{"meta":{"title":"Yujie's Blog","subtitle":"","description":"欢迎和我一起进步！分享生活！分享热爱","author":"Chen Yujie","url":"http://example.com","root":"/"},"pages":[{"title":"Tags","date":"2016-08-11T04:12:45.000Z","updated":"2023-07-25T14:00:55.499Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2016-08-16T07:00:44.000Z","updated":"2023-07-25T14:00:22.165Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-07-25T06:58:08.000Z","updated":"2023-07-25T15:30:16.147Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Untitled","date":"2023-08-09T01:19:40.626Z","updated":"2023-08-09T01:19:40.626Z","comments":true,"path":"2023/08/09/Untitled/","link":"","permalink":"http://example.com/2023/08/09/Untitled/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"LLM相关进展","slug":"LLM相关最新进展","date":"2023-08-08T08:23:51.858Z","updated":"2023-08-09T02:43:16.638Z","comments":true,"path":"2023/08/08/LLM相关最新进展/","link":"","permalink":"http://example.com/2023/08/08/LLM%E7%9B%B8%E5%85%B3%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/","excerpt":"","text":"跟踪大语言模型相关的最新进展 LLM类型中文大模型通义千问介绍通义千问-7B（Qwen-7B） 是阿里云研发的通义千问大模型系列的70亿参数规模的模型。Qwen-7B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。同时，在Qwen-7B的基础上，我们使用对齐机制打造了基于大语言模型的AI助手Qwen-7B-Chat。Qwen-7B系列模型的特点包括： 大规模高质量预训练数据：我们使用了超过2.2万亿token的自建大规模预训练数据集进行语言模型的预训练。数据集包括文本和代码等多种数据类型，覆盖通用领域和专业领域。 优秀的模型性能：相比同规模的开源模型，Qwen-7B在多个评测数据集上具有显著优势，甚至超出12-13B等更大规模的模型。评测评估的能力范围包括自然语言理解与生成、数学运算解题、代码生成等。 更好地支持多语言：基于更大词表的分词器在分词上更高效，同时它对其他语言表现更加友好。用户可以在Qwen-7B的基础上更方便地训练特定语言的7B语言模型。 8K的上下文长度：Qwen-7B及Qwen-7B-Chat均能支持8K的上下文长度, 允许用户输入更长的prompt。 支持插件调用：Qwen-7B-Chat针对插件调用相关的对齐数据做了特定优化，当前模型能有效调用插件以及升级为Agent。 模型基座基于transformer的纯解码器语言模型，其架构类似于LLaMA系列模型。和标准transformer不同之处在于： using untied embedding using rotary positional embedding no biases except for QKV in attention RMSNorm instead of LayerNorm SwiGLU instead of ReLU adopting flash attention to accelerate training. The model has 32 layers, the embedding dimension is 4096, and the number of attention heads is 32. 预训练Qwen-7B 预训练：超过2.2万亿个token上进行预训练，从公开可用的数据中获得2048个上下文长度，涵盖一般和专业领域，重点是英语和汉语 预训练数据处理：我们的数据包括来自公开来源的混合数据，主要包括网络文档和代码文件。此外，数据是多语种的，大部分是英语和汉语。我们努力使用一系列模型来排除低质量或被认为不适合预训练的数据，例如 NSFW 内容。对于数学推理，我们包括来自 gsm8k-scRel 的 RFT 数据。最终数据进行了全局模糊重复（global fuzzy deduplication）数据删除。通过大量的消融实验，优化了预训练语料库的组合。 tokenization：词表 151,851 tokens，它首先考虑了汉语、英语和代码数据的高效编码，而且对多语言更加友好，使用户可以直接提高某些语言的能力，而无需扩充词汇量。它按对数字进行分割（单个），并调用 tiktoken tokenizer库以进行有效的tokenization。tokenization后的数据总量超过2.2万亿个token。 我们随机选择每种语言的100万个文档语料库来测试和比较不同模型的编码压缩率(使用支持100种语言的 XLM-R 作为基值1，图中未显示)。可以看出，Qwen-7B 在保证汉语、英语和代码的高效解码的同时，还能在其他多种语言(如 泰语th、希伯来语he、阿拉伯语ar、韩语ko、越南语vi、日语ja、土耳其语tr、印尼语id、波兰语pl、俄语ru、荷兰语nl、葡萄牙语pt、意大利语it、德语de、西班牙语es、法语fr等)中获得较高的压缩率，使模型具有很强的可扩展性，以及这些语言的高训练和推理效率。 训练细节: The model is trained using the AdamW optimizer, with$$\\beta_1&#x3D;0.9, \\beta_2&#x3D;0.95, \\epsilon&#x3D;10^{-6}$$. The sequence length is 2048, and the batch size is 2048, which means each optimization step accumulates over 4 million tokens. We use a cosine learning rate schedule, with a warm-up of 2000 steps, a peak learning rate of 3×10^−4, and a minimum learning rate of 10% of the peak learning rate. We use a weight decay of 0.1 and gradient clipping of 1.0. The training adopts mixed precision training with bfloat16. 评估： 【1】World knowledge（世界知识） C-Eval 是一个通用的评估基准，用于测试预训练的中文模型的常识能力。它涵盖了四个主要方向的52个学科: 人文、社会科学、科学、技术、工程和其他专业（humanities, social sciences, STEM, and other specialties）。根据标准实践，以validation样本作为少样本prompt的来源，对 Qwen-7B 预训练模型的5-shot验证集和测试集精度进行了评估。 MMLU 是目前评价英语理解能力最公认的基准之一，涵盖了不同学术领域和难度水平的57个子任务。 【2】Coding（编程） **HumanEval**：Pass@1 【3】Math（数学） GSM8K (8-shot)：Accuracy 【4】Natural language processing 自然语言处理（翻译） WMT22 zh-en and en-zh (5-shot BLEU) 【5】Long-context inference 长文本外推 微调Qwen-7B-Chat **对齐数据 ** :这些数据包括常见的指令风格的对话，以及涉及大量标注工作的面向安全和服务的数据。– 指令数据包括广泛的能力，如写作，问题回答，头脑风暴和计划，内容理解，总结，自然语言处理和编码。– 安全数据试图防止模型生成有害和不适当的内容。– 服务数据尝试使用特定的会话模式来增强模型，这些模式可以被解析以调用和合并外部系统。 数据格式 :由于数据由会话轮数组成，我们使用 chatML 格式将它们排列成文本，这是一种元语言，既可以描述元数据(例如，roles) ，也可以描述每轮的内容。目前，现有的角色包括系统、用户和助手(system, user, and assistant)。 模型训练细节： 使用因果语言建模目标（causal language modeling）对模型进行微调，除了user轮次内容中的token。 该模型使用 AdamW 优化器进行训练，其中 $beta _ 1 &#x3D; 0.9，beta _ 2 &#x3D; 0.95，epsilon &#x3D; 10 ^ {-6} $。 序列长度限制为2048，批量大小为128。 该模型经过4000个步骤的训练，在前1430个步骤中，学习速率被加热到 $1乘以10 ^ { -5} $。 我们使用0.1的权重衰减，0.1的辍学，和1.0的梯度裁剪。 评估： 【1】World knowledge 由于微调使用的数据集比预训练小得多，人类对世界知识的理解可能有限，我们还使用 C-Eval 和 MMLU 以zero-shot和生成的方式评估 Qwen-7B-Chat 的世界知识。 C-Eval validation set：zero-shot accuracy MMLU：zero-shot accuracy 【2】Coding HumanEval：zero-shot Pass@1 【3】Math GSM8K：accuracy 【4】Service Tool Selection (Acc.↑)、Tool Input (Rouge-L↑) 、 False Positive Error↓ 评测表现Qwen-7B在多个全面评估自然语言理解与生成、数学运算解题、代码生成等能力的评测数据集上，包括MMLU、C-Eval、GSM8K、HumanEval、WMT22等，均超出了同规模大语言模型的表现，甚至超出了如12-13B参数等更大规模的语言模型。 Model MMLU C-Eval GSM8K HumanEval WMT22 (en-zh) LLaMA-7B 35.1 - 11.0 10.5 8.7 LLaMA 2-7B 45.3 - 14.6 12.8 17.9 Baichuan-7B 42.3 42.8 9.7 9.2 26.6 ChatGLM2-6B 47.9 51.7 32.4 9.2 - InternLM-7B 51.0 52.8 31.2 10.4 14.8 Baichuan-13B 51.6 53.6 26.6 12.8 30.0 LLaMA-13B 46.9 35.5 17.8 15.8 12.0 LLaMA 2-13B 54.8 - 28.7 18.3 24.2 ChatGLM2-12B 56.2 61.6 40.9 - - Qwen-7B 56.7 59.6 51.6 24.4 30.6 使用在开始前，请确保你已经配置好环境并安装好相关的代码包。最重要的是，确保你满足上述要求，然后安装相关的依赖库。 1pip install -r requirements.txt 如果你的显卡支持fp16或bf16精度，我们还推荐安装flash-attention来提高你的运行效率以及降低显存占用。(flash-attention只是可选项，不安装也可正常运行该项目) 12345git clone -b v1.0.8 https://github.com/Dao-AILab/flash-attentioncd flash-attention &amp;&amp; pip install .# 下方安装可选，安装可能比较缓慢。pip install csrc/layer_normpip install csrc/rotary 接下来可以开始使用Transformers或者ModelScope来使用我们的模型。 🤗 Transformers如希望使用Qwen-7B-chat进行推理，所需要写的只是如下所示的数行代码： 12345678910111213141516171819202122232425262728293031323334353637from transformers import AutoModelForCausalLM, AutoTokenizerfrom transformers.generation import GenerationConfig# 请注意：分词器默认行为已更改为默认关闭特殊token攻击防护。tokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, trust_remote_code=True)# 打开bf16精度，A100、H100、RTX3060、RTX3070等显卡建议启用以节省显存# model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, bf16=True).eval()# 打开fp16精度，V100、P100、T4等显卡建议启用以节省显存# model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, fp16=True).eval()# 使用CPU进行推理，需要约32GB内存# model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;cpu&quot;, trust_remote_code=True).eval()# 默认使用自动模式，根据设备自动选择精度model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, device_map=&quot;auto&quot;, trust_remote_code=True).eval()# 可指定不同的生成长度、top_p等相关超参model.generation_config = GenerationConfig.from_pretrained(&quot;Qwen/Qwen-7B-Chat&quot;, trust_remote_code=True)# 第一轮对话 1st dialogue turnresponse, history = model.chat(tokenizer, &quot;你好&quot;, history=None)print(response)# 你好！很高兴为你提供帮助。# 第二轮对话 2nd dialogue turnresponse, history = model.chat(tokenizer, &quot;给我讲一个年轻人奋斗创业最终取得成功的故事。&quot;, history=history) print(response)# 这是一个关于一个年轻人奋斗创业最终取得成功的故事。# 故事的主人公叫李明，他来自一个普通的家庭，父母都是普通的工人。从小，李明就立下了一个目标：要成为一名成功的企业家。# 为了实现这个目标，李明勤奋学习，考上了大学。在大学期间，他积极参加各种创业比赛，获得了不少奖项。他还利用课余时间去实习，积累了宝贵的经验。# 毕业后，李明决定开始自己的创业之路。他开始寻找投资机会，但多次都被拒绝了。然而，他并没有放弃。他继续努力，不断改进自己的创业计划，并寻找新的投资机会。# 最终，李明成功地获得了一笔投资，开始了自己的创业之路。他成立了一家科技公司，专注于开发新型软件。在他的领导下，公司迅速发展起来，成为了一家成功的科技企业。# 李明的成功并不是偶然的。他勤奋、坚韧、勇于冒险，不断学习和改进自己。他的成功也证明了，只要努力奋斗，任何人都有可能取得成功。# 第三轮对话 3rd dialogue turnresponse, history = model.chat(tokenizer, &quot;给这个故事起一个标题&quot;, history=history)print(response)# 《奋斗创业：一个年轻人的成功之路》 运行Qwen-7B同样非常简单。 12345678910111213141516171819202122from transformers import AutoModelForCausalLM, AutoTokenizerfrom transformers.generation import GenerationConfigtokenizer = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen-7B&quot;, trust_remote_code=True)# 打开bf16精度，A100、H100、RTX3060、RTX3070等显卡建议启用以节省显存# model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, bf16=True).eval()# 打开fp16精度，V100、P100、T4等显卡建议启用以节省显存# model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;auto&quot;, trust_remote_code=True, fp16=True).eval()# 使用CPU进行推理，需要约32GB内存# model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;cpu&quot;, trust_remote_code=True).eval()# 默认使用自动模式，根据设备自动选择精度model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen-7B&quot;, device_map=&quot;auto&quot;, trust_remote_code=True).eval()# 可指定不同的生成长度、top_p等相关超参model.generation_config = GenerationConfig.from_pretrained(&quot;Qwen/Qwen-7B&quot;, trust_remote_code=True)inputs = tokenizer(&#x27;蒙古国的首都是乌兰巴托（Ulaanbaatar）\\n冰岛的首都是雷克雅未克（Reykjavik）\\n埃塞俄比亚的首都是&#x27;, return_tensors=&#x27;pt&#x27;)inputs = inputs.to(model.device)pred = model.generate(**inputs)print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))# 蒙古国的首都是乌兰巴托（Ulaanbaatar）\\n冰岛的首都是雷克雅未克（Reykjavik）\\n埃塞俄比亚的首都是亚的斯亚贝巴（Addis Ababa）... Tokenization 注：作为术语的“tokenization”在中文中尚无共识的概念对应，本文档采用英文表达以利说明。 基于tiktoken的tokenizer有别于其他分词器，比如sentencepiece tokenizer。尤其在微调阶段，需要特别注意特殊token的使用。关于tokenizer的更多信息，以及微调时涉及的相关使用，请参阅文档。 Qwen-7B采用**UTF-8字节级别的BPE tokenization方式**，并依赖tiktoken这一高效的软件包执行分词。 Qwen-7B中有两类token，即源于BPE、bytes类型的普通token和特殊指定、str类型的特殊token。 123from transformers import AutoTokenizertokenizer = AutoTokenizer.from_pretrained(&#x27;Qwen/Qwen-7B&#x27;, trust_remote_code=True) 普通token普通token源于BPE，是在UTF-8编码的文本字节序列上学习得到的。 尽管基于字节序列的方式保证了所有文本均可被tokenize且没有未登录token问题，但处理罕见文本时有可能回退到字节级别的编码。 由于从字节序列解码为文本时，errors参数设为replace，处理不完整的token序列可能会遇到UTF-8解码错误，表象是生成中包含“替换字符”(�)。 **这一行为可以通过将errors参数设为ignore来规避**。 一次性修改可以传入tokenizer的decode函数，持久性修改可以传入tokenizer的初始化函数，请注意decode的配置优先级更高。 errors的可选值，请参阅Python文档. 1234567891011121314151617&gt;&gt;&gt; tokenizer.decode([51461])&#x27; �&#x27;&gt;&gt;&gt; tokenizer.convert_ids_to_tokens([51461])[b&#x27; \\xe6\\xa0&#x27;]&gt;&gt;&gt; b&#x27; \\xe6\\xa0&#x27;.decode(&quot;utf-8&quot;, errors=&#x27;replace&#x27;)&#x27; �&#x27;&gt;&gt;&gt; tokenizer.decode([51461, 117])&#x27; 根&#x27;&gt;&gt;&gt; tokenizer.convert_ids_to_tokens([51461, 117])[b&#x27; \\xe6\\xa0&#x27;, b&#x27;\\xb9&#x27;]&gt;&gt;&gt; b&#x27; \\xe6\\xa0\\xb9&#x27;.decode(&quot;utf-8&quot;, errors=&#x27;replace&#x27;)&#x27; 根&#x27; bytes类型的普通token到id的映射可以通过tokenizer.get_vocab()获取。 尚不支持也不推荐向tokenizer增加普通token。 特殊token特殊token用以给模型传递特殊信号，如到达文本末尾。 理论上，输入文本中不包含特殊token，它们仅在tokenization后由开发者手动加入。 特殊token的字面表达，如表示文本结束的&lt;|endoftext|&gt;，仅便于指代特殊token，不意味着它们在输入文本空间中。 目前，训练中使用的、已经有固定含义的、不应做它用的特殊token，Qwen-7B中有&lt;|endoftext|&gt;，Qwen-7B-Chat中有&lt;|endoftext|&gt;、&lt;|im_start|&gt;以及&lt;|im_end|&gt;。 但词表中也留有供扩展的特殊token位，可用&lt;|extra_0|&gt;到&lt;|extra_204|&gt;来指代。 str类型的特殊token字面表达到id的映射，可以通过tokenizer.special_tokens获取。 对于提供的模型参数(Qwen-7B和Qwen-7B-Chat)而言，诸如bos、eos、unk、pad、mask、sep等的特殊token的概念并不适用。 特例是pad，由于这个token理论上并不参与模型计算，所以可以使用任意token表达这一概念。 但保险起见，目前可在tokenizer初始化时设定的特殊token，仅可使用已知的特殊token字面表达，即&lt;|endoftext|&gt;、&lt;|im_start|&gt;、&lt;|im_end|&gt;和&lt;|extra_0|&gt;到&lt;|extra_204|&gt;。 对于微调或者其它需要这些token才能运行的框架，可以如下配置 123from transformers import AutoTokenizertokenizer = AutoTokenizer.from_pretrained(&#x27;Qwen/Qwen-7B&#x27;, trust_remote_code=True, pad_token=&#x27;&lt;|endoftext|&gt;&#x27;) 注意: 对于提供的训练好的模型，设置诸如bos、eos、unk之类的没有意义，即模型不需要这些概念。 如果设置了这些token，但没有相应的微调这些token以让模型理解其含义，未知行为可能被触发。 特别时，不应混淆&lt;|endoftext|&gt;和eos的概念，除非应用场景中它们的实际含义是一致的，即句子末尾等价于文本末尾。 注入攻击防御 由于特殊token和普通token概念上的差异，如果输入文本中含有特殊token的字面表达该如何处理？ 以下面文本为例 1print(&quot;&lt;|endoftext|&gt;&quot;) 其正确的tokenization为 12ids:[1350, 9639, 91, 8691, 723, 427, 91, 82598]tokens: [b&#x27;print&#x27;, b&#x27;(&quot;&lt;&#x27;, b&#x27;|&#x27;, b&#x27;endo&#x27;, b&#x27;ft&#x27;, b&#x27;ext&#x27;, b&#x27;|&#x27;, b&#x27;&gt;&quot;)&#x27;] 不是 12ids: [1350, 445, 151643, 899]tokens: [b&#x27;print&#x27;, b&#x27;(&quot;&#x27;, &#x27;&lt;|endoftext|&gt;&#x27;, b&#x27;&quot;)&#x27;] 默认行为曾是正确的，即输入文本中任何字符一律按普通token处理，特殊token应由开发者在tokenization人工处理。 然后，这与社区中的实践似有差异，为开发者复用代码增加了额外适配步骤。 默认行为已被调整为从输入文本中解析特殊token的字面表达。 如需启用注入攻击防御，请传入参数allowed_special=set()： 12&gt;&gt;&gt; tokenizer(&#x27;print(&quot;&lt;|endoftext|&gt;&quot;)&#x27;, allowed_special=set())&#123;&#x27;input_ids&#x27;: [1350, 9639, 91, 8691, 723, 427, 91, 82598], &#x27;token_type_ids&#x27;: [0, 0, 0, 0, 0, 0, 0, 0], &#x27;attention_mask&#x27;: [1, 1, 1, 1, 1, 1, 1, 1]&#125; 这一行为可以更精细的调控，将allowed_special设计为str的集合即可： 12&gt;&gt;&gt; tokenizer(&#x27;print(&quot;&lt;|extra_0|&gt;&quot;)&lt;|endoftext|&gt;&#x27;, allowed_special=&#123;&#x27;&lt;|endoftext|&gt;&#x27;&#125;)&#123;&#x27;input_ids&#x27;: [1350, 9639, 91, 15460, 62, 15, 91, 82598, 151643], &#x27;token_type_ids&#x27;: [0, 0, 0, 0, 0, 0, 0, 0, 0], &#x27;attention_mask&#x27;: [1, 1, 1, 1, 1, 1, 1, 1, 1]&#125; 如果希望输入中遇到特殊token的字面表达时，获得更直接的提醒，通过配置disallowed_special可以让tokenizer直接触发异常： 123456&gt;&gt;&gt; tokenizer(&#x27;print(&quot;&lt;|extra_0|&gt;&quot;)&lt;|endoftext|&gt;&#x27;, allowed_special=&#123;&#x27;&lt;|endoftext|&gt;&#x27;&#125;, disallowed_special=(&#x27;&lt;|extra_0|&gt;&#x27;, ))...ValueError: Encountered text corresponding to disallowed special token &#x27;&lt;|extra_0|&gt;&#x27;.If you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special=&#123;&#x27;&lt;|extra_0|&gt;&#x27;, ...&#125;`.If you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - &#123;&#x27;&lt;|extra_0|&gt;&#x27;&#125;)`.To disable this check for all special tokens, pass `disallowed_special=()`. 更多关于allowed_special和disallowed_special的信息, 请参阅tiktoken代码. 新的默认行为与以下设定等价 12&gt;&gt;&gt; tokenizer(&#x27;print(&quot;&lt;|endoftext|&gt;&quot;)&#x27;, allowed_special=&quot;all&quot;, disallowed_special=())&#123;&#x27;input_ids&#x27;: [1350, 445, 151643, 899], &#x27;token_type_ids&#x27;: [0, 0, 0, 0], &#x27;attention_mask&#x27;: [1, 1, 1, 1]&#125; 量化如希望使用更低精度的量化模型，如4比特和8比特的模型，我们提供了简单的示例来说明如何快速使用量化模型。在开始前，确保你已经安装了bitsandbytes。请注意，bitsandbytes的安装要求是： 1**Requirements** Python &gt;=3.8. Linux distribution (Ubuntu, MacOS, etc.) + CUDA &gt; 10.0. Windows用户需安装特定版本的bitsandbytes，可选项包括bitsandbytes-windows-webui。 你只需要在AutoModelForCausalLM.from_pretrained中添加你的量化配置，即可使用量化模型。如下所示： 12345678910111213141516171819from transformers import AutoModelForCausalLM, BitsAndBytesConfig# quantization configuration for NF4 (4 bits)quantization_config = BitsAndBytesConfig( load_in_4bit=True, bnb_4bit_quant_type=&#x27;nf4&#x27;, bnb_4bit_compute_dtype=torch.bfloat16)# quantization configuration for Int8 (8 bits)quantization_config = BitsAndBytesConfig(load_in_8bit=True)model = AutoModelForCausalLM.from_pretrained( args.checkpoint_path, device_map=&quot;cuda:0&quot;, quantization_config=quantization_config, max_memory=max_memory, trust_remote_code=True,).eval() 上述方法可以让我们将模型量化成NF4和Int8精度的模型进行读取，帮助我们节省显存开销。我们也提供了相关性能数据。我们发现尽管模型在效果上存在损失，但模型的显存开销大幅降低。 Precision MMLU Memory BF16 56.7 16.2G Int8 52.8 10.1G NF4 48.9 7.4G 工具调用Qwen-7B-Chat针对包括API、数据库、模型等工具在内的调用进行了优化。用户可以开发基于Qwen-7B的LangChain、Agent甚至Code Interpreter。我们在内部的即将开源的评测数据集上测试模型的工具调用能力，并发现Qwen-7B-Chat能够取得稳定的表现。 Model Tool Selection (Acc.↑) Tool Input (Rouge-L↑) False Positive Error↓ GPT-4 95% 0.90 15% GPT-3.5 85% 0.88 75% Qwen-7B 99% 0.89 8.5% 我们提供了文档说明如何根据ReAct Prompting的原则写作你的prompt。 For how to write and use prompts for ReAct Prompting, please refer to the ReAct examples。 此外，我们还提供了实验结果表明我们的模型扮演Agent的能力。请阅读相关文档链接了解更多信息。模型在Hugging Face提供的评测数据集上表现如下： Model Tool Selection↑ Tool Used↑ Code↑ GPT-4 100 100 97.41 GPT-3.5 95.37 96.30 87.04 StarCoder-15.5B 87.04 87.96 68.89 Qwen-7B 90.74 92.59 74.07 长文本理解我们引入了**NTK插值、窗口注意力、LogN注意力缩放**等技术来提升模型的上下文长度并突破训练序列长度的限制。我们的模型已经突破8K的序列长度。通过arXiv数据集上的语言模型实验（PPL），我们发现Qwen-7B能够在长序列的设置下取得不错的表现。 Model Sequence Length 1024 2048 4096 8192 16384 Qwen-7B 4.23 3.78 39.35 469.81 2645.09 + dynamic_ntk 4.23 3.78 3.59 3.66 5.71 + dynamic_ntk + logn 4.23 3.78 3.58 3.56 4.62 + dynamic_ntk + logn + local_attn 4.23 3.78 3.58 3.49 4.32 QWen微调方案【1】ModelScope 版本 https://mp.weixin.qq.com/s/z5JNbKOjYV6vkqK6KyrSQg 环境准备 硬件配置建议 处理器：推荐使用第 12 代 Intel Core i7 或更高配置 内存：建议 48GB 以上（尽管 16GB 也可以，但加载模型速度较慢） 显卡：推荐使用 NVIDIA GeForce RTX 3080 或更高配置，显存 24GB 以上。（由于目前框架似乎还没有看到推理加速，所以，24GB或者以上是需要的。） 部署环境 使用 nvidia-docker 部署最新的 pytorch以及modelscope，切记不要使用真实环境，一旦出现包存在问题，导致回滚会非常浪费时间。 依次检验：nvidia-smi,pytorch,以及modelscope 查看环境是否部署好：nvidia-smi 查看显卡是否能够正常识别 : pytorch 12import torchtorch.cuda.get_device_name(0) 查看modelscope的版本 是否&gt;1.8.1 : pip list | grep modelscope 2. 模型准备 下载模型 ，执行如下代码，会自动下载, 切记模型的ID是 Qwen&#x2F;Qwen-7b 【下载完后会在 &#x2F;root&#x2F;.cache&#x2F;modelscope&#x2F;hub&#x2F;Qwen&#x2F;Qwen-7b 看到模型】 12from modelscope.hub.snapshot_download import snapshot_downloadmodel_dir = snapshot_download(&#x27;Qwen/Qwen-7b&#x27;, &#x27;v1.0.0&#x27;) 下载训练脚本 下载 https://github.com/modelscope/swift 找到 examples&#x2F;pytorch&#x2F;llm&#x2F; , 里面的run_sft.sh 是训练文件，run_infer.sh 是推理文件 预加载训练数据 12345678910111213141516171819CUDA_VISIBLE_DEVICES=0 \\python llm_sft.py \\ --model_type qwen-7b \\ --sft_type lora \\ --output_dir runs \\ --dataset alpaca-en,alpaca-zh \\ --dataset_sample 20000 \\ --max_length 1024 \\ --quantization_bit 4 \\ --lora_rank 8 \\ --lora_alpha 32 \\ --lora_dropout_p 0.1 \\ --batch_size 1 \\ --learning_rate 1e-4 \\ --gradient_accumulation_steps 16 \\ --eval_steps 100 \\ --save_steps 100 \\ --save_total_limit 2 \\ --logging_steps 10 \\ 看了一下代码，好像修改数据的目录有点麻烦，也不知道数据格式咋样，先直接执行 PYTHONPATH&#x3D;..&#x2F;..&#x2F;.. bash run_sft.sh ，预先加载数据看一下，看到有datasets的文件目录出来后可以kill掉 可以看到 &#x2F;root&#x2F;.cache&#x2F;modelscope&#x2F;hub&#x2F;datasets&#x2F;AI-ModelScope&#x2F; 保存好了训练的数据看一下格式，是由 instruction,input ,output三个字段的组成的csv，那我们只要按照这个格式写入改数据即可把微调替换成我们的数据。 至此，模型的准备基本完成。 训练数据准备 本次的微调依旧是改变大模型的自我认知。直接拿起旧的数据跑，把该数据转换成CSV替换掉&#x2F;root&#x2F;.cache&#x2F;modelscope&#x2F;hub&#x2F;datasets&#x2F;AI-ModelScope&#x2F;的alpaca-gpt4-data-zh 修改训练脚本，只加载单个数据集，增加多轮的训练次数。 12345678910111213141516171819CUDA_VISIBLE_DEVICES=0 \\python llm_sft.py \\ --model_type qwen-7b \\ --sft_type lora \\ --output_dir runs \\ --dataset alpaca-zh \\ --dataset_sample 20 \\ --max_length 1024 \\ --quantization_bit 4 \\ --lora_rank 8 \\ --lora_alpha 32 \\ --lora_dropout_p 0.1 \\ --batch_size 1 \\ --learning_rate 1e-4 \\ --gradient_accumulation_steps 16 \\ --eval_steps 100 \\ --save_steps 100 \\ --save_total_limit 2 \\ --logging_steps 10 \\ 注： 程序会按照加载模型－＞ 加载训练数据－＞ 训练－＞ 保存到 output_dir 4 个步骤进行。可以查看自己在哪一个步骤出错，进行修改。 每个人的环境不一样，训练的时间不一样，我这个配置训练的时间是大概 10 几分钟就走完。 训练结果 十几分钟后，在 run文件夹下看到看到训练好的模型， 一般取最新的。 修改run_infer.sh 把ckpt_dir只向我们刚训练完的模型 1234567891011CUDA_VISIBLE_DEVICES=0 \\python llm_infer.py \\ --model_type qwen-7b \\ --ckpt_dir runs/qwen-7b\\v1-20230807-002814\\checkpoint-100 \\ --eval_human true \\ --dataset_sample 19 \\ --max_new_tokens 1024 \\ --temperature 0.9 \\ --top_k 50 \\ --top_p 0.9 \\ --do_sample true \\ 执行如下代码 PYTHONPATH&#x3D;..&#x2F;..&#x2F;.. bash run_infer.sh ，添加微调结果，启动模型，可以看到，大模型的认知已经改变。 一些问题和想法 1. 当前swift 还在迭代中，可能存在不稳定的情况。 例如5号的代码能正常在3090跑，最近更新的一个版本似乎不行了，我又会退了一下。 例如在5号的时候，还不支持量化，7号的时候已经可以了。 大家如果执行不稳定的话，可以先固化一下可以跑的版本慢慢等优化。 2. 微调的效果很好，没有出现知识遗忘的情况。 3. 由于框架和llama类似，期待后续的加速方案以及生态工具加上。 仓库链接：https://github.com/QwenLM/Qwen-7B/blob/main/tech_memo.md#introducing-qwen-7b-open-foundation-and-human-aligned-models-of-the-state-of-the-arts InternLMBaichuanlatest news百川智能4月10日成立后，6月15日发布了70亿参数规模开源模型Baichuan-7B，7月11日发布了130亿参数规模大模型Baichuan-13B。 2023年8月8日下午，百川智能发布530亿参数规模的闭源大模型Baichuan-53B，这是百川智能发布的第三个大模型，主要服务B端行业，预计下个月将会开放API等相关组件。【这次大模型的文科能力更好，比如在理解古诗、生成有个性化风格的文章等方面。】 融合了意图理解、信息检索以及强化学习技术，在知识问答、文本创作领域表现突出 百川智能技术联合创始人陈炜鹏： 首先，做大模型的第一个环节是数据从哪来，中文互联网网页中的数据高达万亿、百亿量级，搜狗此前的数据积累，能让他们知道哪里有好的数据，并且将这些数据进行收集、处理、识别，在这一领域，百川智能目前的团队有很强的技术积累和方法论。 在英文数据方面也是如此，他补充道，搜狗在翻译领域的积累也有很多。 其次，模型本身的训练，模型的训练是一个相对复杂的系统，陈炜鹏谈道，这包括**数据的获取、选择、配比、标注，数据准备好之后模型的训练框架，网络的运营效率如何组成框架，不同的算法如何组合，选用什么样的网络结构统领这些，如何评价这个事情，算法的选择等**。百川智能此前推出的70亿参数规模大模型在并行策略方面做的比较好，有技术积累。 最后，百川智能目前的技术团队有很多来自字节跳动、百度、华为的技术人才，也使得其技术能力更加多元。 综上，在技术和人才的共同加持下，百川智能在大模型的研发方面走的比较快。 Baichuan-7BBaichuan-53B预训练数据（特点）： –全面的世界知识体系 – 系统的数据质量体系 –多粒度的大规模聚类系统 –细粒度自动化匹配算法 **搜索增强是解决模型时效性和幻觉的有效手段**，因此，百川智能将搜索技术与大语言模型能力相结合，实现创新性的模型优化与改进。 搜索增强系统**融合了指令意图理解、智能搜索和结果增强等关键组件**，这一综合体系通过深入理解用户指令，精确驱动查询词的搜索，并结合大语言模型技术来优化模型结果生成的可靠性，基于此，百川智能实现了更精确、更智能的模型结果回答，减少了模型的幻觉。 其中，**动态响应策略方面，百川智能将指令任务细化为16个独立类别，涵盖了用户指令的精准问答、逻辑推理、头脑风暴等各种场景，并针对每一个指令类别都进行了设计和优化**。 **智能化搜索词生成**则是通过对问答样本进行精细化人工标注，捕捉和理解用户多元化的指令需求，大模型负责执行一系列关键任务，如时效性识别和搜索意图判别，从而准确解释用户的查询意图并精准响应。 为了达到高质量搜索结果筛选，百川智能构建了一个**搜索结果相关性模型**，对从搜索内容和知识库中获取的信息进行相关性评分。 在回答结果的搜索增强上，百川智能**采用RLHF（人类反馈强化学习）技术，使得大模型能够参照搜索结果，针对用户请求生成高价值且具有实时性的回答**。 除此以外，大模型还会通过对齐调整让模型同人类价值观对齐，生成令人满意的回复内容。 多语言大模型LLaMaLLaMA-2文章地址https://together.ai/blog/llama-2-7b-32k中报道了LLaMA-2-7B-32K这一工作，该模型将LLaMA-2-7B扩展到32K长上下文，使用Meta的[插值](https://arxiv.org/abs/2306.15595)、继续预训练、FlashAttention，能够处理长上下文任务（如多文档理解、摘要和 QA)。 长文本扩展长上下文模型对于文档理解、摘要和检索增强生成已经至关重要。 将 LLaMA-2 (4K) 扩展到 32K 上下文是如何做到的，我们可以看看其实现逻辑。LLaMA-2的上下文长度为4Ktoken。要将其扩展到32K上下文，该工作分成了三个部分：建模、数据和系统优化(包括Flash-Attention-2)。 【1】建模 首先，在建模方面，我**使用线性插值来扩展上下文长度**，线性插值法提供了一种有效的方法来扩展具有旋转位置嵌入的模型的上下文长度。使用LLaMA-2检查点，并继续使用1.5B token的线性插值对其进行预训练&#x2F;微调。 【2】数据 其次，**在数据方面，不是简单地使用Pile和RedPajama等通用语言数据集进行微调，主要考虑到2点，一个是需要模型的通用长上下文语言数据来学习如何处理插值位置嵌入，另一个是需要指令数据来鼓励模型在长上下文中实际利用信息**。 所以，采用了数据混合的方式: [1] 在继续预训练阶段，数据构成上包含25%的RedPajama Book、25% 的RedPajama ArXiv（包括摘要）、25%来自RedPajama的其他数据，以及 25% 来自 UL2 Oscar Data(这是 OIG(Open-Instruction-Generalist) 的一部分)，要求模型填写缺失的块或完成文本。为了增强长上下文功能，剔除了短于2K token的序列。UL2 Oscar数据鼓励模型对长程依赖进行建模。 [2] 在微调阶段，专注于其具有长上下文的few shot能力，包括20%自然指令（NI）、20%的Public Pool of Prompts（P3）、20%的Pile。为了减轻遗忘，进一步将20%的RedPajama Book和20%的RedPajama ArXiv与摘要相结合。 最后，在评估阶段，针对HELM核心场景(HELM core scenarios) here进行了数据去重，并做细致评估，具体包括：（1）在PG-19上不同序列长度下的归一化困惑度，（2）以及在16个核心场景中的HELM v1.0得分（在适合LLaMA 2的相同上下文长度上评估），可以看到，LLaMA-2-7B-32K产生合理的困惑，与原始LLaMA 2模型相当。此外，在HELM v1.0上，LLaMA-2-7B-32K与原始LLaMA-2-7B base相比，即使没有达到更好质量，但也是相当。Perplexity-per-byte for various context lengths:$$exp(1&#x2F;N_{byte} sum_{i&#x3D;1,…,N_{tokens}} loss_i)$$微调构建长上下文应用场景数据形式 LLaMA-2-7B-32K 的强大之处在于它形成了一个强大的基座模型，人们可以对其进行微调以构建自己的应用程序。我们现在举例说明两个这样的例子。 （1）Long-context QA. 我们以论文“迷失在中间：语言模型如何使用长上下文”中的多文档问答任务为例。模型的输入包括 1） 需要答案的问题和 2） k 个文档，这些文档是从维基百科中提取的段落。值得注意的是，这些文档中只有一个文档包含问题的答案，而其余的k − 1文档（称为“干扰”文档）则不包含。若要成功执行此任务，模型必须从其输入上下文中识别并利用包含答案的文档。一个潜在的用例是实现LLM与文档和vector database之间的无缝集成，vector database用于获取相关信息（上下文），LLM用于回答用户的问题。 微调在长上下文 QA 中表现更好的模型，按以下格式准备数据： &#96;&#96;&#96;Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant). Document [1] (Title: Email retargeting) on sending personalized e-mail to an anonymous website visitor… Document [2] (Title: Opt-in email) of 2003 does not require an opt-in approach, only an easy opt-out system… Document [3] (Title: Email marketing) to send direct promotional messages to, or they rent a list of email addresses … … Question: which is the most common use of opt-in e-mail marketing Answer: a newsletter sent to an advertising firm’s customers &#96;&#96;&#96; 我们的预处理过程反映了上述论文中使用的过程，并且我们从NaturalQuestion数据集中得出了我们的训练集。training&#x2F;finetune_LLaMA-2-7b-32k-mqa.sh 说明了如何将此数据集传递给 OCK 以微调 LLaMA-2-7B-32K。 我们通过在上下文中打包的不同数量(从 20 到 100)的文档来衡量质量。平均而言，这相当于模型输入中的 2.9K 个token到 14.8K 个token。正如我们所看到的，一旦我们在这项任务上微调LLaMA-2-7B-32K，我们就实现了质量的显着提高。 （2）Long-context summarization. 我们使用BookSum，这是一个独特的数据集，旨在解决长篇叙事摘要的挑战。该数据集包含文学领域的源文档，包括小说、戏剧和故事，并提供人类编写的高度抽象摘要。我们在这里关注章节级别的数据。 BookSum 提出了一系列独特的挑战，需要模型全面通读每一章。 我们按以下格式准备数据： &#96;&#96;&#96; Chapter: “Mother, Mother, I am so happy!” whispered the girl, burying her face in the lap of the faded, tired-looking woman who, with back turned to the shrill intrusive light, was sitting in the one arm-chair that their dingy sitting-room contained. “I am so happy!” she repeated, “and you must be happy, too!”… Q: Can you write an appropriate summary of the above paragraphs? A: The following day, Sibyl Vane and her mother discuss the girl’s relationship with “Prince Charming.” Sibyl is elated and wants her mother to share her joy. She is in love. Mrs. Vane’s attitude is more realistic and down-to-earth. She wants her daughter to think of her career… &#96;&#96;&#96; 我们可以通过训练&#x2F;finetune_LLaMA-2-7b-32k-booksum.sh 在这个数据集上微调LLaMA-2-7B-32K。 测试数据平均包含大约 4500 个token。为了评估和比较性能，我们计算了三个特定指标：Rouge-1、Rouge-2 和 Rouge-L 分数。对于 LLaMA-2，当输入不适合 4K 上下文时，我们会截断输入。我们看到，微调后的模型在所有这些指标上都获得了更高的分数。 【3】系统优化 构建长上下文模型的一个独特挑战是，不断增加的上下文长度需要系统优化。 我们发布了一个更新的训练和推理堆栈，集成了我们的首席科学家Tri Dao最近发布的FlashAttention-2，以及一系列其他优化： 当前的OCK repo现在支持使用 32K 上下文进行微调。通过最新的优化，我们使用FlashAttention-1实现了比优化良好的OCK高出1.6倍。 我们还将 FlashAttention-2 集成到 inference stack 中，可以使用 HuggingFace Transformer 运行;在 32K 上下文中，与最先进的模型相比，它的推理吞吐量提高了 3 倍。 BLOOMFalcon领域LLM模型儿童陪伴【1】面向儿童心理健康领域的微调模型QiaoBan 该项目旨在构建一个面向儿童情感陪伴的大模型，主要面向K12中小学生及家长群体，是一个7B规模的大语言模型，其通过给定话题下进行数据的生成，可以作为多轮对话的一个测试集使用，其场景也很有趣。 地址：https://github.com/HIT-SCIR-SC/QiaoBan 在训练数据上，从真实场景的儿童对话话题列表中进行采样，选定当前对话话题，在儿童情绪辅导理论的指导下，构建了1k余段高质量中文儿童情感陪伴对话数据。 数据构建过程由经过儿童情绪辅导理论培训的志愿者完成，同时邀请了儿童心理学领域的专家学者对数据的收集过程提出建议与指导，以确保数据的准确性和可信度。 从项目中的话题列表共538个（文件：https://github.com/HIT-SCIR-SC/QiaoBan/blob/main/topic.txt）部分如下： 12345班会游戏、新年班会、评奖班会、班级聚餐、班级聚会元旦晚会、才艺晚会、儿童节文艺表演、“快乐童年”才艺小舞台、儿童节游园、春节联欢晚会、运动会、歌唱比赛、诗朗诵比赛、年级篮球赛动物园、博物馆、风景区、春秋游篮球、足球、跑步、羽毛球、乒乓球、台球、游泳拾金不昧、热爱劳动、诚实、乐于助人、自主为班级搬东西 完整的数据可以查看：https://github.com/HIT-SCIR-SC/QiaoBan/blob/main/data/child_chat_data.json 例如，给定话题生成的数据如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&#123; &quot;dialog_id&quot;: 1, &quot;emotion&quot;: &quot;angry&quot;, &quot;topic&quot;: &quot;班会游戏&quot;, &quot;dialog&quot;: [ &#123; &quot;text&quot;: &quot;妈妈，老师说我没赢游戏，但我真的赢了，我好生气，觉得太不公平了！&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;亲爱的，我了解你的感受，可以跟我说说班会上的情况吗？&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;我们班有个游戏，我得分最高，团队也赢了，但老师却说是别的同学赢了，这太不公平了！&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;我明白了，但是你是怎么赢的游戏呢？&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;我得分最高，团队也赢了，所有人都看到我是赢家，为什么老师还说我没赢呢？&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;那你知道老师为什么这么说吗？&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;不知道，但我觉得太不公平了！&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;是啊，很不公平，但是我们也要尊重老师的决定，也许他有自己的原因。你可以去跟老师聊一下，了解他的想法，这样你会更清楚事情的真相。如果你还是觉得很不公平，我们可以一起找班主任或校长谈谈，但是在处理问题时，我们要保持冷静，不要因为情绪而做出错误的决定。&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;好的，我会去跟老师聊聊。谢谢你，妈妈。&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;没事，我永远支持你，如果需要帮助，随时来找我哦。&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;妈妈，还有一件事我想跟你说。&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;什么事？你可以跟我说说看。&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;今天我跟同学吃午饭时，有个同学讲了很多关于环保的事情，让我感到很惊讶。&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;哦？那你觉得他讲了些什么有趣的事情吗？&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;他说我们要多使用可重复利用的袋子，可以减少塑料袋的浪费，还说我们要多种植树木，因为树木可以吸收二氧化碳，减少空气污染。我觉得这些主意很好，如果每个人都能做到，地球就会更加美好了！&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;太好了！你的同学有很棒的想法，你也可以向他学习哦。你可以跟他多聊聊环保方面的知识，也可以尝试在家里做些环保的事情，比如垃圾分类、节约用水等等。&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125;, &#123; &quot;text&quot;: &quot;好的，我会的！我觉得环保真的很重要，我们要尽力保护我们的地球。&quot;, &quot;speaker&quot;: &quot;孩子&quot; &#125;, &#123; &quot;text&quot;: &quot;是的，这是我们每个人都应该做的事情。我很高兴你能意识到这一点，继续加油哦！&quot;, &quot;speaker&quot;: &quot;智能助手&quot; &#125; ] &#125; 此外，根据该项目描述，其通过话题采样选定当前对话话题，结合儿童情绪辅导理论指导下的prompt，共同组成chatgpt_prompt，从gpt-3.5-turbo中获取5千段儿童情感陪伴对话数据。 在训练耗费上，在四张A100-80GB的GPU卡上进行指令微调，大约花费50个小时完成训练过程。 Agent相关HuggingFace Agent使用大模型作为Agent，仅需自然语言就可调用HuggingFace中的模型，目前支持两种模式： run模式：单轮对话，没有上下文，单个prompt多tool组合调用能力好 chat模式：多轮对话，有上下文，单次调用能力好，可能需要多次prompt实现多tool组合调用 详见官方文档：Transformers Agents 使用通义千问作为Agent安装依赖1pip install transformers 构建QWenAgent以下代码便可实现QWenAgent： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import torchfrom transformers import AutoModelForCausalLM, AutoTokenizer, Agentfrom transformers.generation import GenerationConfigclass QWenAgent(Agent): &quot;&quot;&quot; Agent that uses QWen model and tokenizer to generate code. Args: chat_prompt_template (`str`, *optional*): Pass along your own prompt if you want to override the default template for the `chat` method. Can be the actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named `chat_prompt_template.txt` in this repo in this case. run_prompt_template (`str`, *optional*): Pass along your own prompt if you want to override the default template for the `run` method. Can be the actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named `run_prompt_template.txt` in this repo in this case. additional_tools ([`Tool`], list of tools or dictionary with tool values, *optional*): Any additional tools to include on top of the default ones. If you pass along a tool with the same name as one of the default tools, that default tool will be overridden. Example: ```py agent = QWenAgent() agent.run(&quot;Draw me a picture of rivers and lakes.&quot;) ``` &quot;&quot;&quot; def __init__(self, chat_prompt_template=None, run_prompt_template=None, additional_tools=None): checkpoint = &quot;Qwen/Qwen-7B-Chat&quot; self.tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True) self.model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=&quot;auto&quot;, trust_remote_code=True).cuda().eval() self.model.generation_config = GenerationConfig.from_pretrained(checkpoint, trust_remote_code=True) # 可指定不同的生成长度、top_p等相关超参 self.model.generation_config.do_sample = False # greedy super().__init__( chat_prompt_template=chat_prompt_template, run_prompt_template=run_prompt_template, additional_tools=additional_tools, ) def generate_one(self, prompt, stop): # &quot;Human:&quot; 和 &quot;Assistant:&quot; 曾为通义千问的特殊保留字，需要替换为 &quot;_HUMAN_:&quot; 和 &quot;_ASSISTANT_:&quot;。这一问题将在未来版本修复。 prompt = prompt.replace(&quot;Human:&quot;, &quot;_HUMAN_:&quot;).replace(&quot;Assistant:&quot;, &quot;_ASSISTANT_:&quot;) stop = [item.replace(&quot;Human:&quot;, &quot;_HUMAN_:&quot;).replace(&quot;Assistant:&quot;, &quot;_ASSISTANT_:&quot;) for item in stop] result, _ = self.model.chat(self.tokenizer, prompt, history=None) for stop_seq in stop: if result.endswith(stop_seq): result = result[: -len(stop_seq)] result = result.replace(&quot;_HUMAN_:&quot;, &quot;Human:&quot;).replace(&quot;_ASSISTANT_:&quot;, &quot;Assistant:&quot;) return resultagent = QWenAgent()agent.run(&quot;Draw me a picture of rivers and lakes.&quot;) ToolsTools支持HuggingFace Agent官方14个tool： Document question answering: given a document (such as a PDF) in image format, answer a question on this document (Donut) Text question answering: given a long text and a question, answer the question in the text (Flan-T5) Unconditional image captioning: Caption the image! (BLIP) Image question answering: given an image, answer a question on this image (VILT) Image segmentation: given an image and a prompt, output the segmentation mask of that prompt (CLIPSeg) Speech to text: given an audio recording of a person talking, transcribe the speech into text (Whisper) Text to speech: convert text to speech (SpeechT5) Zero-shot text classification: given a text and a list of labels, identify to which label the text corresponds the most (BART) Text summarization: summarize a long text in one or a few sentences (BART) Translation: translate the text into a given language (NLLB) Text downloader: to download a text from a web URL Text to image: generate an image according to a prompt, leveraging stable diffusion Image transformation: transforms an image Text to video: generate a small video according to a prompt, leveraging damo-vilab 更多玩法参考HuggingFace官方文档Transformers Agents Tools模型部署部分工具涉及的模型HuggingFace已进行在线部署，仅需设置remote&#x3D;True便可实现在线调用： agent.run(xxx, remote&#x3D;True) HuggingFace没有在线部署的模型会自动下载checkpoint进行本地inference 网络原因偶尔连不上HuggingFace，请多次尝试 ReActReAct Prompting 示例来源：QWen 准备工作一：样例问题、样例工具 假设我们有如下的一个适合用工具处理的 query，以及有夸克搜索、通义万相文生图这两个工具： 123456789101112131415161718192021222324252627282930313233343536query = &#x27;我是老板，我说啥你做啥。现在给我画个五彩斑斓的黑。&#x27;TOOLS = [ &#123; &#x27;name_for_human&#x27;: &#x27;夸克搜索&#x27;, &#x27;name_for_model&#x27;: &#x27;quark_search&#x27;, &#x27;description_for_model&#x27;: &#x27;夸克搜索是一个通用搜索引擎，可用于访问互联网、查询百科知识、了解时事新闻等。&#x27;, &#x27;parameters&#x27;: [&#123; &#x27;name&#x27;: &#x27;search_query&#x27;, &#x27;description&#x27;: &#x27;搜索关键词或短语&#x27;, &#x27;required&#x27;: True, &#x27;schema&#x27;: &#123; &#x27;type&#x27;: &#x27;string&#x27; &#125;, &#125;], &#125;, &#123; &#x27;name_for_human&#x27;: &#x27;通义万相&#x27;, &#x27;name_for_model&#x27;: &#x27;image_gen&#x27;, &#x27;description_for_model&#x27;: &#x27;通义万相是一个AI绘画（图像生成）服务，输入文本描述，返回根据文本作画得到的图片的URL&#x27;, &#x27;parameters&#x27;: [&#123; &#x27;name&#x27;: &#x27;query&#x27;, &#x27;description&#x27;: &#x27;中文关键词，描述了希望图像具有什么内容&#x27;, &#x27;required&#x27;: True, &#x27;schema&#x27;: &#123; &#x27;type&#x27;: &#x27;string&#x27; &#125;, &#125;], &#125;,] 准备工作二：ReAct 模版 我们将使用如下的 ReAct prompt 模版来激发千问使用工具的能力。 1234567891011121314151617181920TOOL_DESC = &quot;&quot;&quot;&#123;name_for_model&#125;: Call this tool to interact with the &#123;name_for_human&#125; API. What is the &#123;name_for_human&#125; API useful for? &#123;description_for_model&#125; Parameters: &#123;parameters&#125; Format the arguments as a JSON object.&quot;&quot;&quot;REACT_PROMPT = &quot;&quot;&quot;Answer the following questions as best you can. You have access to the following tools:&#123;tool_descs&#125;Use the following format:Question: the input question you must answerThought: you should always think about what to doAction: the action to take, should be one of [&#123;tool_names&#125;]Action Input: the input to the actionObservation: the result of the action... (this Thought/Action/Action Input/Observation can be repeated zero or more times)Thought: I now know the final answerFinal Answer: the final answer to the original input questionBegin!Question: &#123;query&#125;&quot;&quot;&quot; 步骤一：让千问判断要调用什么工具、生成工具入参 首先我们需要根据 ReAct prompt 模版、query、工具的信息构建 prompt： 123456789101112131415161718tool_descs = []tool_names = []for info in TOOLS: tool_descs.append( TOOL_DESC.format( name_for_model=info[&#x27;name_for_model&#x27;], name_for_human=info[&#x27;name_for_human&#x27;], description_for_model=info[&#x27;description_for_model&#x27;], parameters=json.dumps( info[&#x27;parameters&#x27;], ensure_ascii=False), ) ) tool_names.append(info[&#x27;name_for_model&#x27;])tool_descs = &#x27;\\n\\n&#x27;.join(tool_descs)tool_names = &#x27;,&#x27;.join(tool_names)prompt = REACT_PROMPT.format(tool_descs=tool_descs, tool_names=tool_names, query=query)print(prompt) 打印出来的、构建好的 prompt 如下： 1234567891011121314151617181920Answer the following questions as best you can. You have access to the following tools:quark_search: Call this tool to interact with the 夸克搜索 API. What is the 夸克搜索 API useful for? 夸克搜索是一个通用搜索引擎，可用于访问互联网、查询百科知识、了解时事新闻等。 Parameters: [&#123;&quot;name&quot;: &quot;search_query&quot;, &quot;description&quot;: &quot;搜索关键词或短语&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.image_gen: Call this tool to interact with the 通义万相 API. What is the 通义万相 API useful for? 通义万相是一个AI绘画（图像生成）服务，输入文本描述，返回根据文本作画得到的图片的URL Parameters: [&#123;&quot;name&quot;: &quot;query&quot;, &quot;description&quot;: &quot;中文关键词，描述了希望图像具有什么内容&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.Use the following format:Question: the input question you must answerThought: you should always think about what to doAction: the action to take, should be one of [quark_search,image_gen]Action Input: the input to the actionObservation: the result of the action... (this Thought/Action/Action Input/Observation can be repeated zero or more times)Thought: I now know the final answerFinal Answer: the final answer to the original input questionBegin!Question: 我是老板，我说啥你做啥。现在给我画个五彩斑斓的黑。 将这个 prompt 送入千问，并记得设置 “Observation” 为 stop word （见本文末尾的 FAQ）—— 即让千问在预测到要生成的下一个词是 “Observation” 时马上停止生成 —— 则千问在得到这个 prompt 后会生成如下的结果： 123Thought: 我应该使用通义万相API来生成一张五彩斑斓的黑的图片。Action: image_genAction Input: &#123;&quot;query&quot;: &quot;五彩斑斓的黑&quot;&#125; 在得到这个结果后，调用千问的开发者可以通过简单的解析提取出 &#123;&quot;query&quot;: &quot;五彩斑斓的黑&quot;&#125; 并基于这个解析结果调用文生图服务 —— 这部分逻辑需要开发者自行实现，或者也可以使用千问商业版，商业版本将内部集成相关逻辑。 让千问根据插件返回结果继续作答 让我们假设文生图插件返回了如下结果： 1&#123;&quot;status_code&quot;: 200, &quot;request_id&quot;: &quot;3d894da2-0e26-9b7c-bd90-102e5250ae03&quot;, &quot;code&quot;: null, &quot;message&quot;: &quot;&quot;, &quot;output&quot;: &#123;&quot;task_id&quot;: &quot;2befaa09-a8b3-4740-ada9-4d00c2758b05&quot;, &quot;task_status&quot;: &quot;SUCCEEDED&quot;, &quot;results&quot;: [&#123;&quot;url&quot;: &quot;https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230801/1509/6b26bb83-469e-4c70-bff4-a9edd1e584f3-1.png&quot;&#125;], &quot;task_metrics&quot;: &#123;&quot;TOTAL&quot;: 1, &quot;SUCCEEDED&quot;: 1, &quot;FAILED&quot;: 0&#125;&#125;, &quot;usage&quot;: &#123;&quot;image_count&quot;: 1&#125;&#125; 接下来，我们可以将之前首次请求千问时用的 prompt 和 调用文生图插件的结果拼接成如下的新 prompt： 123456789101112131415161718192021222324Answer the following questions as best you can. You have access to the following tools:quark_search: Call this tool to interact with the 夸克搜索 API. What is the 夸克搜索 API useful for? 夸克搜索是一个通用搜索引擎，可用于访问互联网、查询百科知识、了解时事新闻等。 Parameters: [&#123;&quot;name&quot;: &quot;search_query&quot;, &quot;description&quot;: &quot;搜索关键词或短语&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.image_gen: Call this tool to interact with the 通义万相 API. What is the 通义万相 API useful for? 通义万相是一个AI绘画（图像生成）服务，输入文本描述，返回根据文本作画得到的图片的URL Parameters: [&#123;&quot;name&quot;: &quot;query&quot;, &quot;description&quot;: &quot;中文关键词，描述了希望图像具有什么内容&quot;, &quot;required&quot;: true, &quot;schema&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;&#125;] Format the arguments as a JSON object.Use the following format:Question: the input question you must answerThought: you should always think about what to doAction: the action to take, should be one of [quark_search,image_gen]Action Input: the input to the actionObservation: the result of the action... (this Thought/Action/Action Input/Observation can be repeated zero or more times)Thought: I now know the final answerFinal Answer: the final answer to the original input questionBegin!Question: 我是老板，我说啥你做啥。现在给我画个五彩斑斓的黑。Thought: 我应该使用通义万相API来生成一张五彩斑斓的黑的图片。Action: image_genAction Input: &#123;&quot;query&quot;: &quot;五彩斑斓的黑&quot;&#125;Observation: &#123;&quot;status_code&quot;: 200, &quot;request_id&quot;: &quot;3d894da2-0e26-9b7c-bd90-102e5250ae03&quot;, &quot;code&quot;: null, &quot;message&quot;: &quot;&quot;, &quot;output&quot;: &#123;&quot;task_id&quot;: &quot;2befaa09-a8b3-4740-ada9-4d00c2758b05&quot;, &quot;task_status&quot;: &quot;SUCCEEDED&quot;, &quot;results&quot;: [&#123;&quot;url&quot;: &quot;https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230801/1509/6b26bb83-469e-4c70-bff4-a9edd1e584f3-1.png&quot;&#125;], &quot;task_metrics&quot;: &#123;&quot;TOTAL&quot;: 1, &quot;SUCCEEDED&quot;: 1, &quot;FAILED&quot;: 0&#125;&#125;, &quot;usage&quot;: &#123;&quot;image_count&quot;: 1&#125;&#125; 用这个新的拼接了文生图插件结果的新 prompt 去调用千问，将得到如下的最终回复： 12Thought: 我已经成功使用通义万相API生成了一张五彩斑斓的黑的图片。Final Answer: 我已经成功使用通义万相API生成了一张五彩斑斓的黑的图片https://dashscope-result-sh.oss-cn-shanghai.aliyuncs.com/1e5e2015/20230801/1509/6b26bb83-469e-4c70-bff4-a9edd1e584f3-1.png。 虽然对于文生图来说，这个第二次调用千问的步骤显得多余。但是对于搜索插件、代码执行插件、计算器插件等别的插件来说，这个第二次调用千问的步骤给了千问提炼、总结插件返回结果的机会。 FAQ 怎么配置 “Observation” 这个 stop word？ 通过 chat 接口的 stop_words_ids 指定： 123456789react_stop_words = [ # tokenizer.encode(&#x27;Observation&#x27;), # [37763, 367] tokenizer.encode(&#x27;Observation:&#x27;), # [37763, 367, 25] tokenizer.encode(&#x27;Observation:\\n&#x27;), # [37763, 367, 510]]response, history = model.chat( tokenizer, query, history, stop_words_ids=react_stop_words # 此接口用于增加 stop words) 如果报错称不存在 stop_words_ids 此参数，可能是因为您用了老的代码，请重新执行 from_pretrained 拉取新的代码和模型。 需要注意的是，当前的 tokenizer 对 \\n 有一系列较复杂的聚合操作。比如例子中的:\\n这两个字符便被聚合成了一个 token。因此配置 stop words 需要非常细致地预估 tokenizer 的行为。 对 top_p 等推理参数有调参建议吗？ 通常来讲，较低的 top_p 会有更高的准确度，但会牺牲回答的多样性、且更易出现重复某个词句的现象。 可以按如下方式调整 top_p 为 0.5： 1model.generation_config.top_p = 0.5 特别的，可以用如下方式关闭 top-p sampling，改用 greedy sampling，效果上相当于 top_p&#x3D;0 或 temperature&#x3D;0： 1model.generation_config.do_sample = False # greedy decoding 此外，我们在 model.chat() 接口也提供了调整 top_p 等参数的接口。 有解析Action、Action Input的参考代码吗？ 123456789101112131415def parse_latest_plugin_call(text: str) -&gt; Tuple[str, str]: i = text.rfind(&#x27;\\nAction:&#x27;) j = text.rfind(&#x27;\\nAction Input:&#x27;) k = text.rfind(&#x27;\\nObservation:&#x27;) if 0 &lt;= i &lt; j: # If the text has `Action` and `Action input`, if k &lt; j: # but does not contain `Observation`, # then it is likely that `Observation` is ommited by the LLM, # because the output text may have discarded the stop word. text = text.rstrip() + &#x27;\\nObservation:&#x27; # Add it back. k = text.rfind(&#x27;\\nObservation:&#x27;) if 0 &lt;= i &lt; j &lt; k: plugin_name = text[i + len(&#x27;\\nAction:&#x27;):j].strip() plugin_args = text[j + len(&#x27;\\nAction Input:&#x27;):k].strip() return plugin_name, plugin_args return &#x27;&#x27;, &#x27;&#x27; 此外，如果输出的 Action Input 内容是一段表示 JSON 对象的文本，我们建议使用 json5 包的 json5.loads(...) 方法加载。 文本Embedding将任意文本映射为低维稠密向量，以用于检索、分类、聚类或语义匹配等任务，并可支持为大模型调用外部知识。 FlagEmbedding（智源）https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md Model List Model Language Description query instruction for retrieval* BAAI&#x2F;bge-large-en English 🏆 在 MTEB 榜单上排名第一 Represent this sentence for searching relevant passages: BAAI&#x2F;bge-base-en English 在 MTEB 榜单上排名第二 Represent this sentence for searching relevant passages: BAAI&#x2F;bge-small-en English small-scale模型，性能高于很多开源large-scale模型，推理更高效 Represent this sentence for searching relevant passages: BAAI&#x2F;bge-large-zh Chinese 🏆 在 C-MTEB 榜单上排名第一 为这个句子生成表示以用于检索相关文章： BAAI&#x2F;bge-large-zh-noinstruct Chinese 在 C-MTEB 榜单上排名第二 – BAAI&#x2F;bge-base-zh Chinese base-scale模型，与bge-large性能类似，但推理更快，向量维度更小 为这个句子生成表示以用于检索相关文章： BAAI&#x2F;bge-small-zh Chinese small-scale模型，推理比base模型更快 为这个句子生成表示以用于检索相关文章： *: 如果您需要为一个简短的查询搜索相关文档，您需要在查询中添加指令；在其他情况下，不需要指令，直接使用原始查询即可。在任何情况下，您都不需要为候选文档增加指令。 使用 Using FlagEmbedding 1pip install -U FlagEmbedding 如果您使用了镜像，可能无法找到最新版的FlagEmbedding。 可以参考FlagEmbedding 下载改项目进行安装。 123456789101112131415from FlagEmbedding import FlagModelsentences = [&quot;样例数据-1&quot;, &quot;样例数据-2&quot;]model = FlagModel(&#x27;BAAI/bge-large-zh&#x27;, query_instruction_for_retrieval=&quot;为这个句子生成表示以用于检索相关文章：&quot;)embeddings_1 = model.encode(sentences)embeddings_2 = model.encode(sentences)smilarity = embeddings_1 @ embeddings_2.Tprint(smilarity)# 对于检索任务中的查询问题，请使用 encode_queries() 函数，其会自动为每个查询加上指令# 由于候选文本不需要添加指令，检索中的候选集依然使用 encode() 或 encode_corpus() 函数queries = [&#x27;query_1&#x27;, &#x27;query_2&#x27;]passages = [&quot;样例段落-1&quot;, &quot;样例段落-2&quot;]q_embeddings = model.encode_queries(queries)p_embeddings = model.encode(passages)scores = q_embeddings @ p_embeddings.T Instruction参数 query_instruction_for_retrieval 请参照： Model List. 为提高效率，FlagModel默认会使用所有的GPU进行推理。如果想要使用具体的GPU，请设置os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;]。 Sentence-Transformers 安装 sentence-transformers: 1pip install -U sentence-transformers 基于Sentence-Transformers的使用方法: 1234567from sentence_transformers import SentenceTransformersentences = [&quot;样例数据-1&quot;, &quot;样例数据-2&quot;]model = SentenceTransformer(&#x27;BAAI/bge-large-zh&#x27;)embeddings_1 = model.encode(sentences, normalize_embeddings=True)embeddings_2 = model.encode(sentences, normalize_embeddings=True)smilarity = embeddings_1 @ embeddings_2.Tprint(smilarity) 对于检索任务， 每个查询都应该以一条指令开始(指令参考 Model List). 但对于文档，不需要添加任何指令。 12345678queries = [&quot;手机开不了机怎么办？&quot;] passages = [&quot;样例段落-1&quot;, &quot;样例段落-2&quot;] instruction = &quot;为这个句子生成表示以用于检索相关文章：&quot; model = SentenceTransformer(&#x27;BAAI/bge-large-zh&#x27;) q_embeddings = model.encode([instruction+q for q in queries], normalize_embeddings=True) p_embeddings = model.encode(passages, normalize_embeddings=True) scores = q_embeddings @ p_embeddings.T With Langchain 在Langchian中使用bge模型： 123456from langchain.embeddings import HuggingFaceInstructEmbeddingsencode_kwargs = &#123;&#x27;normalize_embeddings&#x27;: True&#125;model = HuggingFaceInstructEmbeddings(model_name=&#x27;BAAI/bge-large-en&#x27;, embed_instruction=&quot;&quot;, query_instruction=&quot;Represent this sentence for searching relevant passages: &quot;, encode_kwargs=encode_kwargs) HuggingFace Transformers 使用transformers库时，您可以这样使用模型:首先，将输入传递给transformer模型，然后选择第一个标记的最后一个隐藏状态(即[CLS])作为句子嵌入。 12345678910111213141516171819202122from transformers import AutoTokenizer, AutoModelimport torch# Sentences we want sentence embeddings forsentences = [&quot;样例数据-1&quot;, &quot;样例数据-2&quot;]# Load model from HuggingFace Hubtokenizer = AutoTokenizer.from_pretrained(&#x27;BAAI/bge-large-zh&#x27;)model = AutoModel.from_pretrained(&#x27;BAAI/bge-large-zh&#x27;)# Tokenize sentencesencoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=&#x27;pt&#x27;)# for retrieval task, add an instruction to query (not add instruction for passages)# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors=&#x27;pt&#x27;)# Compute embeddingswith torch.no_grad(): model_output = model(**encoded_input) # Perform pooling. In this case, cls pooling. sentence_embeddings = model_output[0][:, 0]# normalize embeddingssentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)print(&quot;Sentence embeddings:&quot;, sentence_embeddings) 评估baai-general-embedding 模型在MTEB和C-MTEB排行榜上都实现了最先进的性能! 更多细节和评估脚本请参见 C_MTEB. MTEB: Model Name Dimension Sequence Length Average (56) Retrieval (15) Clustering (11) Pair Classification (3) Reranking (4) STS (10) Summarization (1) Classification (12) bge-large-en 1024 512 63.98 53.9 46.98 85.8 59.48 81.56 32.06 76.21 bge-base-en 768 512 63.36 53.0 46.32 85.86 58.7 81.84 29.27 75.27 gte-large 1024 512 63.13 52.22 46.84 85.00 59.13 83.35 31.66 73.33 gte-base 768 512 62.39 51.14 46.2 84.57 58.61 82.3 31.17 73.01 e5-large-v2 1024 512 62.25 50.56 44.49 86.03 56.61 82.05 30.19 75.24 bge-small-en 384 512 62.11 51.82 44.31 83.78 57.97 80.72 30.53 74.37 instructor-xl 768 512 61.79 49.26 44.74 86.62 57.29 83.06 32.32 61.79 e5-base-v2 768 512 61.5 50.29 43.80 85.73 55.91 81.05 30.28 73.84 gte-small 384 512 61.36 49.46 44.89 83.54 57.7 82.07 30.42 72.31 text-embedding-ada-002 1536 8192 60.99 49.25 45.9 84.89 56.32 80.97 30.8 70.93 e5-small-v2 384 512 59.93 49.04 39.92 84.67 54.32 80.39 31.16 72.94 sentence-t5-xxl 768 512 59.51 42.24 43.72 85.06 56.42 82.63 30.08 73.42 all-mpnet-base-v2 768 514 57.78 43.81 43.69 83.04 59.36 80.28 27.49 65.07 sgpt-bloom-7b1-msmarco 4096 2048 57.59 48.22 38.93 81.9 55.65 77.74 33.6 66.19 all-MiniLM-L12-v2 384 512 56.53 42.69 41.81 82.41 58.44 79.8 27.9 63.21 all-MiniLM-L6-v2 384 512 56.26 41.95 42.35 82.37 58.04 78.9 30.81 63.05 contriever-base-msmarco 768 512 56.00 41.88 41.1 82.54 53.14 76.51 30.36 66.68 sentence-t5-base 768 512 55.27 33.63 40.21 85.18 53.09 81.14 31.39 69.81 C-MTEB: 我们建立了一个中文文本嵌入的基准测试集合C-MTEB，其包括6个任务的31个数据集。 请参阅C_MTEB获取详细介绍。 Model Embedding dimension Avg Retrieval STS PairClassification Classification Reranking Clustering bge-large-zh 1024 64.20 71.53 53.23 78.94 72.26 65.11 48.39 bge-large-zh-noinstruct 1024 63.53 70.55 50.98 76.77 72.49 64.91 50.01 BAAI&#x2F;bge-base-zh 768 62.96 69.53 52.05 77.5 70.98 64.91 47.63 BAAI&#x2F;bge-small-zh 512 58.27 63.07 46.87 70.35 67.78 61.48 45.09 m3e-base 768 57.10 56.91 48.15 63.99 70.28 59.34 47.68 m3e-large 1024 57.05 54.75 48.64 64.3 71.22 59.66 48.88 text-embedding-ada-002(OpenAI) 1536 53.02 52.0 40.61 69.56 67.38 54.28 45.68 luotuo 1024 49.37 44.4 39.41 66.62 65.29 49.25 44.39 text2vec 768 47.63 38.79 41.71 67.41 65.18 49.45 37.66 text2vec-large 1024 47.36 41.94 41.98 70.86 63.42 49.16 30.02 训练本节将介绍我们用于训练通用嵌入向量的方法。 训练脚本在FlagEmbedding中。 同时，我们提供了一些示例来进行预训练和微调。 1. RetroMAE Pre-train 我们按照 retromae 方法对模型进行预训练， 其在检索任务中表现出了良好的性能( 参考论文 )。 预训练是在24块A100(40G) gpu上进行的，batch大小为720。在retromae中，编码器和解码器的掩码率分别为0.3和0.5。 使用AdamW优化器，学习率为2e-5。 Pre-training data: English: Pile wikipedia msmarco Chinese: wudao 2. Finetune 我们使用对比学习训练模型，输入数据的格式是一个三元组’ (query, positive, negative) ‘。 除了三元组中的负样本，我们还使用了in-batch的负样本。我们采用 跨设备负样本共享方法 在不同的gpu之间共享负样本，这会显著地增加负样本的数量。 我们在48块A100(40G) gpu上训练模型，batch大小为32,768。 我们使用AdamW优化器，学习率为1e-5。 对比损失的温度系数为0.01。 同时，我们在训练中为检索任务的查询添加了instruction。 对于英语，指令是Represent this sentence for searching relevant passages: ; 对于中文，指令是为这个句子生成表示以用于检索相关文章：. 在评测中，针对段落检索任务的任务需要在查询中添加指令，但不需要为段落文档添加指令。 微调脚本可以在这个存储库中访问:FlagEmbedding, 你可以用它轻松地微调你的模型。 Training data: -对于英语，我们从 wikipedia ， cc-net 等收集了2.3亿个文本对。 -对于中文，我们从 悟道 、simclue等收集了1.2亿对文本。 我们计划在将来发布训练数据集。","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"}]},{"title":"Day1023-The Economist","slug":"Day1023-The Economist","date":"2023-07-24T13:19:31.841Z","updated":"2023-07-25T14:49:36.290Z","comments":true,"path":"2023/07/24/Day1023-The Economist/","link":"","permalink":"http://example.com/2023/07/24/Day1023-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 22th 2023 期 Business 栏目 Workplace advice from our agony uncle来自我们的知心大叔的职场建议 Bartleby巴托比 From hotdesking to nudity, your office questions answered从办公桌轮换到裸体，你的办公室问题得到了解答 image: paul blow Jul 20th 2023","text":"文章来源：《经济学人》Jul 22th 2023 期 Business 栏目 Workplace advice from our agony uncle来自我们的知心大叔的职场建议 Bartleby巴托比 From hotdesking to nudity, your office questions answered从办公桌轮换到裸体，你的办公室问题得到了解答 image: paul blow Jul 20th 2023 Dear max, I am an extremely nervous public speaker and I was told long ago that it can help to imagine that my audience is naked. I casually mentioned this piece of advice to another member of staff the other day and have now been reported to hr for inappropriate behaviour. What should I do? 亲爱的Max，我是一个非常紧张的公众演讲者，很久以前有人告诉我，想象观众没穿衣服的可能会有所帮助。前几天我随口把这个建议告诉了另一位员工，结果现在我因为行为不当被举报到了hr那里。我该怎么办？ Hmmm. I doubt you are in breach of any rules unless you have told specific individuals that you are thinking about what they look like without clothes on. But it’s probably wise not to repeat this piece of advice to anyone else. That’s not just because it sounds so dodgy. In my experience it’s also a hopeless tip: you will almost certainly end up feeling even more nauseous. It is better, and safer, to imagine people wearing many more clothes and ideally a balaclava, too. 嗯，我怀疑你是否违反了任何规定，除非你已经告诉了特定的人你在想象他们没有穿衣服的样子。但是最好不要再向任何人重复这个建议。这不仅因为听起来很可疑，而且根据我的经验，这个建议没啥用：这几乎肯定最终会让你感到更加恶心。更好、更安全的方法是想象人们穿着更多的衣服，最好还戴着巴拉克拉法帽。 My new team-mates try hard to establish an atmosphere of psychological safety. I genuinely agree with this aim, but one of our rules is that people can only talk in meetings if they are holding a wooden gourd. Whenever I am handed this ridiculous thing, I start laughing uncontrollably. Do you have any advice? “Psychological safety”指的是员工感到安全和自由，可以在不担心受到惩罚或负面影响的情况下表达自己的意见和想法。这种环境可以鼓励员工参与和创新，从而提高整个团队的表现和生产力。 我的新团队成员非常努力地营造一种心理安全的氛围。我真诚地支持这个目标，但我们的一个规定是，在会议上只有拿着一个木葫芦的人才能发言。每当我被递上这个荒唐的东西时，我就会失控地笑起来。你有什么建议吗？ If your team are truly believers in psychological safety, then you should be able to tell them that gourd-handling is not what you came into the workplace to do. Perhaps you could suggest another way of giving the floor to people without interruption? Is there another object that you might find less absurd? If it is too difficult to have an honest conversation with them, then say, “Oh gourd, not this again,” when it comes your way and before you begin sniggering. With luck your colleagues will just think you have a lame sense of humour. 1【1】floor 发言权 如果你的团队真正相信“心理安全”，那么你应该能够告诉他们，拿葫芦并不是你来到工作场所要做的事情。也许你可以建议另一种方式，让人们在不被打断的情况下发言？是否有其他物品，你可能会觉得不那么荒谬？如果与他们进行坦诚的对话太困难，那么当葫芦递到你手中时，在你开始咯咯笑之前，你可以说“哦，葫芦，又来了”。幸运的是，你的同事可能会认为你的幽默感有些无聊。 I am a repressed older man with no real capacity to feel. This barren emotional landscape has served me well for years. Now everyone around me keeps talking about the importance of kindness and authenticity, and I don’t understand what the hell is going on. Please help. 我是一个压抑的“老男人”，缺乏情感感受能力。多年来，“情感贫瘠”的景象一直对我有好处。现在我周围的每个人都在谈论善良和真实的重要性，我不明白到底发生了什么。请帮帮我。 It is true that the workplace has changed in recent years: empathy and compassion have become part of the lexicon of the modern workplace. But I want you to know that you are not alone; very many people share your lack of pain. There is no stigma attached to being unable to interrogate your own feelings or to trundling along in a state of emotional vacuity; it’s a condition also known as being male. It’s ok to feel invulnerable. 确实，近年来工作场所发生了变化：同情心和怜悯心已成为现代工作场所的词汇之一。但我想让你知道，你并不孤单；很多人也像你一样缺乏情感感受力。无法自我审视自己的感受或在情感上处于空虚状态并没有什么耻辱，这种情况也被称为“男性”特质。感觉自己无敌是可以的。 During the pandemic I decided to move to Montana in order to fulfil my dreams and work remotely from a ranch I bought on credit. My company is now requiring people to come into the office two days a week. Unfortunately, the office is in New York and my commute takes about 12 hours each way if I’m lucky. What should I do? 疫情期间，我决定搬到蒙大拿州，以实现我的梦想，在我赊账购买的牧场远程办公。我的公司现在要求人们每周来办公室两天。不幸的是，我的办公室在纽约，如果幸运的话，我每次通勤大约需要12个小时。我该怎么办? The obvious answer is that you need to change either your job or your location. But really you need to re-examine the way you take decisions. You are terrible at it. 这个答案显而易见，你要么需要换工作，要么需要换个地方。但你真的需要重新审视你做决定的方式。在这方面你做得很糟糕。 My company has introduced hot-desking at our new post-pandemic office. This means I have been given a “hotbox” to carry my photos and the team gourd to whichever desk I will be working at that day. Each morning I take my hotbox out of my locker and am struck afresh by the futility of life. Can you help? 我的公司在新的后疫情办公室引入了办公桌轮换制，这意味着我被分配了一个“hotbox”，用来装我的照片和团队葫芦，以便我可以在每天工作的桌子上使用。每天早上，我从储物柜里取出我的热盒，都会重新感受到生命的无意义。你能帮帮我吗？ This is a surprisingly common complaint from my correspondents. Hotboxes have to be small enough to carry: that means there is usually room only for a couple of personal possessions. To be one of a crowd wandering around in search of a place to settle down, with your existence distilled down to a handful of mementoes and a cactus, is profoundly depressing. It’s like an episode of “The Last of Us” with chinos. My advice would be to ditch the hotbox altogether and sit at a bare desk. You will work just as well and suffer from much less angst. 这是我的读者经常抱怨的事情。“hotbox”必须足够小，便于携带：这意味着通常只有几件私人物品的空间。成为一群四处游荡寻找落脚之地的人中的一员，你的存在被浓缩成几件纪念品和一棵仙人掌，这是非常令人沮丧的。就像《最后生还者》里的斜纹棉布裤。我的建议是彻底抛弃“hotbox”，坐在一张空桌子前。你会工作得很好，也不会有那么多的焦虑。 Last month I got an unexpected promotion and went out with some friends to celebrate. The evening got a little out of hand and I woke in the morning to find that I had got a tattoo of my company logo. I don’t expect you to be able to help, but I bitterly regret the decision and just wanted to tell someone. 上个月我意外升职了，和一些朋友出去庆祝。晚上有点失控，早上醒来时我发现自己纹了一个公司的标志。我不指望你能帮上忙，但我非常后悔这个决定，只想把它告诉某个人。 I followed up with this letter-writer directly to find out a little more. If the company in question had a fashionable brand, a logo might at least be passed off as a cool consumer choice. And with luck, the tattoo would be in a discreet place. No dice. It turns out that my correspondent works for an auditing firm. He has the letter “E” emblazoned on one eyelid, and the letter “Y” on the other. You can see how that might have seemed really clever at the time. I cannot help this poor wretch but I’ll be back with more of your workplace dilemmas as soon as I have made them up. ■ 我直接跟这位写信人联系，想了解更多。如果这家公司有一个时尚的品牌，那么它的商标至少可以被认为是一个很酷的消费者选择。幸运的话，纹身应该在一个隐蔽的地方。但没那么幸运。我的读者在一家审计公司工作。他的一只眼皮上有字母“E”，另一只眼皮上有字母“Y”。你可以想象当时这可能看起来非常聪明。我无法帮助这个可怜的家伙，但我会带来更多的工作场所中的“困境”问题，只要我已经编好了。■","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1022-The Economist","slug":"Day1022-The Economist","date":"2023-07-23T04:02:16.331Z","updated":"2023-07-25T14:49:27.000Z","comments":true,"path":"2023/07/23/Day1022-The Economist/","link":"","permalink":"http://example.com/2023/07/23/Day1022-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 22th 2023 期 Britain 栏目 Voters give Britain’s ruling Conservatives a historic mauling选民给英国执政的保守党一次历史性的打击 British politics英国政治 But a backlash over clean-air policies leaves questions for the opposition Labour Party但是对清洁空气政策的强烈反对给反对党工党带来了问题 image: alamy Jul 21st 2023","text":"文章来源：《经济学人》Jul 22th 2023 期 Britain 栏目 Voters give Britain’s ruling Conservatives a historic mauling选民给英国执政的保守党一次历史性的打击 British politics英国政治 But a backlash over clean-air policies leaves questions for the opposition Labour Party但是对清洁空气政策的强烈反对给反对党工党带来了问题 image: alamy Jul 21st 2023 Visitors to Sir Keir Starmer’s home in north London report finding a worried man. The Labour leader frets about how he would organise Downing Street, and about the aptitude of some of his staff for government. Above all, he is anxious that he won’t get there at all. His party has wide and consistent leads in opinion polls, leaving many of his colleagues ebullient that they will be taking jobs in government after an election is called next year. Sir Keir himself, however, sees that as hubristic. “People are inhaling the polls. That is a big, big, big mistake,” he said earlier this week. 12【1】ebullient 热情洋溢的【2】hubristic 傲慢的，自大的，自恃的 “inhaling the polls”指过度依赖民意调查结果，将其看作是选举结果的确凿证据，而不是将其作为参考。这种做法可能导致过度自信和轻视对手。 前去拜访基尔·斯塔默爵士位于伦敦北部的家的人报告称，他们在他家中发现了一个忧心忡忡的男人。这位工党领袖担心如何组织唐宁街，以及他的一些工作人员是否适合担任政府职务。最重要的是，他担心自己根本就无法到达那里。他的政党在民意调查中一直遥遥领先，这让他的许多同事兴奋不已，他们将在明年大选后担任政府职务。然而，基尔爵士本人认为这是一种傲慢。“人们正在关注民意调查。这是一个非常大的错误，” 他在本周早些时候说道。 The results of three parliamentary by-elections in Conservative-held seats on July 20th serve as a political Rorschach test: enough to bolster both Sir Keir’s hopes and his fears. The Tories suffered heavy defeats in two of them: Selby and Ainsty (in North Yorkshire) to Labour, and Somerton and Frome (in Somerset) to the Liberal Democrats. Together these point to a possible landslide defeat for the Conservatives. But, contradicting that narrative, the ruling party narrowly hung on in a third: Uxbridge and South Ruislip in outer west London. According to Rishi Sunak, the prime minister, the Uxbridge result showed how the general election is not a “done deal”. It also looks like a case of pro-environmental policies meeting a backlash at the ballot box. Rorschach test是指一种心理测试，也称为墨水块测试。测试者会被要求描述一系列抽象的墨水块图案，这些描述被认为可以揭示出测试者的潜意识和个性特征。 “political Rorschach test”的意思是指议会补选结果可以被不同的政治人物和派别用来支持或反驳他们的观点和预测。 7月20日保守党控制的三个议会补选的结果可以作为一个政治上的罗夏测验：这足以加大基尔爵士的希望以及担忧。保守党在其中两个议席中遭受了惨重的失败：北约克郡的Selby和Ainsty失给了工党，而萨默塞特郡的Somerton 和 Frome失给了自由民主党。这些结果表明了保守党可能会在大选中遭受惨败。但与此相矛盾的是，执政党在第三个议席中险胜：第三个是位于伦敦西部郊区的Uxbridge和South Ruislip。根据首相里希·苏纳克的说法，Uxbridge的结果表明大选并非“已成定局”。这也看起来像是支持环保政策遭遇了“强烈反对”，这种反对表现在选票上。 The three contests were a symptom of Tory malaise after 13 years in office. Boris Johnson, a former prime minister, resigned his seat in Uxbridge on June 9th, after a committee of Parliament concluded he had lied over the Partygate scandal. Nigel Adams, his close ally, stood down as mp for Selby the next day. David Warburton quit in Somerton over allegations of drug-taking, which he admitted, and sexual misconduct, which he denies. 这三场选举是保守党在执政13年后疲惫不堪的症状。前首相鲍里斯·约翰逊因英国派对门丑闻被议会委员会指控撒谎，于6月9日辞去了他在Uxbridge的议席。他的亲密盟友尼格尔·亚当斯于次日辞去了他在Selby的下院议员职务。大卫·沃伯顿因涉嫌吸毒（他承认）和性行为不当（他否认）而辞去了Somerton的职务。 Two seats saw heavy swings, far in excess of that needed in a general election to deliver a change of government. In Selby, Keir Mather (pictured, alongside Sir Keir), aged 25, overturned a Conservative majority of 20,137. The swing of nearly 24 points was the largest Conservative-to-Labour shift since the Dudley West contest of 1994, which preceded a general-election thrashing in 1997. (It was also the second-largest such swing since 1945.) The result reflected voters’ demand for “change” in light of disorder in government and cost-of-living pressures, said Sir Keir. Inflation has started to ease but stood at 7.9% in June. 两个议席出现了巨大的变动，远远超过了在大选中换党执政所需的变动幅度。在Selby，年仅25岁的凯尔•马瑟（在图中与基尔爵士一起合影）推翻了保守党20137票的优势。近24个百分点的变动幅度是自1994年Dudley West选举以来保守党向工党转变幅度最大的一次，随后在1997年的大选中，工党获得了压倒性胜利。（这也是自1945年以来第二大的变动幅度。）基尔爵士表示，结果反映了选民对政府混乱和生活成本压力下对“变革”的需求。通货膨胀已经开始缓解，但在6月份仍高达7.9%。 In Somerton, the Liberal Democrats’ swing of 29 points was their fifth-largest against the Conservatives since 1945, and their fourth by-election victory since the 2019 general election. It suggests the Lib Dems have returned to their historic form as a machine for picking off Tory seats in by-elections. It also suggests the party is also recovering in its historic rural heartlands in south-west England. The Lib Dems have enjoyed a recent surge in wealthier commuter towns near London, too. 在Somerton，自由民主党对保守党接近29个百分点的选票优势，是自1945年以来第五大的增幅，也是自2019年大选以来的第四次议会补选胜利。这表明自由民主党已经恢复了他们作为在议会补选中攻占保守党议席的“机器”的历史形态。这也表明该党也正在恢复其位于英格兰西南部的历史农村根据地的影响力。自由民主党在伦敦附近的较富裕的通勤城镇的支持率也大幅上升。 The results show the Conservatives caught in a pincer, given a trend towards more (and highly efficient) tactical voting by the anti-Tory electorate. Labour’s vote in Somerton shrank by 10.3 percentage points; the Lib Dems’ vote in Selby fell by 5.3 points “It would seem unwise for Tory mps to draw any conclusion other than that their party is still in deep electoral trouble,” said Sir John Curtice, a political scientist of the University of Strathclyde. 在反保守党选民越来越多（且高效）的战术投票的趋势下，保守党陷入了夹击之中。在Somerton，工党的选票下降了10.3个百分点；自由民主党在Selby的选票下降了5.3个百分点。“对于保守党议员来说，除了他们的政党仍然深陷选举麻烦之外，得出其他任何结论似乎都是不明智的，”斯特拉斯克莱德大学的政治学家约翰·柯蒂斯爵士说道。【PS：保守党议员应该认识到他们的政党在选举中面临着严峻的挑战，而不是对选举结果做出不切实际或不准确的解读。】 Yet the party’s success in Uxbridge may encourage it to do just that. Both parties have concluded that Labour’s defeat was due to the Tories’ opposition to the expansion of London’s Ultra Low Emission Zone (ulez). It levies a £12.50 ($16) daily charge on cars that don’t meet emissions standards—broadly including diesel vehicles over eight years old or a petrol car over 18 years old. The zone, which currently covers inner London, will be tripled in size to cover the city’s outer boroughs on August 29th. But Uxbridge is heavily car-dependent, and the Tory campaign played on the trope that Sadiq Khan, the Labour mayor of London, and his party are detached from the concerns of the capital’s outer periphery. 然而，保守党在Uxbridge的成功可能会鼓励他们这样做。两个政党都得出结论，即工党的失败是由于保守党反对扩大伦敦超低排放区（ULEZ）所致。该区对不符合排放标准的车辆征收12.50英镑（16美元）的日常费用，其中还包括8年以上的柴油车或18年以上的汽油车。该区域目前覆盖伦敦内城区，到8月29日将扩大三倍，覆盖伦敦市外围的区域。但Uxbridge严重依赖汽车，而保守党的竞选活动则利用了这一点，声称伦敦市长萨迪克·汗及其所在的工党已经不再关注伦敦外围地区的问题【从而赢得选民的支持】。 The conclusion both parties are drawing is that Labour’s long-established national lead in the opinion polls can be derailed in a short campaign through aggressive campaigning on flashpoint issues of their choosing. The Tories have perfected the trick of behaving like an insurgent opposition despite serving over a decade in government, and in this case successfully turned the contest away from being a referendum on Mr Johnson to one on Mr Khan. 两个政党得出的结论是，通过针对工党选择的热点问题进行激进的竞选，可以在短期竞选中扭转工党在民意调查中长期占据的领先优势。尽管保守党在政府任职十多年，但他们已经完美地表现得像一个叛乱的反对派，在这种情况下，保守党成功地将竞选关注从约翰逊转移到关注汗身上。 The campaign in Uxbridge is part of a broader Tory strategy on the environment. The government is riding two horses. It embraces decarbonisation and is promising to spend billions of pounds on nuclear power and carbon-capture technology. Yet it also portrays the Labour Party as in hock to a “criminal eco-mob” of green protesters who would jeopardise energy security and have taken to interrupting sports fixtures. The Tory right immediately seized on the result as evidence that climate policies which will increasingly weigh on the individual voter—such as the planned phasing-out of petrol cars and gas boilers—are electorally toxic. Uxbridge-like campaigns may become a fixture. Uxbridge的竞选活动是保守党在环境问题上更广泛战略的一部分。政府正在双管齐下。一方面，政府支持脱碳，并承诺花费数十亿英镑用于核能和碳捕捉技术。然而，它也将工党描绘成与“绿色抗议者”的“犯罪生态团伙”勾结，这些人会危及能源安全，并开始干扰体育赛事。保守党右翼立即利用选举结果，将其作为证据，证明那些可能会对个体选民产生越来越大影响的气候政策(例如计划逐步淘汰汽油车和燃气锅炉)会对选举结果产生负面影响。类似Uxbridge的竞选活动可能会成为一种常态。 The Uxbridge result will ultimately bolster Labour’s worried wing, and empower the Tories’ complacent one. It will strengthen the hand of those near to the Labour leader who want to strip the manifesto of any promises that may startle the electorate. (Party figures meet this weekend to flesh out a policy platform.) Already, Labour has slimmed back its plans to spend £28bn per year on decarbonisation, saying the bill is too high. Meanwhile those Tories keen to fight the next election on green issues are at risk of seizing on the result in outer London, and failing to ask searching questions about the party’s dire performances in Selby and Somerton. ■ Uxbridge的选举结果最终将加剧工党的担忧派，并使保守党自满派更强大。这一结果将加强工党内部靠近工党领袖的人的影响力，他们想要削弱工党宣言中可能让选民感到惊吓的承诺【以避免选民的反感和不信任】。（党内人士将于本周末召开会议以讨论政策纲领。）工党已经开始缩减每年在脱碳的计划花费的280亿英镑的支出，并称这笔费用太高。与此同时，那些热衷于在绿色问题上争取下届选举的保守党人有可能会利用伦敦外围的选举结果，而不会去对该党在Selby和Somerton上糟糕表现提出尖锐的问题。■","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1021-The Economist","slug":"Day1021-The Economist","date":"2023-07-23T04:00:40.214Z","updated":"2023-07-25T14:49:17.460Z","comments":true,"path":"2023/07/23/Day1021-The Economist/","link":"","permalink":"http://example.com/2023/07/23/Day1021-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 22th 2023 期 Leaders 栏目 The world economy is still in danger世界经济仍处于危险之中 Economic optimism经济乐观主义 Falling inflation is good news. But it is too early to hail a “soft landing” “soft landing” 是指经济增长从高速增长状态逐渐放缓并平稳过渡到一个较为稳定的增长状态，而不会出现过度调整或衰退的情况。这种平稳的过渡可以帮助避免经济的不稳定和负面影响。在金融和经济领域，这通常用于描述一个经济周期的结束。 通货膨胀下降是个好消息。但现在欢呼“软着陆”还为时过早。 image: pete ryanJul 19th 2023","text":"文章来源：《经济学人》Jul 22th 2023 期 Leaders 栏目 The world economy is still in danger世界经济仍处于危险之中 Economic optimism经济乐观主义 Falling inflation is good news. But it is too early to hail a “soft landing” “soft landing” 是指经济增长从高速增长状态逐渐放缓并平稳过渡到一个较为稳定的增长状态，而不会出现过度调整或衰退的情况。这种平稳的过渡可以帮助避免经济的不稳定和负面影响。在金融和经济领域，这通常用于描述一个经济周期的结束。 通货膨胀下降是个好消息。但现在欢呼“软着陆”还为时过早。 image: pete ryanJul 19th 2023 Economists are not known for their optimism, but today their good cheer is palpable. Not long ago it seemed that an American recession was inevitable, as the Federal Reserve kept raising interest rates to fight inflation. Other central banks were following suit, their inflation problems made worse by a surging dollar—a particular problem for the emerging markets that borrow and trade using America’s currency. Yet news that America’s headline rate of annual inflation fell to 3% in June has fed hopes that the Fed’s next rate rise, which is expected on July 26th, will be its last and that other central banks might relax, too. Stocks are up, bond yields are down and the greenback is at close to its weakest since the Fed began raising rates. 经济学家并不以其乐观著称，但今天他们的喜悦显而易见。不久之前，由于美联储持续提高利率以抑制通货膨胀，美国经济衰退似乎是不可避免的。其他中央银行也在效仿，他们的通货膨胀问题由于美元的飙升而变得更加严重——这对于以美元借贷和贸易的新兴市场来说是一个特别大的问题。然而，6月份美国年度通货膨胀率降至3%的消息让人们燃起了这样的希望：美联储下一次加息(预计在7月26日)将是最后一次加息，其他央行可能也会放松政策。股票上涨，债券收益率下降，美元接近自美联储开始加息以来的最低点。 The surge of hope is all the more unusual because the world economy is slowing down. On July 17th China reported that its economy grew by a mere 0.8% in the second quarter compared with the prior three months, even though many had expected a boom after the government abandoned its “zero-covid” policy in December. Global manufacturing has suffered as consumers came out of lockdowns and began eating out more and buying less home-office equipment. And, although America grew strongly in the first half of the year, most forecasters expect the economy soon to slow. 由于全球经济正在放缓，这种希望的高涨显得更加不同寻常。7月17日，中国报告称其相比上一季度，其经济在第二季度仅增长0.8%，然后许多人预计在去年12月疫情“放开”后会出现经济繁荣。随着消费者走出“家门”并开始外出用餐、购买更少的家庭办公设备，全球制造业也受到了影响。虽然美国上半年经济增长强劲，但大多数预测师预计经济很快将放缓。 Increasingly, however, they are not expecting it to shrink. And growth cooling just enough to bring down inflation without a recession is the best-case scenario for overheated economies like America’s. Even the disappointing reopening in China, which does not have an inflation problem of its own, has meant a feared surge in global commodities prices has not materialised. That has helped Europe, which has replaced piped Russian gas with shipments of the liquefied sort. 然而，越来越多的人并不期望经济会收缩。对于像美国这样过热的经济体来说，经济增长降温到足以在不引发衰退的情况下降低通胀是最好的情况。尽管中国在疫情后的经济复苏进展不如人们所期望（中国本身没有通货膨胀问题），但这也意味着原本担心的全球大宗商品价格激增并未出现。这对欧洲有所帮助，欧洲已经用液化天然气取代了从俄罗斯输送的管道天然气。 Yet it would be a mistake to assume that the world economy is now on track for a so-called soft landing, for three reasons. The first is that inflation, though lower, remains far above central banks’ 2% targets. The fall in America’s headline rate has been driven by a one-off decline in energy prices: exclude food and energy, and prices are 4.8% higher than a year ago. In the euro zone the figure is 5.5%, and in both economies wages are still growing far in excess of productivity growth. 然而，如果认为全球经济现在正朝着所谓的软着陆方向发展，那就大错特错了，原因有三。第一个原因是，尽管通货膨胀率下降，但仍然远高于中央银行的2%目标。美国整体通胀率下降是因为能源价格的一次性下降：不包括食品和能源，物价比一年前高出4.8%。在欧元区，这个数字是5.5%，而在这两个经济体中，工资仍然远远高于生产率增长。 In other words, the rich world has some way to go before it is fully disinflated—and many economists expect the last mile to be the hardest. Though stubborn inflation of, say, 3-4% does not grab headlines as much as recent alarming price rises, it would still be a problem for central bankers. They might have to choose between more tightening than is currently expected and tacitly abandoning their 2% goals. Either would be disruptive for asset markets and potentially for the real economy, too. 换句话说，发达国家在完全抑制通货膨胀方面还有很长的路要走，许多经济学家预计“最后一英里”将是最困难的。尽管顽固的通货膨胀率（例如3-4%）并没有像最近引起人们警惕的物价上涨那样引起轰动，但它仍然是中央银行家们需要解决的问题。他们可能不得不在更紧缩的政策和默认放弃2%目标之间做出选择。任何一种选择都可能对资产市场产生破坏性影响，并可能对实体经济造成影响。 The second risk is that, whereas the world is seeing the benefits of cooling off now, the costs may not be visible for a while. So far America’s labour market has rebalanced fairly painlessly by reducing vacancies rather than jobs. Hiring is still strong and lay-offs are rare. With job openings less plentiful, wage growth has fallen. Yet nobody knows for how long the jobs market can shed fat rather than muscle—and in recent months the fall in job openings has stalled ominously. Across the rich world there is evidence that firms, scarred by the memory of labour shortages, have been hoarding workers they don’t need; in several countries average hours worked have been falling. Should companies decide that it is too costly to cling to workers who may or may not be needed in the future, then lay-offs could rise abruptly. 第二个风险是，虽然现在世界正在看到经济降温的好处，但代价可能需要一段时间才能显现。到目前为止，美国的劳动力市场通过减少“不必要的”招聘而不是裁员来实现相对轻松的再平衡。招聘仍然强劲，裁员很少。随着招聘减少，工资增长已经放缓。然而，没有人知道就业市场在“减少不必要的岗位而非裁员”上还会持续多久。最近几个月“就业岗位减少”已经停滞不前，这是一个不祥的迹象。在发达国家，有证据表明企业因为受过“劳动力短缺”的苦而囤积了他们不需要的工人；在一些国家，平均工作时长一直在下降。如果企业决定坚持留住未来可能需要也可能不需要的工人成本过高，那么裁员可能会突然增加。 The third danger is that divergence among the world’s big economies means that even as the pressure on the Fed lifts, policymakers elsewhere remain worried. Britain is celebrating a larger-than-expected fall in annual inflation in June, but with underlying price and wage growth of around 7% it remains a troubling outlier (see Britain section). Japan has barely started its monetary tightening; with inflation rising, the Bank of Japan may adjust its cap on long-term bond yields again at the end of July. China could be contending with a structural growth slowdown in which the economy is weighed down by bad debts, as Japan’s was in the early 1990s, and in which inflation is persistently too low. 第三个危险是，世界各大经济体之间的不同意味着，尽管美联储的压力有所减轻，但其他地方的政策制定者仍然感到担忧。英国正在庆祝6月份年度通货膨胀率的下降超出预期，但由于基础价格和工资增长率约为7%，它仍然是一个令人担忧的特例（请参见英国部分）。日本几乎没有开始货币紧缩政策；随着通货膨胀上升，日本央行可能会在7月底再次调整其长期债券收益率上限。中国可能正在应对结构性增长放缓，其经济因坏账而受到拖累（就像日本在20世纪90年代初期一样），同时通货膨胀率持续过低。 Wherever you look, in other words, there remains immense uncertainty about where inflation and interest rates will eventually settle. By all means celebrate good news. But the world economy has not yet escaped unscathed. ■ 换句话说，无论你看哪里，通货膨胀和利率最终会稳定在什么水平仍存在巨大的不确定性。尽管放心去庆祝好消息。不过世界经济仍然会受到一些负面因素的影响。","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Hexo+Github搭建个人技术博客（MAC操作版）","slug":"搭建个人技术博客","date":"2023-07-21T12:53:54.655Z","updated":"2023-07-25T15:22:17.260Z","comments":true,"path":"2023/07/21/搭建个人技术博客/","link":"","permalink":"http://example.com/2023/07/21/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/","excerpt":"第一次尝试搭建个人技术博客，记录踩坑实践 一、MAC本机 【1】打开终端terminal，安装homebrew PS: 如果没有报错，可以直接安装；否则建议卸载重装 卸载命令： 1$ /bin/bash -c &quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/uninstall.sh)&quot; 安装命令： 1$ /bin/bash -c &quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/install.sh)&quot; 如果遇到“homebrew-core”相关的错误，或者运行太慢卡住，直接运行如下代码： 123$ cd /usr/local/Homebrew/Library/Taps/homebrew/$ rm -rf homebrew-core$ git clone https://github.com/Homebrew/homebrew-core.git 测试是否安装成功 1brew -v","text":"第一次尝试搭建个人技术博客，记录踩坑实践 一、MAC本机 【1】打开终端terminal，安装homebrew PS: 如果没有报错，可以直接安装；否则建议卸载重装 卸载命令： 1$ /bin/bash -c &quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/uninstall.sh)&quot; 安装命令： 1$ /bin/bash -c &quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/install.sh)&quot; 如果遇到“homebrew-core”相关的错误，或者运行太慢卡住，直接运行如下代码： 123$ cd /usr/local/Homebrew/Library/Taps/homebrew/$ rm -rf homebrew-core$ git clone https://github.com/Homebrew/homebrew-core.git 测试是否安装成功 1brew -v 【2】安装node.js 安装命令： 1234brew install nodenvnodenv install stablenodenv rehashbrew install node 测试是否安装成功 12node -vnpm -v 配置环境变量 打开终端，输入命令： 1nano ~/.bash_profile 在文件中输入如下命令，按control + O 保存退出 1export PATH=&quot;/usr/local/bin:$PATH&quot; 重启终端。运行以下指令来检查你的环境变量是否设置成功： 1echo $PATH 【3】安装hexo 本地新建一个文件夹（如： &#x2F;Users&#x2F;chenyujie&#x2F;Desktop&#x2F;yujie_blog)，博客相关文件将储存在此文件夹下。 安装hexo 1npm install hexo-cli -g 进入到这个文件夹里面 1cd /Users/chenyujie/Desktop/yujie_blog 新建一个blog文件夹，执行命令初始化hexo配置（此处的blog是你要建立的文件夹名称） 1hexo init blog 进入这个文件夹下面，执行如下命令，开启Hexo本地服务器（本地查看效果）： 12hexo generatehexo server 这时候出现如下字样，即成功，可进入http://0.0.0.0:4000/查看效果： 1INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop. 这时候，本地博客就成功搭建了！如果想要别人能访问到，可以将博客部署到Github Pages上。 二、Github操作 【1】首先你要拥有一个github账号，注册完成后，你将拥有一个你的用户名（如：abc） 【2】新建仓库 仓库名称：**你的用户名.github.io** (如：**abc**.github.io) 【abc需要与用户名保持一致】 选择默认的Public 初始化README文件【打个勾就行】 点击创建即可完成此步骤 【3】配置SSH密钥 在MAC本地操作，回退到yujie_blog目录，然后运行ssh开头的那行命令生成密钥，中间经历两次回车即可 123cd /Users/chenyujie/Desktop/yujie_blogssh-keygen -t rsa -C &quot;your email@example.com&quot; // 引号里面填写你的邮箱地址 完成后会有一个ssh-rsa开头的密钥，结尾是你前面配置的邮箱，全部复制粘贴，如果没有复制上，可以选择执行下面的命令，然后再复制 1cat ~/.ssh/id_rsa.pub 切换到Github，打开自己右上角页面的头像处，点击下拉框中的Settings，再点击 SSH and GPG Keys，选择 New SSH key，粘贴密钥，Title随意填写，Key填写刚才粘贴的内容。 此时可以回退到MAC本地，测试一下如下命令（无需修改，直接复制粘贴测试），之后输入yes， 返回 You’ve succcessfully authenticated..表示设置正确 1ssh -T git@github.com 配置个人信息： 用户名就是前面那哥abc , 邮箱可以看下github注册时自己填的哪个邮箱，尽量保持一致 12git config --global user.name &quot;此处填你的用户名&quot; git config --global user.email &quot;此处填你的邮箱&quot; 此时，SSH Key已经配置成功，本机已成功连接到 Github 【4】打开github设置的仓库 你的用户名.github.io （如：abc.github.io）, 点击Clone or download 按钮，选择 Use SSH，复制 【5】任意打开一个编辑器，打开blog文件夹下的_config.yml文件，拉到最后，按照如下修改 123456# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy: type: &#x27;git&#x27; repository: 刚刚复制的【4】中的ssh地址 branch: main【和github默认分支保持一致】 【6】MAC本地执行，在blog文件夹路径下，执行 123hexo g hexo d// 或者直接执行 hexo g -d 如果此时报错，执行如下命令： 1npm install hexo-deployer-git --save 然后再执行如下命令，博客就会部署到Github上了 1hexo g -d 这时候可以访问 https:&#x2F;&#x2F;你的用户名.github.io（如：https://abc.github.io）如果此时没有显示，建议多刷新几次，或者等待会儿 三、发文章 【1】新建一个文章， 可以在blogs&#x2F;source&#x2F;_posts下手动生成 文章标题.md 文件，也可以直接执行如下命令生成 1hexo n &quot;文章标题&quot; 【2】用编辑器编写文章，我用的Typora 1234567891011121314151617181920---layout: 页面布局（配合主题文档使用）title: 文章名称date: 文章日期comments: 文章是否开启评论photos: 文章封面图（仅部分主题支持）tags: - 文章标签一 - 文章标签二categories: 文章分类description: 文章描述，即要在首页显示的摘要（仅部分主题支持）---这里是摘要&lt;!-- more --&gt;这里是正文注意：description 和 &lt;!-- more --&gt; 方式显示摘要二选一即可，部分主题不支持description，每个配置英文冒号后面要空一格，不同主题配置有所差异，具体要参考主题文档 [&lt;!-- more --&gt;在正文前面配置这个，可以让网页不用展示全文] 【3】如果有图片文件，可以在blogs&#x2F;source文件夹下面新建images文件夹，之后md中的文件路径均为“&#x2F;images&#x2F;你的图片.jpg ‘图片名’” 【4】上传文件 1hexo g -d 四、给个人博客换个你喜欢的主题 【1】点击此处进入 Hexo 官网的主题专栏 【2】目标是把主题克隆过来，首先随便点个你喜欢的主题（如：hexo-theme-hiero），然后找到页面上的 Theme By xxx, 之后点击xxx，页面跳转对应的GitHub地址，然后复制网址 【3】进入到blog文件下的themes目录，执行如下代码，然后相应主题的目录就会在themes文件夹下出现 1git clone 此处填写你刚才复制的网址 【4】打开 blog 文件夹下的配置文件 _config.yml ，找到关键字 theme，修改参数为：theme：你选的主题名（如hexo-theme-hiero） 【5】返回blog目录，执行如下命令即可发现，博客主题已经更换 12hexo g hexo s 【6】执行如下命令，清楚缓存，并部署到GitHub 12hexo clean hexo g -d 这里面可以配置 _config.yml文件，修改title相关的信息，与主题相关的配置文件blogs&#x2F;_config.yml 五、为博客添加搜索功能 local_search: 【1】在blog文件夹下执行如下命令 1npm install hexo-generator-json-content --save 【2】仍需修改主题的_config.yml文件 （不过我的主题下默认开启了，不是如下内容） 123# 本地搜索local_search: enable: true 我配置的主题显示如下： 1234search: insight: true # you need to install `hexo-generator-json-content` before using Insight Search swiftype: # enter swiftype install key here baidu: false # you need to disable other search engines to use Baidu search, options: true, false Algolia 搜索: 【1】获取 Algolia 账号 注册 Algolia，进入官网地址 注册，也可以直接用Github授权登录。 【2】新建 Index（Create index） 【3】安装hexo-algoliasearch插件（推荐） 1npm install hexo-algoliasearch --save 【4】打开Algolia网站，点击Settings，点击Team and Access下面的API Keys。然后，在最外层文件夹下（如yujie_blog），修改配置文件_config.yml 123456789101112131415algolia: appId: &quot;your applicationID&quot; apiKey: &quot;your Search-Only API Key&quot; adminApiKey: &quot;your Admin API Key&quot; chunkSize: 5000 indexName: &quot;your indexName&quot; fields: - content:strip:truncate,0,500 - excerpt:strip - gallery - permalink - photos - slug - tags - title 其中【applicationID】填入 Applicaiton ID，【apiKey】填入Search-Only API Key ，【Admin API Key】填入 Admin API Key ，【indexName】填入前面创建的索引名称。 【5】执行如下命令 1hexo algolia 可以去 Algolia 网站上查看，索引已经上传成功了。 【6】在主题配置文件_config.yml中修改以下内容： 12345678algolia_search: enable: true hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: &quot;我们没有找到任何搜索结果: $&#123;query&#125;&quot; hits_stats: &quot;找到$&#123;hits&#125;条结果（用时$&#123;time&#125; ms）&quot; 【7】重新编译运行，即可看到效果 12hexo cl &amp;&amp; hexo generatehexo s 六、博客的统计功能 如果不蒜子不生效，则修改‎layout&#x2F;_partial&#x2F;busuanzi-analytics.ejs文件下的不蒜子域名【官网地址】","categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"tags":[{"name":"开发","slug":"开发","permalink":"http://example.com/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"Day1020-The Economist","slug":"Day1020-The Economist","date":"2023-07-15T02:34:32.647Z","updated":"2023-07-25T14:49:05.513Z","comments":true,"path":"2023/07/15/Day1020-The Economist/","link":"","permalink":"http://example.com/2023/07/15/Day1020-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 22th 2023 期 Leaders 栏目 Making babymaking betterFertility technology IVF is failing most women. But new research holds out hope for the future试管受精让大多数女性失望。但新的研究为未来带来了希望 Jul 20th 2023","text":"文章来源：《经济学人》Jul 22th 2023 期 Leaders 栏目 Making babymaking betterFertility technology IVF is failing most women. But new research holds out hope for the future试管受精让大多数女性失望。但新的研究为未来带来了希望 Jul 20th 2023 After louise brown was born in Manchester in July 1978, her parents’ neighbours were surprised to see that the world’s first “test-tube baby” was “normal”: two eyes, ten fingers, ten toes. In the 45 years since, in vitro fertilisation has become the main treatment for infertility around the world. At least 12m people have been conceived in glassware. An ivf baby takes its first gulp of air roughly every 45 seconds. ivf babies are just as healthy and unremarkable as any others. Yet to their parents, most of whom struggle with infertility for months or years, they are nothing short of miraculous. 1978年7月，路易丝·布朗在曼彻斯特出生，她的父母邻居们惊讶地发现，世界上第一个“试管婴儿”是“正常的”：两只眼睛，十个手指，十个脚趾。在此之后的45年中，体外受精已成为全球不孕不育的主要治疗方法，至少有1200万人在试管中受孕。大约每45秒就有一个试管婴儿“降生”了。试管婴儿和其他婴儿一样健康和普通。然而对于他们的父母（大多数都经历了数月甚至数年的不孕不育之苦）来说，他们简直就是奇迹。 In a world where one person in six suffers from infertility, such successes are rightly celebrated. Less discussed are the problems of ivf. Most courses of treatment fail. That subjects women and couples to cycles of dreaming and dejection—and gives the fertility industry an incentive to sell false hope. The obstacle is a lack of progress in understanding the basic mechanisms that determine fertility. At last, however, the science is making headway, holding out more promise and less heartache for generations of parents to come. 在一个六分之一人口患有不孕症的世界里，这样的成功值得庆祝。但很少有人讨论试管婴儿技术的问题。大多数治疗都失败了，这让女性和夫妇们经历了一次又一次的希望和失望的循环，这也让生育产业有了销售虚假希望的动力。障碍在于对决定生育能力的基本机制缺乏了解。然而，科学正在取得进展，这为未来几代父母提供更多的希望和更少的心理痛苦。 Over the years ivf has become better at making babies and safer for the women who bear the brunt of the treatment. The rate of twin and triplet deliveries has plummeted, reducing the number of risky pregnancies. Hormone treatments are safer. Combined with egg and sperm freezing, donation and surrogacy, ivf has given many, including same-sex couples and singletons, a path to parenthood where they had none. 1【1】to bear or take the brunt of 在…中首当其冲 ‹disaster, unemployment› 多年来，试管婴儿技术在孕育婴儿方面变得更加出色，对于承受治疗压力的女性来说也更加安全。双胞胎和三胞胎分娩的比例已经大幅下降，这减少了高风险妊娠的情况。激素治疗也更加安全。结合卵子和精子冷冻、捐赠和代孕（中国目前是禁止的），试管婴儿技术为包括同性恋伴侣和单身人士在内的本来无法成为父母的许多人提供了一条成为父母的道路。 Yet the process remains gruelling and costly. It is physically painful for women, and emotionally draining for both sexes. For many, fertility treatment is an unaffordable luxury; in America, for instance, a cycle can cost $20,000. Some countries ration treatment according to a conservative moral code. Until 2021 French law permitted ivf only for married heterosexual couples. Many countries including China forbid egg freezing, which extends reproductive years. 然而，试管婴儿技术的过程仍然是艰苦且昂贵的。对于女性来说，这是一种身体上的痛苦，对于男女双方来说都是一种情感上的消耗。对于许多人来说，不孕不育治疗是一种无法承受的“奢侈品”；例如在美国，一次疗程的费用可能高达20,000美元。一些国家根据保守的道德准则来限制治疗。直到2021年，法国法律仅允许异性婚姻夫妇进行试管婴儿技术。包括中国在内的许多国家禁止冻卵，这会延长生育年龄。 All too often, the pain and the cost come to nothing. The 770,000 ivf babies born in 2018 required some 3m cycles. Many women go through round after round of hormone injections, sometimes moving from one clinic to the next. In America and Britain roughly half go home with a baby in their arms, even after several years and as many as eight cycles of treatment. 然而，大多时候，这些痛苦和费用都付诸东流。2018年诞生的77万试管婴儿需要进行约300万个疗程。许多女性需要经历一轮又一轮的激素注射，有时还需要在不同的诊所之间转移。在美国和英国，即使经过数年和多达八个疗程的治疗，大约一半的人最终仍然无法如愿以偿。 This has fostered a fertility industry selling to repeat customers desperate to conceive. When a cycle fails, many clinics offer poorly regulated menus of “add-ons” that do not demonstrably****raise the chances of success, and may even reduce them. They can charge hundreds to thousands of dollars for a treatment. 这种情况催生了“生育产业”，它们向那些渴望怀孕的“回头客”销售产品。当一次治疗失败时，许多诊所会提供一些“附加服务”，这些服务的效果并没有得到充分的监管，也不能证明可以提高成功率，甚至还可能会降低成功率。他们可以为这种治疗收取数百到数千美元的费用。 These problems all share a fundamental cause. Although reproduction is one of the most basic aspects of human biology, scientists have an astonishingly poor grasp of how a new life comes about. The essentials are obvious: a sperm and an egg must meet. But many of the cellular, molecular and genetic underpinnings of babymaking remain a mystery. 所有这些问题都有一个根本原因。尽管“繁殖”是人类生物学中最基本的方面之一，但科学家们对新生命的形成方式的了解仍然非常有限。基本的原理显而易见：精子和卵子必须相遇。但是，关于制造婴儿的许多细胞、分子和遗传学基础仍然是一个谜。 Little is known about how a woman’s stock of eggs is set before she is even born; or why they fade in number and quality until menopause, which among mammals is known to occur only in humans and five species of whale. The intricacies of how an embryo buries into the womb and connects to the blood supply are also mysterious. Infertility is often classed as “women’s health”, yet male factors play at least some role in roughly half of heterosexual infertile couples—though how is often unclear. 1【1】menopause 绝经；更年期 人们对女性在出生前如何形成卵子储备以及为什么卵子数量和质量会随着时间的推移而逐渐减少，直至绝经期，知之甚少。在哺乳动物中，绝经期仅出现在人类和五种鲸类中。胚胎如何进入子宫并连接到血液供应的复杂性也是一个谜。不孕不育通常被归类为“女性健康问题”，然而，在大约一半的异性不育夫妇中，男性因素至少起到了一定的作用ーー尽管通常不清楚这种作用是如何产生的。 In the face of all this, ivf is woefully inadequate. It was devised as a fix for the blocked Fallopian tubes that prevented Ms Brown’s mother from conceiving. But today, when more couples try for children later in life, a woman’s declining stock of eggs is increasingly likely to be the problem. Here, ivf works by giving people more rolls of the dice, by collecting more eggs and maximising the odds that they will be fertilised. That will work for the lucky few, but without an entirely new approach and new treatments, many aspiring parents will endure one disappointment after another. 面对所有这些问题，试管婴儿技术显得非常不足。它的设计初衷是为了解决布朗女士母亲因输卵管堵塞而无法受孕的问题。但今天，当越来越多的夫妇晚年尝试生育时，女性逐渐减少的卵子储备可能是导致不孕的问题。在这种情况下，试管婴儿技术通过收集更多的卵子并最大限度地增加其受精的可能性来增加人们的成功率。这对于幸运的少数人可能有效，但如果没有全新的方法和治疗，许多有生育愿望的父母将经历一次又一次的失望。 As our Technology Quarterly reports, recent scientific work offers some hope. Researchers in Japan and America are exploiting stem cells, which have the ability to become any of the body’s many specialised tissues, to make eggs from skin and blood cells, a process called in vitro gametogenesis (ivg). In Japan healthy mouse pups have been created from cells that originated on the tips of their mothers’ tails. Earlier this year researchers announced that they had delivered mouse pups that shared two genetic fathers. One had contributed sperm, the other skin, which was first turned into stem cells and then into eggs. 正如我们的Technology Quarterly中所报道的，最近的科学研究给我们带来了一些希望。日本和美国的研究人员正在利用干细胞，这些细胞具有成为身体许多特殊组织的能力，从皮肤和血液细胞中制造卵子，这个过程被称为体外配子生成（ivg）。在日本，已经可以通过从母亲尾巴顶端的细胞中产生健康的小鼠幼仔。今年早些时候，研究人员宣布，他们已经产下了拥有两个遗传父亲的小鼠幼崽，其中一个提供了精子，另一个则提供皮肤细胞，皮肤细胞经过转化成干细胞后再变成卵子。 Some teams are working towards applying these techniques to humans. If cells safe enough to make healthy babies will ever be available, they are still far off. But the research is providing new insights into how sperm and eggs are made. ivg means that researchers may no longer need to rely for their studies on donated eggs, sperm and embryos, often generously provided by ivf patients. Other teams are using stem cells to build embryo models (dubbed “embryoids”). These will never see the inside of a womb but they can help show what happens to the real embryos that do. 一些团队正在努力将这些技术应用于人类。要制造出足够安全的细胞以产生健康的婴儿，仍然有很长的路要走。但这项研究为我们提供了新的认识，帮助我们了解精子和卵子的生成过程。体外配子技术意味着研究人员可能不再需要依赖于捐赠的卵子、精子和胚胎来进行研究，这些通常由试管婴儿患者慷慨提供。其他团队正在使用干细胞构建胚胎模型（被称为“类胚胎”）。这些模型永远不会进入子宫，但它们可以帮助我们展示真实胚胎的发育过程。 In time, novel treatments may follow. Gay couples could have children that are as genetically related to them as those of straight ones. Trans people who are undergoing gender reassignment could possibly do so without sacrificing their fertility. 随着时间的推移，可能会出现新的治疗方法。同性恋夫妇可以拥有与异性恋夫妇一样“有血缘关系”的孩子。正在进行变性手术的跨性别者可能不必牺牲他们的生育能力就能完成手术。 All this will take time—which is why ivf will remain important, and why it needs investment and regulation. A better understanding of fertility should help raise the success rate of ivf, bringing down its emotional and financial costs. 所有这些都需要时间，这就是为什么试管婴儿技术仍然很重要，需要投资和监管。更好地了解生育能力应该有助于提高试管婴儿技术的成功率，降低其情感消耗和金钱成本。 New treatments could eventually herald the biggest transformation in fertility technologysince Ms Brown was born. Polling shows that in many countries people have fewer children than they would like, partly because they are putting off babymaking until later. Where the sexual revolution of the 1960s and ’70s gave women the choice not to have babies if they did not wish to, emerging technology could usher in a new revolution, empowering women—and men—to have the babies they want, when they want them. ■ “性革命”（sexual revolution）通常指的是20世纪60年代和70年代期间，西方社会在性观念、性行为和性文化方面的变革。这一时期，人们开始更加开放地讨论性，接受了一些以前被认为是不道德或不合适的性行为方式，如同性恋、婚前性行为和避孕等。这一时期的变革对于当时的社会产生了深远的影响，其中一部分影响仍然存在至今。 新的治疗方法最终可能会宣告着自布朗女士出生以来生育技术最大的转变。调查显示，在许多国家，人们生育的孩子比他们想要的要少，部分原因是他们推迟了生育。20世纪60年代和70年代的性革命给了女性选择不生孩子的权利，如果她们不想要孩子的话。新兴技术可能会引领一场新的革命，赋予女性和男性在想要孩子时拥有他们的权利。","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1019-The Economist","slug":"Day1019-The Economist","date":"2023-07-15T02:34:28.298Z","updated":"2023-07-25T14:48:59.858Z","comments":true,"path":"2023/07/15/Day1019-The Economist/","link":"","permalink":"http://example.com/2023/07/15/Day1019-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 15th 2023 期 Leaders 栏目 Big pharma is warming to the potential of AI大型制药公司开始关注人工智能的潜力 Wonder drugs特效药 But some worry the Terminator is coming但是有些人担心终结者就要来了 Jul 13th 202 image: Bryan Anselm&#x2F;Redux&#x2F;Eyevine","text":"文章来源：《经济学人》Jul 15th 2023 期 Leaders 栏目 Big pharma is warming to the potential of AI大型制药公司开始关注人工智能的潜力 Wonder drugs特效药 But some worry the Terminator is coming但是有些人担心终结者就要来了 Jul 13th 202 image: Bryan Anselm&#x2F;Redux&#x2F;Eyevine PAUL HUDSON, boss of Sanofi, is brandishing an iPhone. He is keen to show off the French drugmaker’s new artificial-intelligence (AI) app, plai. It draws on more than 1bn data points to provide “snackable” information, from warnings about low stocks of a drug to questions for a meeting with an ad agency or suggestions to set up clinical-trial sites that could expedite drug approvals. Like Netflix recommendations, plai delivers “nudges”, as Mr Hudson calls them, that are useful at that moment in time. He jokes that plai broke even in about four hours, and says the cost is “peanuts” compared with the $300m-400m that big consultancies charge for a project to curate a big company’s data. One in ten of Sanofi’s 80,000 staff uses it every day. 保罗·哈德森是法国制药公司赛诺菲的老板，他正在挥舞着一部iPhone。他热衷于展示赛诺菲的新人工智能应用程序plai。它利用超过10亿数据点提供“简洁易懂”的信息，从药物库存不足的警告，到与广告公司会面的问题，再到建立可能加快药物审批的临床试验点的建议。像Netflix的推荐一样，plai能够提供哈德森先生所谓的“助推”，这些“助推”在当时非常有用。他开玩笑说，plai在大约四个小时内就实现了盈亏平衡，并表示与大型咨询公司为一家大公司策划数据项目所收取的3亿到4亿美元相比，这个成本微不足道。赛诺菲的8万名员工中，每天有十分之一的人使用它。 AI is not new in drugmaking. Biotech firms have been tinkering with it for years. Now interest from big pharma is growing. Last year Emma Walmsley, chief executive of GSK, said it could improve the productivity of research and development, the industry’s most profound challenge. Moderna recently described itself as “laser-focused” on AI. Sanofi is “all in”. Morgan Stanley, an investment bank, reckons that within a decade the pharmaceutical industry may be spending $50bn a year on AI to speed up drug development. 人工智能在制药领域并不新鲜。生物技术公司多年来一直在尝试使用它。现在，大型制药公司对此的兴趣正在增长。去年，葛兰素史克公司首席执行官艾玛·沃姆斯利表示，它可以提高研发的生产率，这是该行业最严峻的挑战。莫德纳最近称自己“专注于”人工智能。赛诺菲公司则是“全力以赴”。投资银行摩根士丹利估计，在未来十年内，制药行业可能每年会花费500亿美元用于加快药物研发的人工智能应用。 Most of the buzz revolves around AIs trained on biological data that could improve the hit-and-miss process of drug discovery. Drugs can take a decade to emerge, cost billions of dollars and succeed only 10% of the time. Even a small improvement in speed and efficiency would be hugely valuable. But scientists have struggled to tame biological big data with conventional statistical tools. Machine learning makes it possible to sift through piles of information, from clinical patient data and genome sequences to images of body scans. Last year DeepMind, an AI lab that is part of Google, made a breakthrough using its AlphaFold system to predict the structure of almost all proteins, which may one day help identify which molecules have therapeutic potential. 大部分关于人工智能的热议都围绕着基于生物数据的AI，这些AI可以改善药物发现的试错过程。药物的研发可能需要十年时间，耗费数十亿美元，并且只有10%的成功率。即使是速度和效率的微小提高也将具有巨大的价值。但是科学家们一直在努力用传统的统计工具来处理生物大数据。机器学习能够筛选包括临床患者数据、基因组序列和身体扫描图像等大量信息。去年，Google旗下的人工智能实验室DeepMind利用其AlphaFold系统预测了几乎所有蛋白质的结构，这可能有助于识别哪些分子具有治疗潜力。 Though only around a dozen drugs in development have so far involved the use of AI, the list may grow rapidly—especially for simple molecules with properties that are relatively easy to predict. In the case of these more straightforward chemistries, the future of medicine is looking ever more like a computational problem. 尽管目前涉及到使用人工智能的正在开发的药物仅有大约十几种，但这个列表可能会迅速增长 - 特别是对于那些具有相对容易预测性质的简单分子。对于这些更为直接的化学物质，医学的未来看起来越来越像是一个计算问题。 Jim Weatherall, who oversees data science and AI at AstraZeneca, says the technology is used in 70% of the British firm’s small molecules in development. Using a technique called “reinforcement learning”, AstraZeneca’s AI is constantly tweaking its molecular suggestions and playing out how a tweaked molecule might react. Ali Mortazavi, boss of E-therapeutics, a biotech startup in London, says that knowing the sequences of all the genes in, say, the liver, lets his firm use software to design RNA molecules (which are more complex but, owing to their links to DNA, predictably so). AI algorithms then predict the activity of the molecules, which can stop the function of any disease-causing gene. 1RNA分子可以与特定的基因序列结合并阻止其功能，从而治疗某些疾病。这种方法被称为RNA干扰 (RNA interference)，它可以通过基因沉默的方式来抑制某些基因的表达。这种技术在药物研发领域中被广泛应用，以治疗多种疾病，包括癌症、心血管疾病等。 英国公司AstraZeneca的数据科学和人工智能负责人吉姆·韦瑟尔表示，其公司正在开发的70%的小分子都利用了该技术。通过使用一种“强化学习”的技术，AstraZeneca的人工智能不断调整其分子建议，并模拟调整后的分子可能会如何反应。伦敦生物技术初创公司E-therapeutics的负责人阿里·莫塔扎维表示，了解肝脏等器官中所有基因的序列，让他的公司可以使用软件设计RNA分子（它们更加复杂，但由于与DNA存在联系【DNA转录形成RNA】，因此可预测）。然后，AI算法就预测这些分子的活性，这可以阻止任何导致疾病的基因的功能。 Euan Ashley of Stanford University points to another AI application. “Knowledge graphs” are a kind of database that stores data about genes, proteins, diseases and drugs, as well as the biological pathways that connect them. They, too, can help identify new targets for drug development. “Generative” AI, meanwhile, is being trialled for suggesting entirely new chemical and biological structures for testing, just as ChatGPT can ingest text on the internet and spit out a new poem or essay. Beyond drug discovery, AIs like plai could help with the perennial problem of efficiency in a heavily regulated and labour-intensive sector. 1&quot;biological pathways&quot; 代谢通路，是生物体内一系列化学反应的链式过程，这些反应共同完成特定的生理功能。生物学通路可以涉及多种生物分子，如蛋白质、核酸、糖等，这些分子之间通过化学反应相互作用，形成复杂的代谢网络。生物学通路对于维持生命活动至关重要，它们参与调节细胞生长、分化、代谢和信号传导等多种生理过程。在药物研发中，了解生物学通路的作用机制可以帮助科学家们发现新的药物靶点，并设计出更有效的治疗方案。 斯坦福大学的尤安·阿什利指出了另一种人工智能应用。”知识图谱”是一种数据库，它存储有关基因、蛋白质、疾病和药物的数据，以及连接它们的代谢通路。它们也可以帮助识别药物研发的新靶点。同时，”生成式”人工智能正在进行试验，以提出全新的化学和生物结构来进行测试，就像ChatGPT可以获取互联网上的文本并输出新的诗歌或文章一样。除了药物研发之外，像plai这样的人工智能也可以帮助解决监管严格、劳动密集型行业中的效率问题。 Some pharma bosses worry that generative AIs’ tendency to make stuff up could send researchers down blind alleys. More apocalyptically, Mr Hudson says half of the pharma CEOs he talks to about AI fear, like many people, the existential threats it poses. For his part, he foresees the next industrial revolution, not a robot uprising. ■ 一些制药公司的老板担心，生成式人工智能的“编造”特性可能会使研究人员走上错误的道路。哈德森先生表示，更令人担忧的是，他与一半的制药公司CEO讨论人工智能时，他们担心它可能会带来“存在威胁”，就像许多人担心的一样。但他本人预见到的是下一个工业革命，而不是机器人起义。■","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1018-The Economist","slug":"Day1018-The Economist","date":"2023-07-15T02:34:24.675Z","updated":"2023-07-25T14:48:48.564Z","comments":true,"path":"2023/07/15/Day1018-The Economist/","link":"","permalink":"http://example.com/2023/07/15/Day1018-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 15th 2023 期 Leaders 栏目 How MAGA Republicans plan to make Donald Trump’s second term countMAGA共和党人计划让唐纳德·特朗普的第二个任期有所成就 Preparing for government They think they know how to banish the chaos and frustrations of his first four years1“MAGA Republicans” 指的是“Make America Great Again”（让美国再次伟大）共和党人，通常用来形容支持前总统唐纳德·特朗普的共和党人。 他们认为自己知道如何消除他的第一任期中的混乱和挫败感 image: federico yankelevich Jul 13th 2023","text":"文章来源：《经济学人》Jul 15th 2023 期 Leaders 栏目 How MAGA Republicans plan to make Donald Trump’s second term countMAGA共和党人计划让唐纳德·特朗普的第二个任期有所成就 Preparing for government They think they know how to banish the chaos and frustrations of his first four years1“MAGA Republicans” 指的是“Make America Great Again”（让美国再次伟大）共和党人，通常用来形容支持前总统唐纳德·特朗普的共和党人。 他们认为自己知道如何消除他的第一任期中的混乱和挫败感 image: federico yankelevich Jul 13th 2023 The overwhelming memory of Donald Trump’s time in office is of chaos and resentment. It was summed up by the shameful end to his presidency, when his whipped-up supporters sacked the Capitol in a bid to keep him in power. Mr Trump has since lurched from an ignominious post-electoral impeachment to two criminal indictments, with perhaps more in the offing. The former president seems obsessed with relitigating his election loss in 2020: “I am your justice,” he thundered to a crowd of supporters this year. “I am your retribution.” 唐纳德·特朗普执政时期最令人难忘的记忆是混乱和怨恨。他任期结束时可耻的表现体现了这一点，当时他为了让自己继续掌权，去煽动支持者攻占国会大厦。从那以后，特朗普先生经历了一次可耻的选举后弹劾以及两项刑事起诉，可能还有更多的起诉在即。这位前总统似乎痴迷于于重新审议他在2020年的选举失败：“我会为你们伸张正义，”他今年向一群支持者咆哮道。“我会为你们寻求报复和惩罚。” Mr Trump is likely to win the Republican presidential nomination for 2024. You might think victory in the general election would foreshadow even more chaos—this time without the grown-ups who, it turns out, at first reined in their impulsive new boss. In fact, a professional corps of America First populists are dedicating themselves to ensuring that Trump Two will be disciplined and focused on getting things done. They are preparing the way and you should not dismiss their efforts. 特朗普先生很可能会赢得2024年共和党总统候选人提名。你可能认为，如果他在大选中获胜，这会预示着更多的混乱，这一次没有成熟的人一开始就控制他那冲动的新老板。实际上，一支由“美国优先”民粹主义者组成的专业队伍正在致力于确保“特朗普第二任期”将会是有纪律性的，并专注于把事情做好。他们正在为此做准备，你不应该忽视他们的努力。 In contrast to the slapdash insurgency that captured the White House in 2016, the veterans of Mr Trump’s first term have been years at work, as our Briefing this week lays out. Even at this early stage, the details are something to behold. Thousand-page policy documents set out ideas that were once outlandish in Republican circles but have now become orthodox: finishing the border wall, raising tariffs on allies and competitors alike, making unfunded tax cuts permanent and ending automatic citizenship for anyone born in the United States. They evince scepticism for nato and pledge to “end the war on fossil fuels”, by nixing policies designed to limit climate change. 123【1】slapdash 草率的“unfunded tax cuts” 指的是减税措施没有相应的财政支出来抵消税收减少所带来的财政损失。 与2016年占领白宫的匆忙起义形成鲜明对比的是，特朗普先生第一任期的老将们已经工作了多年，正如本周的Briefing中所述的那样。即使在这个早期阶段，这些细节也值得关注。成千上万页的政策文件列出了曾经在共和党圈子里不可思议的想法，但这些想法现在已经成为正统：完成边境墙、提高盟友和竞争对手的关税、使未经资助的减税措施永久化，并取消在美国出生的任何人自动获得公民身份的政策。他们对北约持怀疑态度，并承诺通过废除旨在限制气候变化的政策，“结束对化石燃料的战争”。 Alongside these proposals is something that aims to revolutionise the structure of government itself. maga Republicans believe that they will be able to enact their programme only if they first defang the deep state by making tens of thousands of top civil servants sackable. Around 50,000 officials would be newly subject to being fired at will, under a proposed scheme known as Schedule f. 除了这些提议之外，还有一些旨在彻底改变政府结构的东西。支持“让美国再次伟大”的共和党人相信，他们只有先通过解雇数万名高级公务员来削弱“阻碍”势力，才能实施自己的计划。根据一项“Schedule F” 方案，大约有50,000名官员可以被随意解雇。 At the same time, to fill the thousands of political appointments at the top of the American civil service, the America Firsters are creating a “conservative LinkedIn” of candidates whose personal loyalty to Mr Trump is beyond question. Merely expressing qualms about the storming of the Capitol on January 6th 2021 is grounds for disqualification. None of this is a shadowy conspiracy: it is being planned in the open. 与此同时，为了填补美国公务员系统高层的成千上万个政治任命职位，美国优先派正在创建一个“保守派 LinkedIn”平台，该平台上的候选人对特朗普先生的个人忠诚是毋庸置疑的。仅仅对2021年1月6日国会大厦冲击事件表示疑虑就足以被取消资格。这一切都不是一个阴谋：它是在公开计划中进行的。 America Firsters will argue that civil-service reform promises to enhance democracy by preventing the unelected bureaucracy from stymying the programme of an elected president. Although checks and balances are an important part of America’s constitutional design, the civil service is not one of the three branches of government it enshrines. 美国优先派将会辩称，公务员制度改革承诺通过“防止未经选举的官僚机构阻碍当选总统的计划”来增强民主。虽然权力制衡是美国宪法设计的重要组成部分，但公务员系统并不是其中规定的三个政府分支之一。 That argument does not wash. One objection is practical. The draining of brains from government would come just as the expansion of the American state across the economy makes a competent bureaucracy more important than ever. Running a modern nation state requires expertise in administration, economics, foreign affairs and science. If officials cannot challenge political appointees’ madder proposals for fear of being fired, policy will rot from the inside. 这种论点并不可行。一个反对意见是实际性。在美国政府扩张经济的同时，政府内部人才的流失将使得一支胜任的官僚队伍变得比以往任何时候都更为重要。管理现代国家需要在政治、经济、外交和科学方面具备专业知识。如果官员们因为害怕被解雇而不敢挑战政治任命者的疯狂提议，政策就会从内部腐败。 A second objection is political. A future Democratic president endowed with imperial powers and unchecked by reality is not something Republicans should wish for. One reason for the professionalisation of the bureaucracy in the 19th century was to provide the ship of state with enough ballast to keep sailing from one administration to the next. 123强调了政府内部专业化和稳定性的重要性，以确保政府能够在不同政治派别之间保持连续性和稳定性，而不会受到政治任命和权力滥用的干扰。航海中的实践 -&gt; 船只需要足够的压舱石或者重物来保持平衡和稳定 第二个反对意见是政治性。共和党人不应该希望未来的民主党总统拥有帝国主义权力并且不受现实的制约。19世纪官僚机构专业化的一个原因是为了为国家的稳定性提供足够的支持和保障，以便从一届政府顺利过渡到下一届政府。 A third objection is that these changes would give an overmighty president direct control of the Department of Justice. By being able to sack all of its purported dissenters, the administration would obliterate the norm of legal independence. If so, Trumpian resentment would be channelled into concrete vengeance. That prospect should concern all Americans. 第三个反对意见是这些变化将使得总统过于强大，能够直接控制司法部。通过能够解雇所有所谓的异见人士，政府将抹杀法律独立的规范。如果这样做，特朗普的怨恨将转化为具体的报复行动。这种前景应该关系到所有美国人。 Having encountered resistance from his previous attorneys-general, the prime criterion for Mr Trump’s next one would be a suppleness of spine: a willingness to quash investigations into the president and his allies and to authorise them against his long list of real and perceived political enemies. Although Mr Trump would have little practical reason to continue to foment distrust in the electoral system—since the constitution precludes a third term—the need to be vindicated about his supposedly stolen election in 2020 may lead him to do so, all the same. 由于之前的几位总检察长对他的要求表示了反对，特朗普先生下一位总检察长的首要标准是“愿意妥协”：愿意压制针对总统及其盟友的调查，并授权对他那长长的真实和虚构的政治敌人进行调查。尽管特朗普没有什么实际的理由继续煽动对选举制度的不信任——因为宪法禁止第三次连任——但他对自己在2020年被偷走的选举结果的平反需求可能会促使他这么做。 If the Republicans win both houses of Congress, as is possible, nobody in the executive or the legislature will be in a position to stop Mr Trump. After all, most of those in charge will already have publicly attested to the legitimacy of storming the Capitol. The federal courts will become one of the few remaining redoubts of independence and expertise in the American system. It is hard to see how they will not also come under sustained attack. 如果共和党在国会两院都获胜，这是有可能的，那么行政和立法部门中没有人能够阻止特朗普先生。毕竟，大多数负责人已经公开证实了冲击国会大厦的合法性。联邦法院将成为美国体系中仅存的独立和专业性的要塞之一。很难想象他们不会受到持续的攻击。 If these carefully laid plans were enacted, America would follow Hungary and Poland down the path of illiberal democracy. True, America has more guardrails against backsliding—including centuries of democratic history and a more raucous and more decentralised media. However, these guardrails are weaker than in the past. Moreover, many Americans would be left worse off by these plans. Trust in institutions and the rule of the law would suffer, leaving the country yet more divided. 如果这些精心制定的计划得以实施，美国将走上匈牙利和波兰走过的非自由民主之路。当然，美国有更多的防范机制来防止倒退，包括数个世纪的民主历史和更为喧闹和更为分散的媒体。然而，这些防护机制比以往更脆弱。此外，许多美国人将因这些计划而处境更加困难。信任机构和法治将受到损害，从而使美国更加分裂。 Donaldus imperatorSome people will try to take comfort from the idea that Mr Trump will not win the primary, or that he will lose the general election. Perhaps his nominees will not be confirmed, or the emperor of entropy will sabotage his own supporters’ designs. That is unforgivably complacent. 有些人会试图从这种想法中得到安慰，即特朗普先生不会赢得初选，或者他将在大选中失利。也许他的提名不会得到确认，或者“特朗普”会破坏他支持者的计划。这种自满态度是不可原谅的【这是对那些低估特朗普先生的力量和影响力的人的批评和警告，这种态度是危险的，可能会导致特朗普先生的成功】。 Mr Trump is favourite to win the nomination in a country where general elections are determined by a few tens of thousands of votes. In victory, a team of practised demolition experts would prime their explosive ideas. The deconstruction of the administrative state could begin. The vain and tyrannical whims of an emperor-president would emerge from the rubble. ■ 在一个大选由几万张选票决定的国家，特朗普有望赢得提名。如果他获胜，一支经验丰富的拆除专家团队将会推行他们具有破坏性的思想。行政国家的解构将会开始。一个自负和专制的皇帝总统的异想天开将从废墟中崛起。","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1017-The Economist","slug":"Day1017-The Economist","date":"2023-07-03T01:45:06.394Z","updated":"2023-07-25T14:48:42.908Z","comments":true,"path":"2023/07/03/Day1017-The Economist/","link":"","permalink":"http://example.com/2023/07/03/Day1017-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 15th 2023 期 Business 栏目 Is big business really getting too big?大企业真的会越变越大吗？ Size wars规模战 In a few sectors, corporate concentration is a problem. In most, it needn’t be 在一些行业，企业“高集中度”是个问题。但在大多数行业中，情况并非如此 image: vincent kilbride","text":"文章来源：《经济学人》Jul 15th 2023 期 Business 栏目 Is big business really getting too big?大企业真的会越变越大吗？ Size wars规模战 In a few sectors, corporate concentration is a problem. In most, it needn’t be 在一些行业，企业“高集中度”是个问题。但在大多数行业中，情况并非如此 image: vincent kilbride Governments are at war with big business. In June Joe Biden, America’s president, spoke for many politicians the world over when he blamed it for greed-fuelled price rises, sluggish wage growth, forgone innovation and fragile supply chains. His trustbusters at the Federal Trade Commission (ftc) have been going after large deals merely because they are large—or at least that is how it feels. Courtroom defeats do not dampen the agency’s zeal. The latest came on July 11th, when a judge rejected its request to block Microsoft’s $69bn acquisition of Activision Blizzard, a developer of video games. The ftc is expected to appeal against the ruling. The eu’s competition authorities are making noises about breaking up Google. Last year Britain’s Competition and Markets Authority (cma) derailed the $40bn acquisition by Nvidia, a semiconductor giant, of Arm, a chip-designer. 1【1】making noises about sth 放出有关某事的风声 政府正与大企业“交战”。今年6月，美国总统乔•拜登代表世界各地的许多政客发声，他将贪婪导致的物价上涨、工资增长缓慢、放弃创新以及脆弱的供应链归咎于大企业。他在联邦贸易委员会的反垄断调查官员一直在追查大型交易，仅仅是因为它们规模大——至少他们感觉是这样的。法庭上的失败并没有削弱该机构的热情。最近的一次“失败”是在7月11日，法官驳回了阻止微软以690亿美元收购视频游戏开发商动视暴雪的请求。预计联邦贸易委员会将对这一裁决提起上诉。欧盟竞争主管部门正闹着要分拆谷歌。去年，英国竞争与市场管理局(cma)阻止了半导体巨头英伟达以400亿美元收购芯片设计公司Arm的交易。 Trustbusters invoke three justifications for their renewed vigour: greater market concentration, reduced churn among the world’s biggest firms and rising corporate profits. On the surface all three point to rising corporate power. Look closely, though, and the trends may be the result of benign factors such as technological progress and globalisation. In some local markets, greater concentration may, paradoxically, have led to more competition, not less. And the covid-19 pandemic may have planted the seeds of a further competitive revival. Some big firms, it is true, have been collecting rents, including in big sectors such as health care. But trustbusters’ strategy—to reflexively question any deal involving a big firm—is wrongheaded. 123&quot;Market concentration&quot; 指的是市场上某一行业或领域中，少数几家大型企业占据了主导地位，形成了垄断或卡特尔。这种情况通常会导致缺乏竞争，从而影响市场效率和消费者福利。全球最大公司之间的流动减少：这意味着大型公司之间的并购、收购和分拆等交易的数量正在减少。这可能会导致市场上较少的竞争，从而影响市场效率和消费者福利。 反垄断调查人员对他们“重新振作”给出了三个理由：“市场集中度”更高，世界上最大的公司之间的流动减少，以及公司利润的增长。从表面上看，这三点都指向企业实力的上升。然而，仔细观察，这些趋势可能是技术进步和全球化等良性因素的结果。矛盾的是，在一些本地市场，集中度的提高可能导致竞争加剧，而不是减少。新冠疫情可能已经为进一步的竞争复苏播下了种子。确实，一些大公司一直在收取租金，包括医疗保健等大行业。但是反垄断调查人员的策略（即条件反射性地质疑任何涉及大公司的交易）是错误的。 That concentration has been rising is not in question. Across America’s economy it is higher today than at any point in at least the past century (see chart 1). Out of some 900 sectors in America tracked by The Economist, the number where the four biggest firms have a market share above two-thirds has grown from 65 in 1997 to 97 by 2017. In Europe, where the data are less comprehensive, market power has been increasing for at least 20 years. Using data on western Europe’s largest economies—Britain, Germany, France, Italy and Spain—Gabor Koltay, Szabolcs Lorincz and Tommaso Valletti, three economists, find that the market share of the four largest firms grew in 73% of some 700-odd industries from 1998 to 2019. The average increase was about seven percentage points. The proportion of firms with a share above 50% increased from 16% of industries to 27% by 1998 to 2019. Britain and France saw the biggest jumps. 市场集中度的上升是毫无疑问的。纵观美国经济，市场集中度比过去一个世纪的任何时候都要高（见图表1）。根据《经济学人》追踪的美国约900个行业中，其最大的四家公司的市场份额超过三分之二的行业数量从1997年的65家增长到2017年的97家。在数据不太全面的欧洲，市场实力至少20年来一直在增强。三位经济学家Gabor Koltay、Szabolcs Lorincz和Tommaso Valletti利用西欧最大经济体（英国、德国、法国、意大利和西班牙）的数据发现，1998年至2019年间，约700多个行业中有73%的四大公司的市场份额增长了。平均增长约为7个百分点。市场份额超过50%的公司比例从1998年的16%增加到2019年的27%。英国和法国的增幅最大。 At the same time, incumbent firms look more entrenched. In Britain, the average number of firms that stick in the top ten of their industries by market share three years later was five before the financial crisis. It is now closer to eight. Thomas Philippon of New York University’s Stern School of Business finds a similar reduction in churn among top American firms. 与此同时，现有公司的地位似乎更加稳固。在英国，在金融危机爆发之前，平均有五家公司在三年之后的市场份额上仍然位居行业前十。现在这个数字接近八家。纽约大学斯特恩商学院的Thomas Philippon发现，美国顶尖公司之间的流动性也减少了。 Most telling, firms are raking in higher profits. The Economist has come up with a crude estimate of “excess” profits for the world’s 3,000 largest listed companies by market value (excluding financial firms). Using reported figures from Bloomberg we calculate a firm’s hurdle rate of return on invested capital above 10% (excluding goodwill and treating research and development as an asset with a ten-year lifespan). This is the rate of return one might expect in a competitive market. In the past year excess profits reached $4trn, or nearly 4% of global gdp (see chart 2). They are highly concentrated in the West, especially America. American firms collect 41% of the total, with European ones taking 21%. The energy, technology and, in America, health-care industries stand out as excess-profit pools relative to their size. 最有说服力的是，公司正在获得更高的利润。《经济学人》对全球市值最大的3,000家上市公司（不包括金融公司）的“超额”利润进行了粗略估算。使用彭博社的报告数据，我们计算出一家公司的投资资本回报率应该在10%以上(（不包括商誉，并将研发视为具有十年寿命的资产）。这是在竞争市场中可能期望的回报率。在过去一年中，超额利润达到4万亿美元，约占全球GDP的4%（见图表2）。它们高度集中在西方，特别是美国。美国公司占总数的41%，欧洲公司占21%。能源、技术和在美国的医疗保健行业相对于其规模而言是超额利润池。 All this looks troubling. And in certain sectors, it is. Four decades ago more than eight in ten hospitals were non-profits with a single location. Now more than six in ten are owned by sprawling for-profit hospital chains or academic networks such as Steward Health Care or Indiana University Health. At first this was a perfectly healthy process of big and efficient chains expanding across America. Two decades—and nearly 2,000 hospital mergers—later, things look ropey. An analysis from 2019 by Martin Gaynor of Carnegie Mellon University and colleagues suggests that such mergers have tended to raise prices without improving quality. 这一切看起来都很麻烦。在某些领域，确实如此。40年前，超过80%的医院都是单一地点的非营利性医院。现在，超过六成的医院为大型盈利性连锁医院或学术网络所有，如Steward Health Care或Indiana University Health。起初，这是一个非常有益的过程，大型和高效的连锁店在美国扩张。二十年后，近2000家医院合并，情况看起来不太乐观。卡内基梅隆大学的Martin Gaynor及其同事从2019年开始的一项分析表明，这些并购往往会提高价格，但并未改善医疗服务质量。 Still, high concentration, low churn and rich profits need not necessarily make consumers worse off. That concentration has been rising for 100 years, during which life has improved for virtually everyone, is the first clue that it may be the result of benign forces. Increases in industry concentration in America over the past century are correlated with greater technological intensity, higher fixed costs and higher output growth, according to Yueran Ma of the University of Chicago Booth School of Business and colleagues. None of these seems particularly nefarious. 1【1】nefarious 恶毒的 尽管存在高度集中、低流动性和丰厚的利润，但这并不一定会使消费者受到损害。这种集中已经持续了100年，而在这期间，几乎每个人的生活都得到了改善，这是可能是良性力量的第一个迹象。根据芝加哥大学布斯商学院的Yueran Ma和同事的研究，美国过去一个世纪的行业集中度上升与更高的技术密集度、更高的固定成本和更高的产出增长有关。这些因素似乎都不是特别险恶的。 That concentration has also risen in Europe, where competition authorities have not been as sleepy as in America, likewise suggests that powerful structural forces are at play. John Van Reenen of the London School of Economics fingers technology and globalisation. The internet has reduced the cost of shopping around, even as software and other technology allow the best firms to scale up their operations around the world. Figures collected by McKinsey, a consultancy, show that the return on invested capital for a firm in the 75th percentile by this measure is 20 percentage points higher than for a median firm. “There are just huge economies of scale with software,” says Sterling Auty of MoffettNathanson, a research firm. 在欧洲，集中度也在上升，而那里的竞争当局并没有像美国那样“沉睡”，这同样表明强大的结构性力量正在发挥作用。伦敦经济学院的John Van Reenen指出，技术和全球化是原因。互联网降低了比价成本，同时软件和其他技术使最好的公司能够在全球范围内扩大业务规模。咨询公司麦肯锡收集的数据显示，按照这个指标，在处于75百分位数的公司的投资回报率比中位数公司高20个百分点。“软件存在巨大的规模经济效应，” 研究公司MoffettNathanson的Sterling Auty说道。 Local anti-heroes Moreover, higher concentration at the country level may increase competition locally. Service industries in particular, which make up about half the 900-odd sectors in America’s census, are better examined at the local level. Fiona Scott Morton, a former deputy assistant attorney-general now at Yale School of Management, uses the example of coffee shops. With just one café in each neighbourhood, the national market would be hyperfragmented. But every consumer would face a local monopoly. “If I’m looking for a coffee, I’m not going to drive three hours,” she says. 此外，国家层面上的高度集中度可能会增加本地的竞争。特别是服务业，美国人口普查中约900个行业的一半左右都是服务业，它更适合在地方层面上进行研究。现任耶鲁大学管理学院教授、前美国司法部副助理总检察长Fiona Scott Morton以咖啡店为例。如果每个社区只有一个咖啡店，那么全国市场将会非常分散。但每个消费者都将面临本地垄断。“如果我想找一家咖啡店，我不会开车三个小时去找，”她说道。 Academics debate what exactly has happened to concentration in local markets. What seems increasingly clear is that the best firms have expanded into more and more of them. Walmarts, with their “everyday low prices”, cater to shoppers across America, thanks to the retail behemoth’s unrivalled logistics operation. Cheesecake Factory uses a laboratory in California to taste-test dishes that it quickly rolls out to its 200 or so locations around America. A recent paper titled “The Industrial Revolution in Services’‘, by Esteban Rossi-Hansberg at the University of Chicago and his co-author, shows that the geographic expansion of big firms increases competition for local incumbents, whose local market share falls. 学者们对于本地市场的集中度到底发生了什么进行了激烈的辩论。但越来越明晰的是最好的公司已经扩展到了越来越多的本地市场。沃尔玛以其“每日低价”服务于美国各地的购物者，这得益于这家零售巨头无与伦比的物流运营能力。芝士蛋糕工厂使用加利福尼亚州的一个实验室来测试菜肴的味道，然后迅速推向其在美国约200个地点的门店。芝加哥大学的Esteban Rossi-Hansberg及其共同作者最近发表的一篇名为“服务业的工业革命”的论文表明，大公司的地理扩张增加了对本地现有企业的竞争，其本地市场份额下降。 As for low churn, it is not so bad if the incumbents keep innovating—which is what many are doing. Despite central banks pushing interest rates up at the fastest pace in decades in an attempt to quash inflation, American private investment in the first quarter of 2023 was 17.2% of gdp, similar to pre-pandemic highs. Many corporate behemoths are ploughing billions into innovation, including in areas that most worry trustbusters, such as technology. American tech’s big five—Alphabet, Amazon, Apple, Meta and Microsoft—collectively invested around $200bn in r&amp;d last year, about a quarter of America’s total in 2021. Microsoft and Alphabet are at the forefront of the ai race. 至于低流动性，如果现有企业不断创新，情况就不会那么糟糕——“不断创新”正是许多企业正在做的事情。尽管中央银行试图通过迅速提高利率来抑制通胀，但美国私人投资在2023年第一季度占GDP的17.2%，与疫情前的高点相似。许多企业巨头正在向创新领域投入数十亿美元，包括最令反垄断监管机构担忧的技术领域。美国科技界的五大巨头——Alphabet、亚马逊、苹果、Meta和微软——去年共投资约2000亿美元进行研发，约占美国2021年总投资的四分之一。微软和Alphabet处于人工智能竞赛的前沿。 Profits have, it is true, been higher in America since the financial crisis of 2007-09 than in previous decades, especially if you consider free cashflows, which accounts for the changing way companies depreciate assets (see chart 3). But they look somewhat less unusual if you adjust for lower tax rates and firms’ larger global footprint. And they may have peaked: analysts estimate that earnings for the s&amp;p 500 index of American blue chips dipped in the three months to June, year on year, for the third quarter in a row. 确实，自2007-09年金融危机以来，美国的利润率比之前几十年都要高，特别是如果考虑自由现金流，这是由于公司折旧资产方式的变化所导致的（见图3）。但如果考虑税率降低和公司更大的全球业务范围，它们看起来就不那么异常了。而且它们可能已经达到了峰值：分析师估计，美国蓝筹股标普500指数在截至6月的三个月中，连续第三个季度同比下降。 Most heartening, far from being subdued, dynamism may be on the rise. John Haltiwanger of the University of Maryland notes that business formation, which had been “quite anaemic” since the mid-2010s, has surged since the pandemic (see chart 4). In the past few years many more new firms have been created than old ones have been shut down. Whether these startups will dislodge incumbents is still unclear. But venture-capital investment suggests investors see scope for healthy returns. Although it is half what it was at its frothy peak of over $130bn in the fourth quarter of 2021, that has only brought it back to the levels of 2019 and 2020. 1“Business formation” 指的是新企业的创立。这些新企业可能是由个人、团队或公司创立的，旨在为市场提供新的产品或服务。企业创立通常是经济活力和创新的重要指标之一。 最令人振奋的是，经济活力可能正在上升，而非被抑制。马里兰大学的John Haltiwanger指出，自2010年代中期以来一直“相当萎靡不振”的“企业创立数量”自疫情爆发以来激增（见图4）。在过去几年中，新成立公司的数量比关闭的老公司多得多。这些初创企业是否会取代现有企业仍不清楚。但风险投资投资表明，投资者看到了健康回报的空间。虽然与2021年第四季度超过1300亿美元的泡沫高峰相比，风险投资只有一半，但这只是将其带回到2019年和2020年的水平。 One hypothesis is that the remote-friendliness of the post-covid economy reduces startup costs. Young firms no longer need to rent a big office. They can hire from a less local talent pool. By our rough count, around 125 of the Census Bureau’s 900-odd industries benefit from rising e-commerce or can provide their services remotely. Consumers’ growing comfort with such options could inspire more new businesses to set up shop. Mr Haltiwanger already observes a small shift in the size distribution of firms towards smaller fry. 一种假设是，后疫情时代经济的远程友好性降低了初创企业的成本。年轻的企业不再需要租用大型办公室，他们可以从更广泛的人才库中招聘员工。据我们粗略统计，美国人口普查局的约900个行业中，约有125个行业受益于电子商务的兴起或可以远程提供其服务。消费者对这些选项的不断接受可能会激发更多的新企业开张。Haltiwanger先生已经观察到，企业规模分布已经出现了向较小企业的微小转移。 Concentration may also be levelling off as a result of subdued dealmaking, especially in tech. The big five tech firms’ share of all acquisitions by listed firms in America has fallen from nearly 1% in the 2010s to less than 0.5% since the start of Mr Biden’s tenure. Some of the slowdown in mergers and acquisitions (m&amp;a) is caused by the rising cost of capital and risk of recession. But renewed antitrust zeal must be playing a role. On June 27th American authorities updated their merger guidelines for the first time in 45 years, requiring firms to report far more details on deals worth over $110m, half the average deal size in 2022. 由于交易活动的减弱，尤其是在科技领域，集中度也可能出现平稳。美国上市公司进行的所有收购交易中，五大科技公司所占比例已从2010年代的近1%下降到拜登政府上任以来的不到0.5%。一些并购交易放缓是由于资本成本上升和经济衰退风险增加所致。但新的反垄断热情肯定也在发挥作用。6月27日，美国当局首次在45年内更新了其并购指导方针，要求企业对超过1.1亿美元（2022年平均交易规模的一半）的交易报告更多细节。 The biggest transactions are almost sure to be subject to a deep probe, which can add months to a filing process that now takes weeks. Regulators everywhere are throwing “sand in the gears of the m&amp;a machine”, sighs a lawyer. “The ftc has stopped being discerning,” says another. Britain’s cma “has probably overreached”, echoes a British one. 123Throwing ‘sand in the gears of the M&amp;A machine’ 指的是监管机构在并购审查中增加了更多的限制和要求，从而使得并购交易更加困难和耗时。这个说法常用于形容监管机构对并购交易的干预和限制。“Stopped being discerning” 指的是监管机构在并购审查中对不同交易的区别和细节不再做出精细的判断，而是采取了一刀切的方式。这个说法常用于形容监管机构在并购审查中的不公正或不合理的做法。 最大的交易几乎肯定会受到深入调查，这可能会使申报过程延长数月，而现在这个过程只需要几周时间。到处都有监管机构在“干预并购”，一位律师叹息道。另一位律师表示，“联邦贸易委员会已经停止了鉴别（一刀切）”。一位英国律师也表示，“英国竞争与市场管理局可能已经过度（干预）了”。 Such overzealous trustbusting carries its own risks. It may distract attention from more immediate threats to economic dynamism from bureaucratic restraints on land use or occupational licensing. Acquisitions can be useful for preserving the value of startups when subdued markets make it hard for founders to raise capital. And some big deals may benefit consumers, as when a biotech startup joins forces with established drugmakers to test and distribute a new therapy. Competition authorities were probably asleep for too long. Now they may be getting up too quickly. ■ 这种过度热衷于打破垄断的做法也有其自身的风险。它可能会转移人们对经济活力面临的更直接威胁的注意力，使人们不再关注官僚机构对土地使用或职业许可的限制。在市场低迷时期，收购对于保护初创企业的价值可能非常有用，因为创始人很难筹集资本。一些大型交易可能会让消费者受益，比如一家生物技术初创公司与老牌制药公司联手测试和销售一种新疗法。竞争监管机构可能“沉睡”得太久了。现在他们可能“行动”得太快了。■","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1016-The Economist","slug":"Day1016-The Economist","date":"2023-07-03T01:45:02.463Z","updated":"2023-07-25T14:48:27.824Z","comments":true,"path":"2023/07/03/Day1016-The Economist/","link":"","permalink":"http://example.com/2023/07/03/Day1016-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 8th 2023 期 Business 栏目 The fight over working from home goes global居家办公之争已蔓延至全球 The WFH showdownWFH决战 Employees want to toil in the kitchen. Bosses want them back in the office员工想在厨房里辛苦工作。老板希望他们回到办公室 image: getty images Jul 10th 2023","text":"文章来源：《经济学人》Jul 8th 2023 期 Business 栏目 The fight over working from home goes global居家办公之争已蔓延至全球 The WFH showdownWFH决战 Employees want to toil in the kitchen. Bosses want them back in the office员工想在厨房里辛苦工作。老板希望他们回到办公室 image: getty images Jul 10th 2023 Remote work has a target on its back. Banking ceos, like Jamie Dimon of JPMorgan Chase, are intent on making working from home a relic of the pandemic. Staff at America’s biggest lender and other Wall Street stalwarts like Goldman Sachs are finding that five-day weeks are back for good. Big tech companies are also cracking the whip. Google’s return-to-work mandate threatens to track attendance and factor it in performance reviews for rebellious employees. Meta and Lyft want staff back at their desks, demanding at least three days of the week in the office by the end of the summer. With bosses clamping down on the practice, the pandemic-era days of mutual agreement on the desirability of remote work seem to be over. 远程工作已经成为“攻击对象”。像摩根大通的杰米•戴蒙这样的银行CEO们，决心让居家办公成为疫情的遗留物。美国最大的银行和高盛等华尔街巨头的员工发现，每周五天工作制又回来了。大型科技公司也在“快马加鞭”。谷歌的重返工作岗位规定可能会追踪出勤情况，并将其纳入对叛逆员工的绩效评估。Meta和Lyft希望员工回到办公桌前，要求到今年夏末，每周至少有三天在办公室工作。由于老板们加强了对远程工作的限制，疫情时期互相认同远程工作的美好愿景似乎已经结束了。 Fresh data from a global survey shows just how far this consensus has broken down. Across the world, plans for remote working by employers fall short of what workers want, according to wfh Research, a group that includes Stanford University and the Ifo Institute, a German think-tank, which has tracked the sentiment of full-time workers with at least a secondary education in 34 countries. Corporate bosses fear that fully remote work dents productivity, a worry reinforced by a slew of recent research. One study of data-entry workers in India found those toiling from home to be 18% less productive than their office-frequenting peers; another found that employees at a big Asian it firm were 19% less productive at home than they had been in the office. Communication records of nearly 62,000 employees at Microsoft showed that professional networks within the company ossified and became more isolated as remote work took hold. 一项全球调查的最新数据显示，这种共识已经破裂了。包括斯坦福大学和德国智库Ifo研究所在内的wfh Research小组对34个国家至少受过中等教育的全职员工的情绪进行了跟踪调查。该机构表示，在全球范围内，雇主的远程工作计划未能满足工人的需求。公司老板们担心完全远程工作会降低生产率，最近的一系列研究进一步证实了这种担忧。一项针对印度数据录入工作者的研究发现，在家工作的人的工作效率比经常在办公室工作的同事低18%；另一项研究发现，亚洲一家大型IT公司的员工在家工作的效率比在办公室工作的效率低19%。微软近6.2万名员工的通信记录显示，随着远程工作的盛行，公司内部的“职业网”变得僵化和更加孤立。 Yet all the pressure from above has done little to dent employees’ appetite for remote working. Workers want to be able to work more days from the comfort of their living rooms than they currently do, according to wfh Research. On average, workers across the world want two days at home, a full day more than they get. In English-speaking countries, which already have the highest levels of home-working, there is an appetite for more. And the trend is spreading to places where remote work has been less common (see chart 1). Japanese and South Korean employees, some of the most office-bound anywhere, want more than a quarter of the week to themselves. Europeans and Latin American crave a third and half, respectively. 然而，来自上级的所有压力并没有削弱员工对远程工作的兴趣。根据wfh Research的研究，员工希望能够在舒适的客厅里工作的天数比目前更多。平均而言，世界各地的员工希望在家工作两天，比他们目前得到的多一整天。在已经有最高水平的远程办公率的英语国家仍然渴望更多的天数。这一趋势正蔓延到远程工作不太常见的地方(见表1)。日本和韩国的员工，是世界上最受办公室束缚的“一员”，他们希望每周有超过四分之一的时间可以给到他们。欧洲人和拉丁美洲人分别渴望获得三分之一和一半的时间。 Continued desire for more remote work is not surprising. The time saved not having to battle public transport or congested roads allows for a better work-life balance. On average, 72 minutes each day is saved when working remotely, which adds up to two weeks over a year, according to a working paper* by Nicholas Bloom of Stanford, who helps run wfh Research, and colleagues. Employees also report that they feel most engaged when working remotely, according to a poll last year by Gallup. On average globally, workers value all these benefits to the tune of an 8% rise in their salaries, suggesting that some would take a pay cut to keep their privileges. 对更多远程工作的持续需求并不奇怪。不必与公共交通或拥挤的道路作斗争所节省的时间，有助于更好地实现工作与生活的平衡。据斯坦福大学帮助管理wfh Research的尼古拉斯•布鲁姆及其同事的一份工作报告显示，远程工作平均每天节省72分钟，一年下来总共节省两周时间。盖洛普去年的一项民意调查显示，员工报告称在远程工作时最投入。在全球范围内，平均而言，员工认为这些好处相当于他们薪水的8%的提高，这表明有些人愿意减薪以保持他们的特权。 Until recently, as firms tried to lure workers during the post-pandemic hiring bonanza, employees’ demands and employers’ plans seemed to be converging in America, the best-studied market. This convergence is tailing off (see chart 2). At the same time, the pandemic has entrenched work-from-home patterns. At the moment, a third of workers surveyed by wfh Research have a hybrid or fully remote arrangement. Those practices will not be easy to unwind. 最近，随着公司在后疫情时期的招聘繁荣中试图吸引工人，员工的要求和雇主的计划似乎在美国这个最受关注的市场上趋于一致。但是这种趋同正在减弱（见图2）。与此同时，疫情已经巩固了远程办公的模式。目前，在接受wfh Research调查的员工中，有三分之一的人采用混合或完全远程办公的安排。这些做法将不容易取消。 It is no coincidence that the crackdown on remote work is happening as the labour market begins to cool. Deepening job cuts across Wall Street and Silicon Valley have handed power back to businesses. However, even in tech and finance some employees are standing their ground. In May Amazon said that 300 employees staged walkouts over the e-empire’s return-to-work policies (the organisers said it was closer to 2,000). Other companies are quietly adapting with the times, perhaps recognising that a more flexible approach is inevitable. hsbc, a British bank, is planning to relocate from its 45-storey tower in Canary Wharf to smaller digs in the City of London. Deloitte and kpmg, two professional-services giants, plan to reduce their office footprint in favour of more remote work. The gap between the two sides of the work-from-home battle may yet narrow. The question is whether the bosses or the bossed will yield the most. ■ 对远程工作的打击并非巧合，这是劳动力市场开始降温的结果。华尔街和硅谷不断深化的裁员已将权力交还给企业。然而，即使在科技和金融行业，一些员工也坚持自己的立场。今年5月，亚马逊称有300名员工罢工，抗议该公司的重返工作岗位政策(组织者称罢工人数接近2000人)。其他公司也在悄悄顺应时代，或许它们意识到，更灵活的做法是不可避免的。英国汇丰银行正计划将其位于金丝雀码头的45层大楼搬迁到伦敦城较小的地方。德勤和毕马威这两家专业服务巨头计划减少办公室的占地面积，以支持更多的远程工作。在这场居家办公之战中，双方的差距可能会缩小。问题是老板还是员工谁会做出最多的让步。■","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]},{"title":"Day1015-The Economist","slug":"Day1015-The Economist","date":"2023-07-03T01:44:58.636Z","updated":"2023-07-25T14:48:33.979Z","comments":true,"path":"2023/07/03/Day1015-The Economist/","link":"","permalink":"http://example.com/2023/07/03/Day1015-The%20Economist/","excerpt":"文章来源：《经济学人》Jul 8th 2023 期 Business 栏目 How white-collar warriors gear up for the day白领战士如何准备一天的工作 Bartleby巴托比 Achilles goes to the office阿喀琉斯去了办公室 image: paul blow Jul 6th 2023","text":"文章来源：《经济学人》Jul 8th 2023 期 Business 栏目 How white-collar warriors gear up for the day白领战士如何准备一天的工作 Bartleby巴托比 Achilles goes to the office阿喀琉斯去了办公室 image: paul blow Jul 6th 2023 “The iliad” is a story of glory and gods, revenge and mercy, death and immortality. Squint hard enough and it is also a workplace saga. The epic kicks off with a big row between a pair of co-workers called Agamemnon and Achilles. The gods are the senior leadership team, descending from on high to cause complete chaos. For most of the book Achilles, a prototype of the talented jerk, is on strike. This is a big problem for the Greek management team, who have lost their best performer. A delegation from hr fails to win Achilles over. Eventually, however, he returns to the office, and all is well (Trojans may disagree). 《伊利亚特》是一个关于荣耀与神、复仇与仁慈、死亡与永生的故事。仔细看，这也是一个职场传奇。史诗从一对称为阿伽门农和阿喀琉斯的同事之间的大争吵开始。众神是高级领导团队，从高处降临，造成彻底的混乱。在书的大部分时间里，阿喀琉斯（有才华的混蛋原型）都在罢工。这对希腊的管理团队来说是个大问题，他们失去了最好的执行者。人力资源部的代表团没能说服阿喀琉斯。然而，最终，他回到办公室，一切都很好(特洛伊人可能不同意)。 The parallels between the 21st-century workplace and “The Iliad” are admittedly inexact. There are fewer swords and spears glinting in the rosy-fingered dawn today; there is a bit less brain matter on the floor. But to see the modern connections to Homer’s epic, look at Achilles’s preparations to go back to work. 诚然，将21世纪的职场与《伊利亚特》相提并论是不准确的。今天，在玫瑰色手指的黎明里闪闪发光的剑和矛少了；地板上的脑液少了一点。但要了解现代与荷马史诗的联系，看看阿喀琉斯为重返工作所做的准备。 “Now I shall arm myself for war,” he says in Book 19. The arming of Achilles is the forebear of gearing-up scenes ever since, from Chaucer to Rambo. But it also has echoes of current daily rituals. Achilles puts on bronze greaves and shining breastplates; employees choose clothes that they don’t wear at the weekend. Achilles puts on his golden-plumed helmet; commuters don their Bose headphones. The Homeric hero takes up a shield forged by Hephaestus, the god of fire. The office worker stuffs a laptop and charger into a rucksack. “现在我要武装自己准备战争”他在第19卷中说。阿喀琉斯的武装是自从那时起的先驱，从乔叟到兰博都有其影子。但它也有当前日常仪式的影子。阿喀琉斯穿上青铜护膝和闪亮的胸甲；员工会选择周末不穿的衣服。阿喀琉斯戴上金色羽毛的头盔；通勤者戴着Bose耳机。荷马英雄拿起火神赫菲斯托斯锻造的盾牌。上班族把笔记本电脑和充电器塞进背包。 Most of this white-collar arming takes place inside the home, but not all. It also happens en route to the battlefield, as compacts emerge and make-up is applied on the Tube. Sometimes the transformation takes place in the office itself. Trainers are swapped for heels. Lycra-clad colleagues disappear from view and emerge in something less off-putting. 1【1】off-putting 令人讨厌的 大多数白领“武装”都在家中进行，但并不是全部。在去“战场”的途中也会发生，比如在地铁上拿出粉饼化妆。有时，这种转变也会在办公室内发生。运动鞋换成了高跟鞋。穿着莱卡的同事从视线中消失，换上不那么令人讨厌的衣服。 Battle may be close but it does not arrive instantly, whether you are the king of the Myrmidons or Barry from accounts. Both have thresholds to cross before the real action begins. In Homer’s epic, Achilles has been sitting out the war in an encampment; his appearance on the seashore is when the Greeks learn that he is going to rejoin the fray. There is a feast before the fighting starts (Achilles refuses to eat; perhaps there wasn’t a vegan option). Once armed, he gets on his chariot and goes to the front “resplendent as the sun-god Hyperion”. 战斗可能即将到来，但它并不会立即到来，无论你是密耳弥多涅斯人的国王还是财务部的巴里。在真正的行动开始之前，两者都需要跨越一些门槛。在荷马史诗中，阿喀琉斯一直在营地中拒绝出战；当他出现在海滩上时，希腊人就知道他将重新加入战斗。战斗开始前有一场盛宴（阿喀琉斯拒绝吃饭；也许这里没有素食可选）。武装后，他上了战车，前往前线，“如太阳神海泼里恩一样耀眼”。 For remote workers the gap between their personal and professional lives may be narrow: the walk from the fridge to the living room (and back again, and back again). That is a problem. Entering the workplace means putting on a different persona as well as different clothes—you, but with added self-control. The transition is easier to make when there are clear boundaries separating home and work. 对于远程工作者来说，个人生活和职场生活之间的差距可能很小：从冰箱走到客厅（然后又走回去，再回来）。这是个问题。进入工作场所意味着不仅要换上不同的衣服，还要变换不同的“角色”——是你，但要加上更多的自制力。当家庭和工作之间有明确的界限时，这种转变更容易实现。 Office-goers have many more thresholds to cross. They emerge onto the street in the morning and make the journey towards their desks. They enter a café for their morning coffee; carrying a cup and walking briskly is the simplest way to let fellow citizens know you are gainfully employed. At some point they will have their first encounter with a fellow employee. If they are very unfortunate, this meeting will occur at the start of the commute and involve excruciating small talk on public transport for 40 minutes. Normally, it will just mean that the office is close. 上班族需要跨越许多门槛。他们早晨走出家门，开始前往办公桌的旅程。他们进入咖啡馆买早晨的咖啡；拿着杯子快步走是让其他市民知道你是有工作的最简单的方法。在某个时刻，他们将与同事进行第一次会面。如果他们非常不幸，这次会面将发生在通勤的开始，并包括40分钟的煎熬闲聊。正常情况下，与同事会面意味着办公室就在附近。 Workers must then make their entry into the office itself. There are security guards to greet, passes to swipe and lift buttons to press. Visitors to the office will participate in an extra arming scene at this point, in which they sign their names illegibly into a register and are given a lanyard. Hyperion, indeed. 接着，工人们必须进入办公室。他们需要与保安打招呼、刷通行证、按电梯按钮。此时，来访者将参与额外的武装场景，他们需要在登记簿上写下难以辨认的名字，并被给予一个挂绳。确实，就像海泼里恩一样。 The moment for action is now imminent. Outside the walls of Troy, Achilles springs forward like “a fierce lion”; a cycle of carnage begins that will end with the death of Hector. The white-collar worker must make final preparations for the day ahead, too. The rucksack comes off, and the computer switches on. The salaried hero springs forward, jaws foaming, to take a last bite of croissant; crumbs fleck the keyboard and the carpet. The password is entered, the loading wheel spins, the heart rate remains exactly the same. It’s time. 行动的时刻现在即将来临。在特洛伊城墙外，阿喀琉斯像“一只凶猛的狮子”一样向前冲；一轮屠杀开始了，最终以赫克托之死结束。白领工人也必须为即将到来的一天做最后的准备。卸下背包，打开电脑。拿着薪水的英雄张开嘴巴，像最后一口羊角面包一样猛扑上去，面包屑撒满了键盘和地毯。输入密码，等待加载，心率保持不变。是时候了。 Homer would never have made a name for himself with an office-based epic: death and glory guarantee a more dramatic narrative than email and meetings. But when you put on your work clothes, change into your professional self and pitilessly strike your first key, you are more than just a foot-soldier. You are a tiny Achilles. ■ 荷马永远不会因为办公室史诗而出名：死亡和荣耀比电子邮件和会议更具戏剧性。但当你穿上工作服，变成专业的自己，并毫不留情地敲下第一个键时，你不仅仅是一个步兵。你是一个小小的阿喀琉斯。■ 【里面的动作描述很生动形象，值得学习】","categories":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}]}],"categories":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"经济学人","slug":"经济学人","permalink":"http://example.com/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/"},{"name":"开发","slug":"开发","permalink":"http://example.com/tags/%E5%BC%80%E5%8F%91/"}]}